{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8426cfdf",
   "metadata": {},
   "source": [
    "<a id='top'></a>\n",
    "# HANDBUILT IMAGE PROCESSING FUNCTIONS \n",
    "# Truncated version for spectral clustering\n",
    "\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "</div>\n",
    "\n",
    "***\n",
    "## Table of Contents\n",
    "\n",
    "- [Reference To Constants & Predefined Kernels ](#reference-to-constants--predefined-kernels-)\n",
    "- [Image Loading & Saving](#image-loading--saving)\n",
    "- [Display](#display)\n",
    "- [Statistics](#statistics)\n",
    "- [Type Conversion](#type--conversion)\n",
    "- [Algebraic Manipulations & General Enhancement](#algebraic-manipulations--general-enhancement)\n",
    "- [Histograms & Data Processing](#histograms--data-processing)\n",
    "- [Color](#color)\n",
    "- [Noise Addition](#noise-addition)\n",
    "- [Filtering (Denoising)](#filtering-denoising)\n",
    "- [Filtering (Sharpening)](#filtering-sharpening)\n",
    "- [Thresholding | Object Detection](#thresholding--object-detection)\n",
    "- [Niblack, Bernsen, Sauvola](#niblack-bernsen-sauvola)\n",
    "- [Convolution & Edge Detection](#convolution--edge-detection)\n",
    "- [Morphology](#morphology)\n",
    "- [Midterm General](#midterm-general)\n",
    "- [Midterm Procedures](#midterm-procedures)\n",
    "- [Feature Extraction](#feature-extraction)\n",
    "- [Downsampling & Upsampling](#downsample-upsample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daa661a4",
   "metadata": {},
   "source": [
    "[GO TO TOP](#top)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a6eed99",
   "metadata": {},
   "source": [
    "<a id=\"reference-to-constants--predefined-kernels-\"></a>\n",
    "### Reference To Constants & Predefined Kernels \n",
    "Note these can be accessed in file name: \"Constants\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fa41302f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n#-------------------SOBEL------------------------\\nkernel3x3_sobel_x\\nkernel3x3_sobel_y\\n#-----------------PREWITT------------------------\\nkernel3x3_prewitt_x\\nkernel3x3_prewitt_y \\n#-----------------ROBERTS------------------------\\nkernel2x2_roberts_x\\nkernel2x2_roberts_y\\n#-----------------LAPLACIAN------------------------\\nkernel3x3_laplacian1\\nkernel3x3_laplacian1I\\nkernel3x3_laplacian2\\nkernel7x7_laplacianDoG\\n#-----------------ROBINSON------------------------\\nkernel3x3_robinson_N\\nkernel3x3_robinson_NW\\nkernel3x3_robinson_W \\nkernel3x3_robinson_SW\\nkernel3x3_robinson_S\\nkernel3x3_robinson_SE\\nkernel3x3_robinson_E\\nkernel3x3_robinson_NE\\n\\n#-----------------CV2 SHAPES----------------------\\n                \"RECT\": cv2.MORPH_RECT,\\n                \"CROSS\": cv2.MORPH_CROSS,\\n                \"ELLIPSE\": cv2.MORPH_ELLIPSE,\\n                \"HITMISS\": cv2.MORPH_HITMISS,\\n'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "#-------------------SOBEL------------------------\n",
    "kernel3x3_sobel_x\n",
    "kernel3x3_sobel_y\n",
    "#-----------------PREWITT------------------------\n",
    "kernel3x3_prewitt_x\n",
    "kernel3x3_prewitt_y \n",
    "#-----------------ROBERTS------------------------\n",
    "kernel2x2_roberts_x\n",
    "kernel2x2_roberts_y\n",
    "#-----------------LAPLACIAN------------------------\n",
    "kernel3x3_laplacian1\n",
    "kernel3x3_laplacian1I\n",
    "kernel3x3_laplacian2\n",
    "kernel7x7_laplacianDoG\n",
    "#-----------------ROBINSON------------------------\n",
    "kernel3x3_robinson_N\n",
    "kernel3x3_robinson_NW\n",
    "kernel3x3_robinson_W \n",
    "kernel3x3_robinson_SW\n",
    "kernel3x3_robinson_S\n",
    "kernel3x3_robinson_SE\n",
    "kernel3x3_robinson_E\n",
    "kernel3x3_robinson_NE\n",
    "\n",
    "#-----------------CV2 SHAPES----------------------\n",
    "                \"RECT\": cv2.MORPH_RECT,\n",
    "                \"CROSS\": cv2.MORPH_CROSS,\n",
    "                \"ELLIPSE\": cv2.MORPH_ELLIPSE,\n",
    "                \"HITMISS\": cv2.MORPH_HITMISS,\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "201f2d0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nimport timeit\\n\\n# Load a numpy or PIL image to use for testing\\nimage = image_name_here\\n# Measure the execution time of Code 1\\ncode_1_time = timeit.timeit(lambda: function1(image), number=100)\\n# Measure the execution time of Code 2\\ncode_2_time = timeit.timeit(lambda: function2(image), number=100)\\n\\nprint(f\"Code 1 execution time: {code_1_time:.6f} seconds\")\\nprint(f\"Code 2 execution time: {code_2_time:.6f} seconds\")\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' Test two functions for speed comparison '''\n",
    "'''\n",
    "import timeit\n",
    "\n",
    "# Load a numpy or PIL image to use for testing\n",
    "image = image_name_here\n",
    "# Measure the execution time of Code 1\n",
    "code_1_time = timeit.timeit(lambda: function1(image), number=100)\n",
    "# Measure the execution time of Code 2\n",
    "code_2_time = timeit.timeit(lambda: function2(image), number=100)\n",
    "\n",
    "print(f\"Code 1 execution time: {code_1_time:.6f} seconds\")\n",
    "print(f\"Code 2 execution time: {code_2_time:.6f} seconds\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2eb40d0",
   "metadata": {},
   "source": [
    "[GO TO TOP](#top)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a567d83",
   "metadata": {
    "id": "3a567d83"
   },
   "source": [
    "<a id=\"image-loading--saving\"></a>\n",
    "-----------------------------\n",
    "## Image Loading & Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0eb01702",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for file_name in sorted(os.listdir(folder_path)):\n",
    "def import_from_folder(folder_path, classification=None, title_addon=None, display_names=True, force_binary=False):\n",
    "    im_np_gray_data = []\n",
    "    im_np_gray_titles = []\n",
    "    im_PIL_gray_data = []\n",
    "    im_PIL_gray_titles = []\n",
    "    labels = []\n",
    "    \n",
    "    if display_names and title_addon is not None:\n",
    "        print(f\"\\n\\nSINGLE CHANNEL VARIABLE NAMES OF LOADED {title_addon.upper()} IMAGES: \\n\")\n",
    "    elif display_names:\n",
    "        print(\"\\n\\nSINGLE CHANNEL VARIABLE NAMES OF LOADED IMAGES: \\n\")\n",
    "        \n",
    "    label = None\n",
    "    if classification is not None:\n",
    "        if classification == 'clean':\n",
    "            label = 0\n",
    "        elif classification == 'dirty':\n",
    "            label = 1\n",
    "        else:\n",
    "            \"WARNING: label exists but is unidentified. May interfere with Classification.\"\n",
    "    \n",
    "    filenames = os.listdir(folder_path)\n",
    "    filenames.sort(key=lambda f: int(re.sub('\\D', '', f)) if f.endswith(('.jpg', '.jpeg', '.png')) else float('inf'))\n",
    "    \n",
    "    for file_name in filenames:\n",
    "        if file_name.endswith((\".jpg\", \".jpeg\", \".png\")):\n",
    "            file_path = os.path.join(folder_path, file_name)\n",
    "            im_PIL = Image.open(file_path)\n",
    "            \n",
    "            #if the image originates from an already thresholded image set, make sure it is loaded as such.\n",
    "            if force_binary:\n",
    "                im_PIL = single_threshold(im_PIL, 128)\n",
    "            \n",
    "            im_np = np.array(im_PIL)\n",
    "            im_PIL_gray = im_PIL.convert(\"L\")\n",
    "            im_np_gray = np.array(im_PIL_gray)\n",
    "            \n",
    "            base_name = os.path.splitext(file_name)[0]\n",
    "            if title_addon is None:\n",
    "                im_PIL_var_name = f\"{base_name}_PIL\"\n",
    "                im_np_var_name = f\"{base_name}_np\"\n",
    "                im_PIL_gray_var_name = f\"{base_name}_PIL_gray\"\n",
    "                im_np_gray_var_name = f\"{base_name}_np_gray\"\n",
    "            else:\n",
    "                im_PIL_var_name = f\"{title_addon}_{base_name}_PIL\"\n",
    "                im_np_var_name = f\"{title_addon}_{base_name}_np\"\n",
    "                im_PIL_gray_var_name = f\"{title_addon}_{base_name}_PIL_gray\"\n",
    "                im_np_gray_var_name = f\"{title_addon}_{base_name}_np_gray\"\n",
    "            \n",
    "            if display_names:\n",
    "                print(\" - \", im_PIL_gray_var_name, \"[+]\", im_np_gray_var_name)\n",
    "            \n",
    "            im_np_gray_data.append(im_np_gray)\n",
    "            im_np_gray_titles.append(im_np_gray_var_name)\n",
    "            im_PIL_gray_data.append(im_PIL_gray)\n",
    "            im_PIL_gray_titles.append(im_PIL_gray_var_name)\n",
    "            if label is not None:\n",
    "                labels.append((im_np_gray_var_name, label))\n",
    "                \n",
    "            globals()[im_PIL_var_name] = im_PIL\n",
    "            globals()[im_np_var_name] = im_np\n",
    "            globals()[im_PIL_gray_var_name] = im_PIL_gray\n",
    "            globals()[im_np_gray_var_name] = im_np_gray\n",
    "\n",
    "    return im_PIL_gray_data, im_PIL_gray_titles, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "97704980",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def import_from_folder(folder_path, addon=None, display_names = True):\n",
    "#     im_PIL_list = []\n",
    "#     im_np_list = []\n",
    "#     im_PIL_gray_list = []\n",
    "#     im_np_gray_list = []\n",
    "    \n",
    "#     im_np_gray_data = []\n",
    "#     im_np_gray_titles = []\n",
    "    \n",
    "#     im_PIL_gray_data = []\n",
    "#     im_PIL_gray_titles = []\n",
    "    \n",
    "#     #print(\"\\nVARIABLE NAMES OF LOADED\", addon.upper(), \"IMAGES: \\n\")\n",
    "#     if display_names == True and addon != None:\n",
    "#         print(\"\\n\\nSINGLE CHANNEL VARIABLE NAMES OF LOADED\", addon.upper(), \"IMAGES: \\n\")\n",
    "#     elif display_names == True and addon == None:\n",
    "#         print(\"\\n\\nSINGLE CHANNEL VARIABLE NAMES OF LOADED IMAGES: \\n\")\n",
    "          \n",
    "#     filenames = os.listdir(folder_path)\n",
    "#     filenames.sort(key=lambda f: int(re.sub('\\D', '', f)) if f.endswith(('.jpg', '.jpeg', '.png')) else float('inf'))\n",
    "    \n",
    "#     for file_name in filenames:\n",
    "        \n",
    "#         # Check if the file is an image\n",
    "#         if file_name.endswith((\".jpg\", \".jpeg\", \".png\")):\n",
    "            \n",
    "#             # Read the image file and convert to numpy arrays\n",
    "#             file_path = os.path.join(folder_path, file_name)\n",
    "#             im_PIL = Image.open(file_path)\n",
    "            \n",
    "#             # ENSURE that binary files are binary\n",
    "#             if addon == 'bin' or addon == 'provided':\n",
    "#                 im_PIL = single_threshold(im_PIL, 128)\n",
    "            \n",
    "#             im_np = np.array(im_PIL)\n",
    "#             im_PIL_gray = im_PIL.convert('L')\n",
    "#             im_np_gray = np.array(im_PIL_gray)\n",
    "\n",
    "#             # Extract the image name from the filename (no type extension)\n",
    "#             base_name = os.path.splitext(file_name)[0]\n",
    "            \n",
    "#             if addon == None:\n",
    "#                 # Create variable names using f-strings\n",
    "#                 im_PIL_var_name = f\"{base_name}_PIL\"\n",
    "#                 im_np_var_name = f\"{base_name}_np\"\n",
    "#                 im_PIL_gray_var_name = f\"{base_name}_PIL_gray\"\n",
    "#                 im_np_gray_var_name = f\"{base_name}_np_gray\"\n",
    "#             else:\n",
    "#                 # Create variable names using f-strings\n",
    "#                 im_PIL_var_name = f\"{addon}_{base_name}_PIL\"\n",
    "#                 im_np_var_name = f\"{addon}_{base_name}_np\"\n",
    "#                 im_PIL_gray_var_name = f\"{addon}_{base_name}_PIL_gray\"\n",
    "#                 im_np_gray_var_name = f\"{addon}_{base_name}_np_gray\"\n",
    "            \n",
    "#             # Display names of loaded files\n",
    "#             if display_names == True:\n",
    "#                 #print(\" - \", im_PIL_var_name, \"[+]\", im_np_var_name, \"[+]\", im_PIL_gray_var_name, \"[+]\", im_np_gray_var_name)\n",
    "#                 print(\" - \", im_PIL_gray_var_name, \"[+]\", im_np_gray_var_name)\n",
    "            \n",
    "#             # Add the numpy arrays to the corresponding lists\n",
    "#             im_PIL_list.append((im_PIL_var_name, im_PIL))\n",
    "#             im_np_list.append((im_np_var_name, im_np))\n",
    "#             im_PIL_gray_list.append((im_PIL_gray_var_name, im_PIL_gray))\n",
    "#             im_np_gray_list.append((im_np_gray_var_name, im_np_gray))\n",
    "            \n",
    "#             # Create grey-only returnable lists for image data and image titles\n",
    "#             im_np_gray_data.append(im_np_gray)\n",
    "#             im_np_gray_titles.append(im_np_gray_var_name)\n",
    "            \n",
    "#             im_PIL_gray_data.append(im_PIL_gray)\n",
    "#             im_PIL_gray_titles.append(im_PIL_gray_var_name)\n",
    "            \n",
    "#             # Assign the numpy arrays to separate variables\n",
    "#             globals()[im_PIL_var_name] = im_PIL\n",
    "#             globals()[im_np_var_name] = im_np\n",
    "#             globals()[im_PIL_gray_var_name] = im_PIL_gray\n",
    "#             globals()[im_np_gray_var_name] = im_np_gray\n",
    "\n",
    "#     return im_PIL_gray_data, im_PIL_gray_titles   \n",
    "#     #return im_np_gray_data, im_np_gray_titles       \n",
    "#     #return im_PIL_list, im_np_list, im_PIL_gray_list, im_np_gray_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "655fb2cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_images(images, width=512, height=512, display_status=True):\n",
    "    \n",
    "    #ensure that the image data is pil format\n",
    "    images = numpy_to_pil(images)\n",
    "    \n",
    "    # Resize a single image\n",
    "    if isinstance(images, Image.Image):\n",
    "        if images.size[0] == width and images.size[1] == height:\n",
    "            if display_status:\n",
    "                print(\"resize requested: the single image did not need to be resized.\")\n",
    "            return images\n",
    "        else:\n",
    "            img_resized = images.resize((width, height))\n",
    "            if display_status:\n",
    "                print(\"resize requested: the single image has been resized.\")\n",
    "            return img_resized\n",
    "    \n",
    "    # Resize a list of images\n",
    "    elif isinstance(images, list):\n",
    "        resized_images = []\n",
    "        for image in images:\n",
    "            if image.size[0] == width and image.size[1] == height:\n",
    "                resized_images.append(image)\n",
    "                resized=False\n",
    "            else:\n",
    "                img_resized = image.resize((width, height))\n",
    "                resized_images.append(img_resized)\n",
    "                resized=True\n",
    "        \n",
    "        if display_status:\n",
    "            if resized  == False:\n",
    "                print(\"resize requested: the set of images did not need to be resized.\")\n",
    "            if resized  == True:\n",
    "                print(\"resize requested: the set of images has been resized.\")\n",
    "                \n",
    "        return resized_images\n",
    "    \n",
    "    else:\n",
    "        raise TypeError(\"ERROR: Input image(s) could not be resized.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "141a172c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save SINGLE image\n",
    "def save_image(image, filename, color_type='rgb'):\n",
    "    \"\"\"\n",
    "    Detects the format of the image file and saves it to disk with the given filename.\n",
    "\n",
    "    Parameters:\n",
    "        image (str, numpy.ndarray, PIL.Image, cv2.Image): The input image file, as a \n",
    "        path to an image file, a numpy array, a PIL image, or a cv2 image.\n",
    "        filename (str): The desired name of the output file, including the file extension.\n",
    "        color_type (str): The color mode of the input image. Valid values are 'gray', 'rgb', 'hsl', or 'hsv'. Default is 'rgb'.\n",
    "    \"\"\"\n",
    "    # Convert the input image to a PIL image\n",
    "    if isinstance(image, str):\n",
    "        with Image.open(image) as im:\n",
    "            pil_image = im.copy()\n",
    "    elif isinstance(image, np.ndarray):\n",
    "        if len(image.shape) == 2:\n",
    "            # Convert grayscale image to RGB for saving as PNG or JPEG\n",
    "            pil_image = Image.fromarray(image).convert(color_type.upper())\n",
    "        else:\n",
    "            pil_image = Image.fromarray(image, mode=color_type.upper())\n",
    "    elif isinstance(image, Image.Image):\n",
    "        if image.mode == 'L':\n",
    "            # Convert grayscale image to RGB for saving as PNG or JPEG\n",
    "            pil_image = ImageOps.grayscale(image).convert(color_type.upper())\n",
    "        else:\n",
    "            pil_image = image.copy()\n",
    "            if image.mode != color_type.upper():\n",
    "                pil_image = pil_image.convert(color_type.upper())\n",
    "    elif isinstance(image, cv2.UMat):\n",
    "        pil_image = Image.fromarray(cv2.UMat.get(image))\n",
    "    elif isinstance(image, cv2.Mat):\n",
    "        if len(image.shape) == 2:\n",
    "            # Convert grayscale image to RGB for saving as PNG or JPEG\n",
    "            pil_image = Image.fromarray(image).convert(color_type.upper())\n",
    "        else:\n",
    "            pil_image = Image.fromarray(cv2.cvtColor(image, cv2.COLOR_BGR2RGB), mode=color_type.upper())\n",
    "    elif isinstance(image, cv2.VideoCapture):\n",
    "        ret, frame = image.read()\n",
    "        if frame.ndim == 2:\n",
    "            # Convert grayscale image to RGB for saving as PNG or JPEG\n",
    "            pil_image = Image.fromarray(frame).convert(color_type.upper())\n",
    "        else:\n",
    "            pil_image = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB), mode=color_type.upper())\n",
    "    else:\n",
    "        raise ValueError(f'Invalid image type: {type(image)}')\n",
    "\n",
    "    # Get the file format of the image\n",
    "    file_format = pil_image.format\n",
    "\n",
    "    # Save the image to disk with the given filename and format\n",
    "    output_filename = filename + '.png'\n",
    "    pil_image.save(output_filename)\n",
    "    # with open(output_filename, 'wb') as f:\n",
    "        # pil_image.save(f)\n",
    "\n",
    "    print(f'Saved image to {output_filename}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78bd58ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save LIST of images\n",
    "def save_images(images, filenames, color_type='rgb'):\n",
    "    \"\"\"\n",
    "    Detects the format of the image file and saves it to disk with the given filename.\n",
    "\n",
    "    Parameters:\n",
    "        images (list): A list of input images files, as paths to image files, numpy arrays, PIL images, or cv2 images.\n",
    "        filenames (list): A list of desired names of the output files, NOT including file extensions.\n",
    "        color_type (str): The color mode of the input image. Valid values are 'gray', 'rgb', 'hsl', or 'hsv'. Default is 'rgb'.\n",
    "    \"\"\"\n",
    "    for image, filename in zip(images, filenames):\n",
    "        # Convert the input image to a PIL image\n",
    "        if isinstance(image, str):\n",
    "            with Image.open(image) as im:\n",
    "                pil_image = im.copy()\n",
    "        elif isinstance(image, np.ndarray):\n",
    "            if len(image.shape) == 2:\n",
    "                # Convert grayscale image to RGB for saving as PNG or JPEG\n",
    "                pil_image = Image.fromarray(image).convert(color_type.upper())\n",
    "            else:\n",
    "                pil_image = Image.fromarray(image, mode=color_type.upper())\n",
    "        elif isinstance(image, Image.Image):\n",
    "            if image.mode == 'L':\n",
    "                # Convert grayscale image to RGB for saving as PNG or JPEG\n",
    "                pil_image = ImageOps.grayscale(image).convert(color_type.upper())\n",
    "            else:\n",
    "                pil_image = image.copy()\n",
    "                if image.mode != color_type.upper():\n",
    "                    pil_image = pil_image.convert(color_type.upper())\n",
    "        elif isinstance(image, cv2.UMat):\n",
    "            pil_image = Image.fromarray(cv2.UMat.get(image))\n",
    "        elif isinstance(image, cv2.Mat):\n",
    "            if len(image.shape) == 2:\n",
    "                # Convert grayscale image to RGB for saving as PNG or JPEG\n",
    "                pil_image = Image.fromarray(image).convert(color_type.upper())\n",
    "            else:\n",
    "                pil_image = Image.fromarray(cv2.cvtColor(image, cv2.COLOR_BGR2RGB), mode=color_type.upper())\n",
    "        elif isinstance(image, cv2.VideoCapture):\n",
    "            ret, frame = image.read()\n",
    "            if frame.ndim == 2:\n",
    "                # Convert grayscale image to RGB for saving as PNG or JPEG\n",
    "                pil_image = Image.fromarray(frame).convert(color_type.upper())\n",
    "            else:\n",
    "                pil_image = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB), mode=color_type.upper())\n",
    "        else:\n",
    "            raise ValueError(f'Invalid image type: {type(image)}')\n",
    "\n",
    "        # Get the file format of the image\n",
    "        file_format = pil_image.format\n",
    "\n",
    "        # Save the image to disk with the given filename and format\n",
    "        output_filename = filename + '.png'\n",
    "        pil_image.save(output_filename)\n",
    "        # with open(output_filename, 'wb') as f:\n",
    "            # pil_image.save(f)\n",
    "\n",
    "        print(f'Saved image to {output_filename}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d163326",
   "metadata": {},
   "source": [
    "[GO TO TOP](#top)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdb865e2",
   "metadata": {
    "id": "bdb865e2"
   },
   "source": [
    "<a id=\"display\"></a>\n",
    "-----------------------------\n",
    "## Display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "27648cff",
   "metadata": {
    "id": "27648cff"
   },
   "outputs": [],
   "source": [
    "#PIL or nparray\n",
    "def plot_image(image, title = '', save = False):\n",
    "    pylab.title(title, size=20), pylab.imshow(image)\n",
    "    if save == True:\n",
    "        pylab.imsave(title + '.png', image)\n",
    "    pylab.axis('off')\n",
    "    \n",
    "#     plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1443bb07",
   "metadata": {
    "id": "1443bb07"
   },
   "outputs": [],
   "source": [
    "#PIL or nparray\n",
    "def display_image(image, title=None, n=None, indirect_call=False, save=False): \n",
    "    # retrieve plot colors from main file\n",
    "    %store -r plt_color\n",
    "    %store -r label_color\n",
    "    %store -r title_color\n",
    "    \n",
    "    if indirect_call == False:\n",
    "        if n is not None:\n",
    "            fig = plt.figure(figsize=(n,n))\n",
    "        else:\n",
    "            fig = plt.figure()\n",
    "            \n",
    "    if title is not None:    \n",
    "        _ = plt.title(title, color = title_color)\n",
    "    _ = plt.set_cmap('gray')\n",
    "    _ = plt.axis('off')\n",
    "    _ = plt.imshow(image)\n",
    "    \n",
    "    if save == True:\n",
    "        _ = fig.savefig(title + '.png', dpi = 300, transparent=True, bbox_inches=\"tight\")\n",
    "    \n",
    "#     plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4eac2a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_contours(image, contours, title=None, save=False):\n",
    "    # retrieve plot colors from main file\n",
    "    %store -r plt_color\n",
    "    %store -r label_color\n",
    "    %store -r title_color\n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "    ax.imshow(image, cmap='gray')\n",
    "    for contour in contours:\n",
    "        ax.plot(contour[:,0, 0], contour[:,0, 1], color='red', linewidth=2)\n",
    "    if title is not None:\n",
    "        ax.set_title(title, color=title_color)\n",
    "    ax.set_axis_off()\n",
    "\n",
    "    if save:\n",
    "        if title is None:\n",
    "             title = 'contours'\n",
    "        plt.savefig(title + '.png', dpi=300, transparent=True, bbox_inches=\"tight\")\n",
    "        \n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80597f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_contour_image(image, contours, line=0.5, title=None, display=False, save=False):\n",
    "    import matplotlib as mpl\n",
    "    \n",
    "    blank_base = np.zeros_like(image)\n",
    "    \n",
    "    with mpl.rc_context(rc={'backend': 'Agg'}):\n",
    "        fig, ax = plt.subplots()\n",
    "        fig.set_size_inches(image.shape[1] / fig.dpi, image.shape[0] / fig.dpi)\n",
    "        ax.imshow(blank_base, cmap='gray')\n",
    "        \n",
    "        for contour in contours:\n",
    "            ax.plot(contour[:, 0, 0], contour[:, 0, 1], color='white', linewidth=line)\n",
    "            \n",
    "        if title is not None:\n",
    "            ax.set_title(title)\n",
    "        \n",
    "        ax.set_axis_off()\n",
    "        ax.margins(0)\n",
    "        fig.tight_layout(pad=0)\n",
    "            \n",
    "        # Save the plot as a PIL image\n",
    "        buf = BytesIO()\n",
    "        fig.savefig(buf, format='png', dpi=fig.dpi, transparent=True, bbox_inches=\"tight\", pad_inches=0)\n",
    "        buf.seek(0)\n",
    "        contour_image = Image.open(buf).convert('L')\n",
    "    \n",
    "    # Threshold the image to get binary white contours\n",
    "    threshold = 128\n",
    "    contour_image = contour_image.point(lambda p: p > threshold and 255)\n",
    "    \n",
    "    if save:\n",
    "        if title is None:\n",
    "            title = 'contours'\n",
    "        plt.savefig(title + '.png', dpi=300, transparent=True, bbox_inches=\"tight\")\n",
    "    \n",
    "    plt.close(fig)  # Close the figure to avoid showing it in the notebook\n",
    "    \n",
    "    return contour_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f8adc0e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def generate_contour_image(image, contours, line=0.5, title=None, display=False, save=False):\n",
    "#     blank_base = np.zeros_like(image)\n",
    "    \n",
    "#     fig, ax = plt.subplots()\n",
    "#     fig.set_size_inches(image.shape[1] / fig.dpi, image.shape[0] / fig.dpi)\n",
    "#     ax.imshow(blank_base, cmap='gray')\n",
    "    \n",
    "#     for contour in contours:\n",
    "#         ax.plot(contour[:, 0, 0], contour[:, 0, 1], color='white', linewidth=line)\n",
    "        \n",
    "#     if title is not None:\n",
    "#         ax.set_title(title)\n",
    "    \n",
    "#     ax.set_axis_off()\n",
    "#     ax.margins(0)\n",
    "#     fig.tight_layout(pad=0)\n",
    "        \n",
    "#     # Save the plot as a PIL image\n",
    "#     buf = BytesIO()\n",
    "#     fig.savefig(buf, format='png', dpi=fig.dpi, transparent=True, bbox_inches=\"tight\", pad_inches=0)\n",
    "#     buf.seek(0)\n",
    "#     contour_image = Image.open(buf).convert('L')\n",
    "    \n",
    "#     # Threshold the image to get binary white contours\n",
    "#     threshold = 128\n",
    "#     contour_image = contour_image.point(lambda p: p > threshold and 255)\n",
    "    \n",
    "#     if save:\n",
    "#         if title is None:\n",
    "#             title = 'contours'\n",
    "#         plt.savefig(title + '.png', dpi=300, transparent=True, bbox_inches=\"tight\")\n",
    "    \n",
    "#     plt.close(fig)  # Close the figure to avoid showing it in the notebook\n",
    "    \n",
    "#     return contour_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "58f95aa6",
   "metadata": {
    "id": "58f95aa6"
   },
   "outputs": [],
   "source": [
    "def display_hist(image, title='', indirect_call=False, m=None, n=None, save=False):\n",
    "    image = pil_to_numpy(image)\n",
    "    \n",
    "    # retrieve plot colors from main file\n",
    "    %store -r plt_color\n",
    "    %store -r label_color\n",
    "    %store -r title_color\n",
    "    \n",
    "    if indirect_call == False:\n",
    "        if m is not None:\n",
    "            fig = plt.figure(figsize=(m,n))\n",
    "        else:\n",
    "            fig = plt.figure(figsize=(4,2))\n",
    "        \n",
    "    hist = image.histogram()\n",
    "    _ = plt.title(title + \" Histogram\", color = title_color)\n",
    "    _ = plt.bar(range(256), hist, color = plt_color)\n",
    "    if save == True:\n",
    "        _ = fig.savefig(title + '.png', dpi = 300, transparent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "356cc49f",
   "metadata": {
    "id": "356cc49f"
   },
   "outputs": [],
   "source": [
    "#types: display_pair(PIL, string, bool)\n",
    "def display_pair(image, title=None, auto_title=False, m=None, n=None, save=False):\n",
    "    image = numpy_to_pil(image)\n",
    "    # retrieve plot colors from main file\n",
    "    %store -r plt_color\n",
    "    %store -r label_color\n",
    "    %store -r title_color\n",
    "    \n",
    "    #FIX SO THAT IT DISPLAYS THE IMAGE NAME\n",
    "    if title is None and auto_title == True:\n",
    "            title = f\"{image}\"\n",
    "    \n",
    "    with plt.rc_context({'axes.edgecolor':label_color, 'xtick.color':label_color, 'ytick.color':label_color}):\n",
    "        if m is not None:\n",
    "            fig = plt.figure(figsize=(m,n))\n",
    "        else:\n",
    "            fig = plt.figure(figsize=(8,2))\n",
    "\n",
    "\n",
    "         # show image\n",
    "        _ = fig.add_subplot(1,2,1)\n",
    "        if title is not None:\n",
    "            _ = plt.title(title, color= title_color)\n",
    "        _ = plt.set_cmap('gray')\n",
    "        _ = plt.axis('off')\n",
    "        _ = plt.imshow(image)\n",
    "\n",
    "        # show image histogram\n",
    "        hist = image.histogram()\n",
    "        _ = fig.add_subplot(1,2,2)\n",
    "        if title is not None:\n",
    "            _ = plt.title(title + ' Histogram', color= title_color)\n",
    "        _ = plt.bar(range(256), hist, color = plt_color )\n",
    "\n",
    "        fig.tight_layout()\n",
    "        if save == True:\n",
    "            _ = fig.savefig(title + '.png', dpi = 300, transparent=True)\n",
    "        _ = plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5bcf3913",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_4x5(images, titles=None, auto_title=False, fileName=None, save=False):\n",
    "    num_images = len(images)\n",
    "    num_rows = 4\n",
    "    num_cols = 5\n",
    "    fig, axes = plt.subplots(num_rows, num_cols, figsize=(10, 8))\n",
    "    \n",
    "    if titles is None and auto_title == True:\n",
    "        titles = [f\"Image {i+1}\" for i in range(num_images)]\n",
    "#         titles = [os.path.basename(img_path) for img_path in images]\n",
    "\n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        if i < num_images:\n",
    "            ax.imshow(images[i], cmap='gray')\n",
    "            if titles is not None:\n",
    "                ax.set_title(titles[i], color='lightpink')\n",
    "        ax.axis('off')\n",
    "\n",
    "    # Hide remaining axes\n",
    "    for i in range(num_images, num_rows*num_cols):\n",
    "        axes.flat[i].set_visible(False)\n",
    "    \n",
    "    # Set layout and save\n",
    "    fig.tight_layout()\n",
    "    if save == True:\n",
    "        if fileName == None:\n",
    "            fileName = 'plot_4x5'\n",
    "        fig.savefig(fileName + '.png', dpi=300, transparent=True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f6c1b08d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_rowsxcols(images, num_rows, num_cols, titles=None, auto_title=False, fileName=None, size=None, save=False):\n",
    "    \n",
    "    # retrieve plot colors from main file\n",
    "    %store -r plt_color\n",
    "    %store -r label_color\n",
    "    %store -r title_color\n",
    "    \n",
    "    num_images = len(images)\n",
    "    num_plots = num_rows * num_cols\n",
    "    \n",
    "    if num_images > num_plots:\n",
    "        raise ValueError(f\"Number of images ({num_images}) is greater than the number of plots ({num_plots})\")\n",
    "    \n",
    "    if size is None:\n",
    "        fig, axes = plt.subplots(num_rows, num_cols, figsize=(10, 8))\n",
    "    else:\n",
    "        fig, axes = plt.subplots(num_rows, num_cols, figsize=(size[0], size[1]))\n",
    "    \n",
    "    if titles is None and auto_title == True:\n",
    "        titles = [f\"Image {i+1}\" for i in range(num_images)]\n",
    "    \n",
    "    # Flatten the axes array\n",
    "    axes = np.array(axes).flatten()\n",
    "\n",
    "    for i in range(num_plots):\n",
    "        if i < num_images:\n",
    "            ax = axes[i]\n",
    "            ax.imshow(images[i], cmap='gray')\n",
    "            if titles is not None:\n",
    "                ax.set_title(titles[i], color=title_color)\n",
    "            ax.axis('off')\n",
    "        else:\n",
    "            # Hide remaining axes\n",
    "            axes[i].set_visible(False)\n",
    "\n",
    "    # Set labels for the axes\n",
    "    plt.xlabel('eigenvectors')\n",
    "    plt.ylabel('clusters')\n",
    "    \n",
    "    # Set layout and save\n",
    "    fig.tight_layout()\n",
    "    if save == True:\n",
    "        if fileName == None:\n",
    "            fileName = 'plot_images'\n",
    "        fig.savefig(fileName + '.png', dpi=300, transparent=True)\n",
    "    plt.show()\n",
    "    \n",
    "  \n",
    "def plot_rowsxcols_style2(images, num_rows, num_cols, title=None, fileName=None, size=None, save=False):  \n",
    "    num_images = len(images)\n",
    "    num_plots = num_rows * num_cols\n",
    "    \n",
    "    if num_images > num_plots:\n",
    "        raise ValueError(f\"Number of images ({num_images}) is greater than the number of plots ({num_plots})\")\n",
    "    \n",
    "    if size is None:\n",
    "        fig, axes = plt.subplots(num_rows, num_cols, figsize=(10, 8), sharex='col', sharey='row')\n",
    "    else:\n",
    "        fig, axes = plt.subplots(num_rows, num_cols, figsize=(size[0], size[1]), sharex='col', sharey='row')\n",
    "    plt.suptitle(f'Clustering Results for {title}')\n",
    "        \n",
    "    # Set Individual Plot Labels\n",
    "    for i in range(num_cols):\n",
    "        plt.setp(axes[-1, i], xlabel=f'{i+2}')\n",
    "    for i in range(num_rows):\n",
    "        ylabels = plt.setp(axes[i:, 0], ylabel=f'{i+2}')\n",
    "        for ylabel in ylabels:\n",
    "            ylabel.set_rotation(0)\n",
    "            \n",
    "    # Flatten the axes array\n",
    "    axes = np.array(axes).flatten()\n",
    "\n",
    "    # Hide the subplot borders\n",
    "    for ax in axes:\n",
    "        ax.spines[\"top\"].set_visible(False)\n",
    "        ax.spines[\"right\"].set_visible(False)\n",
    "        ax.spines[\"bottom\"].set_visible(False)\n",
    "        ax.spines[\"left\"].set_visible(False)\n",
    "\n",
    "    for i in range(num_plots):\n",
    "#         plt.setp(axes[-1:i], xlabel='x axis label', ylabel='y axis label')        \n",
    "        if i < num_images:\n",
    "            ax = axes[i]\n",
    "            ax.imshow(images[i], cmap='gray')\n",
    "            ax.grid(False)\n",
    "            ax.xaxis.set_major_locator(plt.NullLocator())\n",
    "            ax.yaxis.set_major_locator(plt.NullLocator())\n",
    "        else:\n",
    "            # Hide remaining axes\n",
    "            axes[i].set_visible(False)\n",
    "\n",
    "    # Set labels for the axes\n",
    "    fig.supxlabel('eigenvectors')\n",
    "    fig.supylabel('clusters')\n",
    "    \n",
    "    # Set layout and save\n",
    "    fig.tight_layout()\n",
    "    if save == True:\n",
    "        if fileName == None:\n",
    "            fileName = 'clustering_results'\n",
    "        fig.savefig(f'{title}_clustering_results' + '.png', dpi=300, transparent=False)\n",
    "    plt.show()\n",
    "    \n",
    "#plot images with predefined number of rows & columns\n",
    "def plot_rowsxcols_style3(images, num_rows, num_cols, titles=None, auto_title=False, fileName=None, size=None, save=False):\n",
    "    \n",
    "    # retrieve plot colors from main file \n",
    "    num_images = len(images)\n",
    "    num_plots = num_rows * num_cols\n",
    "    \n",
    "    if num_images > num_plots:\n",
    "        raise ValueError(f\"Number of images ({num_images}) is greater than the number of plots ({num_plots})\")\n",
    "    \n",
    "    if size is None:\n",
    "        fig, axes = plt.subplots(num_rows, num_cols, figsize=(10, 8))\n",
    "    else:\n",
    "        fig, axes = plt.subplots(num_rows, num_cols, figsize=(size[0], size[1]))\n",
    "    \n",
    "    if titles is None and auto_title == True:\n",
    "        titles = [f\"Image {i+1}\" for i in range(num_images)]\n",
    "    \n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        if i < num_images:\n",
    "            ax.imshow(images[i], cmap='gray')\n",
    "            if titles is not None:\n",
    "                ax.set_title(titles[i])\n",
    "        ax.axis('off')\n",
    "\n",
    "    # Hide remaining axes\n",
    "    for i in range(num_images, num_plots):\n",
    "        axes.flat[i].set_visible(False)\n",
    "    \n",
    "    # Set layout and save\n",
    "    fig.tight_layout()\n",
    "    if save == True:\n",
    "        if fileName == None:\n",
    "            fileName = 'plot_images'\n",
    "        fig.savefig(fileName + '.png', dpi=300, transparent=True)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1c3ebaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot images with auto-determined square dimensions\n",
    "def plot_nxn(images, titles=None, auto_title=False, fileName=None, size=None, save=False):\n",
    "    \n",
    "    # retrieve plot colors from main file\n",
    "    %store -r plt_color\n",
    "    %store -r label_color\n",
    "    %store -r title_color\n",
    "    \n",
    "    #if images is list or set of images...\n",
    "    if isinstance(images, (list, tuple, np.ndarray)):\n",
    "        num_images = len(images)\n",
    "        num_plots = math.ceil(math.sqrt(num_images))\n",
    "\n",
    "        if num_plots**2 == num_images:\n",
    "            num_rows = num_cols = num_plots\n",
    "        else:\n",
    "            num_cols = num_plots\n",
    "            num_rows = math.ceil(num_images / num_cols)\n",
    "\n",
    "        if size is None:\n",
    "            fig, axes = plt.subplots(num_rows, num_cols, figsize=(10, 8))\n",
    "        else:\n",
    "            fig, axes = plt.subplots(num_rows, num_cols, figsize=(size[0], size[1]))\n",
    "            \n",
    "        if titles is None and auto_title == True:\n",
    "            titles = [f\"Image {i+1}\" for i in range(num_images)]\n",
    "    #         titles = [os.path.basename(img_path) for img_path in images]\n",
    "\n",
    "        for i, ax in enumerate(axes.flat):\n",
    "            if i < num_images:\n",
    "                ax.imshow(images[i], cmap='gray')\n",
    "                if titles is not None:\n",
    "                    ax.set_title(titles[i], color = title_color)\n",
    "            ax.axis('off')\n",
    "\n",
    "        # Hide remaining axes\n",
    "        for i in range(num_images, num_rows*num_cols):\n",
    "            axes.flat[i].set_visible(False)\n",
    "         \n",
    "        # Set layout and save\n",
    "        fig.tight_layout()\n",
    "        if save == True:\n",
    "            if fileName == None:\n",
    "                fileName = 'plot_images'\n",
    "            fig.savefig(fileName + '.png', dpi=300, transparent=True)\n",
    "        plt.show()\n",
    "    \n",
    "    #if images is a single image...\n",
    "    else:\n",
    "        if titles is None: \n",
    "            display_image(images, indirect_call=True, save=save)\n",
    "        else:\n",
    "            display_image(images, titles[0], indirect_call=True, save=save)\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "76fae81a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_nxhist(images, titles=None, auto_title=False, fileName=None, save=False):\n",
    "    \n",
    "    # if data is a numpy array, convert it to PIL\n",
    "    images = numpy_to_pil(images)\n",
    "    \n",
    "    # retrieve plot colors from main file\n",
    "    %store -r plt_color\n",
    "    %store -r label_color\n",
    "    %store -r title_color\n",
    "\n",
    "    #if images is list or set of images...\n",
    "    if isinstance(images, (list, tuple, np.ndarray)):\n",
    "        num_images = len(images)\n",
    "\n",
    "        if titles is None and auto_title == True:\n",
    "            titles = [f\"Image {i+1}\" for i in range(num_images)]\n",
    "\n",
    "        with plt.rc_context({'axes.edgecolor':label_color, 'xtick.color':label_color, 'ytick.color':label_color}): \n",
    "            fig, axs = plt.subplots(num_images, 2, figsize=(8,num_images*2))\n",
    "\n",
    "            for i in range(num_images):\n",
    "                # show image\n",
    "                if titles is not None:\n",
    "                    axs[i, 0].set_title(titles[i], color=title_color)\n",
    "                axs[i, 0].imshow(images[i], cmap='gray')\n",
    "                axs[i, 0].axis('off')\n",
    "\n",
    "                # show histogram\n",
    "                hist = images[i].histogram()\n",
    "                if titles is not None:\n",
    "                    axs[i, 1].set_title(titles[i] + ' Histogram', color=title_color)\n",
    "                axs[i, 1].bar(range(256), hist, color=plt_color)\n",
    "                axs[i, 1].set_xlim([0, 256])\n",
    "\n",
    "            fig.tight_layout()\n",
    "            if save:\n",
    "                _ = fig.savefig(fileName + '.png', dpi=300, transparent=True)\n",
    "            _ = plt.show()\n",
    "            \n",
    "    #if images is a single image...        \n",
    "    else:\n",
    "        if titles is None:\n",
    "            display_pair(images, save=save)\n",
    "        else:\n",
    "            display_pair(images, titles[0], save=save)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "862268fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def plot_nxhist(images, titles=None, auto_title=False, fileName=None, save=False):\n",
    "    \n",
    "#     # if data is a numpy array, convert it to PIL\n",
    "#     images = numpy_to_pil(images)\n",
    "    \n",
    "#     # retrieve plot colors from main file\n",
    "#     %store -r plt_color\n",
    "#     %store -r label_color\n",
    "#     %store -r title_color\n",
    "\n",
    "#     #if images is list or set of images...\n",
    "#     if isinstance(images, (list, tuple, np.ndarray)):\n",
    "#         num_images = len(images)\n",
    "#         num_rows = num_images * 2\n",
    "\n",
    "#         if titles is None and auto_title == True:\n",
    "#             titles = [f\"Image {i+1}\" for i in range(num_images)]\n",
    "\n",
    "#         with plt.rc_context({'axes.edgecolor':label_color, 'xtick.color':label_color, 'ytick.color':label_color}): \n",
    "#             fig = plt.figure(figsize=(6,num_images*2))\n",
    "\n",
    "#             for i in range(num_images):\n",
    "#                 # show image\n",
    "#                 _ = fig.add_subplot(num_rows, 2, i*2+1)\n",
    "#                 if titles is not None:\n",
    "#                     _ = plt.title(titles[i], color=title_color)\n",
    "#                 _ = plt.set_cmap('gray')\n",
    "#                 _ = plt.axis('off')\n",
    "#                 _ = plt.imshow(images[i])\n",
    "\n",
    "#                 # show histogram\n",
    "#                 hist = images[i].histogram()\n",
    "#                 _ = fig.add_subplot(num_rows, 2, i*2+2)\n",
    "#                 if titles is not None:\n",
    "#                     _ = plt.title(titles[i] + ' Histogram', color=title_color)\n",
    "#                 _ = plt.bar(range(256), hist, color=plt_color)\n",
    "\n",
    "#             fig.tight_layout()\n",
    "#             if save:\n",
    "#                 _ = fig.savefig(fileName + '.png', dpi=300, transparent=True)\n",
    "#             _ = plt.show()\n",
    "            \n",
    "#     #if images is a single image...        \n",
    "#     else:\n",
    "#         display_pair(images, titles, m=6, n=2, save=save)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b2153d6",
   "metadata": {},
   "source": [
    "[GO TO TOP](#top)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61d26b04",
   "metadata": {},
   "source": [
    "<a id=\"statistics\"></a>\n",
    "-----------------------------\n",
    "## Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ea682d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_first_order_statistics(hist, display=False):\n",
    "    \"\"\"\n",
    "    This function computes the first order statistics of a given histogram\n",
    "    Parameters:\n",
    "    hist (numpy.ndarray): A 1D numpy array representing the histogram.\n",
    "\n",
    "    Returns:\n",
    "    tuple: A tuple containing the following first order statistics:\n",
    "    - n_pixels (int): The total number of pixels in the histogram.\n",
    "    - min_val (int): The minimum value in the histogram.\n",
    "    - max_val (int): The maximum value in the histogram.\n",
    "    - mean (float): The mean value of the histogram.\n",
    "    - std (float): The standard deviation of the histogram.\n",
    "    - median (float): The median value of the histogram.\n",
    "    - mode (int): The mode value of the histogram.\n",
    "    \"\"\"\n",
    "    n_pixels = np.sum(hist)\n",
    "    min_val = np.min(np.where(hist > 0))\n",
    "    max_val = np.max(np.where(hist > 0))\n",
    "    mean = np.sum(np.arange(len(hist)) * hist) / n_pixels\n",
    "    std = np.sqrt(np.sum(((np.arange(len(hist)) - mean) ** 2) * hist) / n_pixels)\n",
    "    median = np.median(np.where(hist > 0))\n",
    "    mode = np.argmax(hist)\n",
    "    \n",
    "    if display:\n",
    "        print(f\"Number of pixels:\", n_pixels)\n",
    "        print(f\"Minimum value:\", min_val)\n",
    "        print(f\"Maximum value:\", max_val)\n",
    "        print(f\"Mean value:\", mean)\n",
    "        print(f\"Standard deviation:\", std)\n",
    "        print(f\"Median value:\", median)\n",
    "        print(f\"Mode value:\", mode)\n",
    "        \n",
    "    return n_pixels, min_val, max_val, mean, std, median, mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3793be1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_data_distance(input1, input2, data_mode='image', measure='euclidean', display_hist=False, display=False):\n",
    "    \"\"\"\n",
    "    Calculate the distance between two datasets (images or features) using a specified distance measure.\n",
    "    \n",
    "    Args:\n",
    "        input1: First dataset (single image or feature array)\n",
    "        input2: Second dataset (single image or feature array)\n",
    "        data_mode (str): Type of data, either 'image' or 'feature'\n",
    "        measure (str): Distance measure to use, either 'euclidean', 'linear', 'chi2', or 'cosine'\n",
    "        display_hist (bool): Whether to display histogram data (only for image data_mode)\n",
    "        display (bool): Whether to display the calculated distance\n",
    "\n",
    "    Returns:\n",
    "        float: The calculated distance between input1 and input2\n",
    "    \"\"\"\n",
    "    distance = None\n",
    "    if data_mode == 'image':\n",
    "        if isinstance(input1, np.ndarray) or isinstance(input2, np.ndarray):\n",
    "            print(f\"Error: data_mode is '{data_mode}' but input is stored in ndarray\")\n",
    "            return -1      \n",
    "        A = np.array(input1.histogram(), dtype='int64')\n",
    "        B = np.array(input2.histogram(), dtype='int64')\n",
    "        #display histogram data if desired\n",
    "        if display_hist:\n",
    "            print(\"Histogram1: \\n\", A.reshape(1,-1), \"\\nHistogram2: \\n\", B.reshape(1,-1))     \n",
    "    elif data_mode == 'feature':\n",
    "        if isinstance(input1, Image.Image) or isinstance(input2, Image.Image):\n",
    "            print(f\"Error: data_mode is '{data_mode}' but input is stored as PIL Image\")\n",
    "            return -1\n",
    "        A = np.array(input1).astype(float)\n",
    "        B = np.array(input2).astype(float)\n",
    "        \n",
    "    else:\n",
    "        raise TypeError(\"Unrecognized data_mode. Currently accepting only: \\'image\\' and \\'feature\\'\")\n",
    "        \n",
    "    #if the datasets can't be matched send warning\n",
    "    if len(A) != len(B):\n",
    "        raise ValueError(\"Datasets must have the same length in order to evaluate distance.\")\n",
    "        \n",
    "    if measure == 'euclidean': \n",
    "        distance = 0\n",
    "        distance = np.sqrt(np.sum((A - B)**2))\n",
    "    elif measure == 'linear':\n",
    "        distance = 0\n",
    "        distance = np.mean(np.abs(A - B))  \n",
    "    elif measure == 'chi2':\n",
    "        distance = chi2_distance(A, B)\n",
    "    elif measure == 'cosine':\n",
    "        distance = 1 - np.dot(A, B) / (np.linalg.norm(A) * np.linalg.norm(B))\n",
    "    else:\n",
    "        print(\"No Distance Calculation Method Specified\")\n",
    "\n",
    "    if distance is None:\n",
    "        raise ValueError(\"No distance calculation method was specified\")\n",
    "    if display:\n",
    "        print(f\"\\n{data_mode} {measure} distance = \", distance)\n",
    "        \n",
    "    return distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c120ad0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given two matrices as input, the following function computes the minimum squared error(MSE) of the two matrices.\n",
    "def calculate_mean_sq_error(mat1, mat2):\n",
    "    min_sq = 0\n",
    "    M, N = mat1.shape[:2]\n",
    "    for i in range(M):\n",
    "        for j in range(N):\n",
    "            min_sq += np.square(mat1[i][j] - mat2[i][j])\n",
    "    return min_sq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b39d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def intersection_distance(A, B):\n",
    "#     return np.sum(np.minimum(A, B))\n",
    "\n",
    "# def bhattacharyya_distance(A, B):\n",
    "#     return -np.log(np.sum(np.sqrt(A * B)) / (np.sqrt(np.sum(A)) * np.sqrt(np.sum(B))))\n",
    "\n",
    "# def calculate_data_distance(input1, input2, data_mode='image', measure='euclidean', display_hist=False, display=False):\n",
    "#     # ... (previous code)\n",
    "        \n",
    "#     if measure == 'euclidean': \n",
    "#         distance = np.sqrt(np.sum((A - B)**2))\n",
    "#     elif measure == 'linear':\n",
    "#         distance = np.mean(np.abs(A - B))  \n",
    "#     elif measure == 'chi2':\n",
    "#         distance = chi2_distance(A, B)\n",
    "#     elif measure == 'cosine':\n",
    "#         distance = 1 - np.dot(A, B) / (np.linalg.norm(A) * np.linalg.norm(B))\n",
    "#     elif measure == 'intersection':\n",
    "#         distance = intersection_distance(A, B)\n",
    "#     elif measure == 'bhattacharyya':\n",
    "#         distance = bhattacharyya_distance(A, B)\n",
    "#     elif measure == 'emd':\n",
    "#         from scipy.stats import wasserstein_distance\n",
    "#         distance = wasserstein_distance(A, B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "059fc438",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_white_pixels(image):\n",
    "    image = pil_to_numpy(image)\n",
    "    height, width = image.shape\n",
    "\n",
    "    white_pixel_count = 0\n",
    "    \n",
    "    # Loop through each pixel in the image\n",
    "    for x in range(width):\n",
    "        for y in range(height):\n",
    "            # Get pixel color\n",
    "            pixel = image[y, x]\n",
    "\n",
    "            # Check if pixel is white (255) for RGB color channels\n",
    "            if np.all(pixel == 255):\n",
    "                # Increment counter\n",
    "                white_pixel_count += 1\n",
    "\n",
    "    return white_pixel_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "afc0e583",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_perimeter(image, display=False, save=False):\n",
    "    image = pil_to_numpy(image)\n",
    "    \n",
    "    contours, hierarchy = cv2.findContours(image.astype(np.uint8), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "    perimeter = sum(cv2.arcLength(contour, True) for contour in contours)\n",
    "    extracted_contours = generate_contour_image(image, contours, title=None, save=save)\n",
    "\n",
    "    perimeter = count_white_pixels(extracted_contours)\n",
    "    perimeter_feat = np.array([perimeter])\n",
    "    \n",
    "    if display: \n",
    "        display_contours(image, contours, title=None, save=save)\n",
    "        print(\"\\nOriginal Image Shape = \", segmented_data[72].size)\n",
    "        print(\"Generated Image Shape = \", extracted_contours.size)\n",
    "        print(\"PERIMITER = \", perimeter)\n",
    "    \n",
    "    return perimeter_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7823341",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate Chi-distance\n",
    "def chi2_distance(A, B, normalize=True):\n",
    "    A = pil_to_numpy(A).astype(float)\n",
    "    B = pil_to_numpy(B).astype(float)\n",
    "    \n",
    "    if normalize:\n",
    "        A /= np.sum(A)\n",
    "        B /= np.sum(B)\n",
    "        \n",
    "    # compute the chi-squared distance using above formula\n",
    "    chi = 0.5 * np.sum([((a - b) ** 2) / (a + b + 1e-10) for (a, b) in zip(A, B)])\n",
    "    \n",
    "    return chi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75a7063d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chi_squared_onimages(images, reference, display=False, save=False):\n",
    "    chi_squared_vals = []\n",
    "    diff = 0\n",
    "    total = 0\n",
    "    for i in range(len(images)):\n",
    "        img = np.array(images[i]).astype(np.uint8)\n",
    "        ref = np.array(reference).astype(np.uint8)\n",
    "        diff = 0.5 * np.sum((img-ref)**2 / (img + ref + 1e-10))\n",
    "        if display == True:\n",
    "            print(diff)\n",
    "        total += diff\n",
    "        chi_squared_vals.append(diff)\n",
    "    \n",
    "    if display == True:   \n",
    "        print(\"avg\", total/len(chi_squared_vals))\n",
    "    return chi_squared_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "da49a101",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chi_squared_onfeatures(feature_set, feature_benchmark):\n",
    "    # calculate distances between all new_images_features and the single benchmark_image_features\n",
    "    distances = []\n",
    "    feature_benchmark = np.array(feature_benchmark)\n",
    "    \n",
    "    for i in range(len(feature_set)):\n",
    "        feature_image = np.array(feature_set[i])\n",
    "        dist = 0.5 * np.sum((feature_image - feature_benchmark) ** 2 / (feature_set[i] + feature_benchmark + 1e-10))\n",
    "        distances.append(dist)\n",
    "\n",
    "    return distances"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c632278",
   "metadata": {},
   "source": [
    "[GO TO TOP](#top)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "012d5aea",
   "metadata": {},
   "source": [
    "<a id=\"type--conversion\"></a>\n",
    "-----------------------------\n",
    "## Type Conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "350308e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_gray_or_binary(image, force_binary = False):\n",
    "    \"\"\"\n",
    "    This function detects if an image is binary or grayscale and optionally forces it to be binary.\n",
    "\n",
    "    Parameters:\n",
    "    image (numpy.ndarray): A 2D numpy array representing the image to check.\n",
    "    force_binary (bool): A boolean indicating whether to force the image to be binary (default False).\n",
    "\n",
    "    Returns:\n",
    "     PIL.Image.Image: An instance of PIL.Image.Image representing the image after optional binarization.\n",
    "    \"\"\"\n",
    "    image = pil_to_numpy(image)\n",
    "    grayscale = False #assume false until non-binary value found\n",
    "    for i in range(len(image)):\n",
    "        for j in range(len(image[i])):\n",
    "            pixelval = image[i][j]\n",
    "            if (pixelval > 0) and (pixelval < 255):\n",
    "                grayscale = True\n",
    "\n",
    "    print(\"Grayscale Status: \", grayscale, \"\\nValues:\\n\", image)\n",
    "\n",
    "    # Display and threshold if needed \n",
    "    display_image(image)\n",
    "    if force_binary == True and grayscale == True:\n",
    "        image = np.array(single_threshold(image, 128))\n",
    "        display_image(image)\n",
    "\n",
    "        grayscale = False #assume false until non-binary value found\n",
    "        for i in range(len(image)):\n",
    "            for j in range(len(image[i])):\n",
    "                pixelval = image[i][j]\n",
    "                if (pixelval > 0) and (pixelval < 255):\n",
    "                    grayscale = True\n",
    "\n",
    "        print(\"Grayscale Status UPDATED: \", grayscale, \"\\nValues:\\n\", grey_lap1_sigma1_np_gray)\n",
    "        \n",
    "    image = numpy_to_pil(image)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c718e1c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#works for both single images and sets of images\n",
    "def detect_type(images, display_type = False):\n",
    "    \n",
    "    # Input is a list or other iterable of images. check type of first image\n",
    "    if isinstance(images, (list, tuple)):\n",
    "        first_image = images[0]\n",
    "        if isinstance(first_image, np.ndarray):\n",
    "            if display_type == True: \n",
    "                print(\"NumPy: Image SET contains images stored as NumPy arrays.\")\n",
    "            return 'numpy_set'\n",
    "        elif isinstance(first_image, Image.Image):\n",
    "            if display_type == True:\n",
    "                print(\"PIL: Image SET contains images stored as PIL images.\")\n",
    "            return 'pil_set'\n",
    "        else:\n",
    "            raise TypeError(\"Image SET type not recognized.\")\n",
    "    \n",
    "    # Input is a single image\n",
    "    elif isinstance(images, np.ndarray):\n",
    "        if display_type == True: \n",
    "            print(\"NumPy: Image SINGLE is stored as a NumPy array.\")\n",
    "        return 'numpy_single'\n",
    "    elif isinstance(images, Image.Image):\n",
    "        if display_type == True:\n",
    "            print(\"PIL: Image SINGLE is stored as a PIL image.\")\n",
    "        return 'pil_single'\n",
    "    else:\n",
    "        raise TypeError(\"Image SET type not recognized.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cc9ec242",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pil_to_numpy(images):\n",
    "    '''note: this function will not harm image(s) that are already in numpy format'''\n",
    "    current_type = detect_type(images)\n",
    "        \n",
    "    # Immediately return numpy images\n",
    "    if current_type == 'numpy_set' or current_type == 'numpy_single':\n",
    "        return images\n",
    "    \n",
    "    # Convert single PIL image to NumPy array\n",
    "    elif current_type == 'pil_single':\n",
    "        numpy_img = np.array(images).astype(np.uint8)\n",
    "        return numpy_img\n",
    "    \n",
    "    # Convert set of PIL images to set of NumPy arrays\n",
    "    elif current_type == 'pil_set':\n",
    "        numpy_images = []\n",
    "        for img in images:\n",
    "            numpy_img = np.array(img).astype(np.uint8)\n",
    "            numpy_images.append(numpy_img)\n",
    "        return numpy_images\n",
    "    \n",
    "    else:\n",
    "        print(\"Attempted pil_to_numpy. Image type could not be identified -- data returned unmodified.\")\n",
    "        return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6bd3ca90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def numpy_to_pil(images):\n",
    "    '''note: this function will not harm image(s) that are already in pil format'''\n",
    "    current_type = detect_type(images)\n",
    "    \n",
    "    # Immediately return PIL images\n",
    "    if current_type == 'pil_single' or current_type == 'pil_set':\n",
    "        return images\n",
    "    \n",
    "    # Convert single NumPy array to PIL image\n",
    "    elif current_type == 'numpy_single':\n",
    "        pil_img = Image.fromarray(images.astype(np.uint8))\n",
    "        return pil_img\n",
    "          \n",
    "    # Convert set of NumPy arrays to set of PIL images\n",
    "    elif current_type == 'numpy_set':\n",
    "        pil_images = []\n",
    "        for img in images:\n",
    "            pil_img = Image.fromarray(img.astype(np.uint8))\n",
    "            pil_images.append(pil_img)\n",
    "        return pil_images\n",
    "\n",
    "    else:\n",
    "        print(\"Attempted numpy_to_pil. Image type could not be identified -- data returned unmodified.\")\n",
    "        return images\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "385fd468",
   "metadata": {},
   "source": [
    "[GO TO TOP](#top)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f97309ec",
   "metadata": {},
   "source": [
    "<a id=\"algebraic-manipulations--general-enhancement\"></a>\n",
    "-----------------------------\n",
    "## Algebraic Manipulations & General Enhancement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9bb9a59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98faa0de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3885a481",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18101d71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e07fec7d",
   "metadata": {},
   "source": [
    "[GO TO TOP](#top)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "836ca227",
   "metadata": {},
   "source": [
    "<a id=\"histograms--data-processing\"></a>\n",
    "-----------------------------\n",
    "## Histograms & Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "4db9b530",
   "metadata": {
    "id": "4db9b530"
   },
   "outputs": [],
   "source": [
    "def histogram_stretch(image):\n",
    "    image = pil_to_numpy(image)    # if data is PIL, convert it to NumPy\n",
    "    # np_image = np.array(image).astype(np.uint8)\n",
    "    \n",
    "    # Transformation to obtain stretching\n",
    "\n",
    "    # constant = (255-0)/(np_image.max()-np_image.min())\n",
    "    # img_stretch = np_image * constant\n",
    "    # img_PIL_stretch = Image.fromarray(image_stretch)\n",
    "    img_max = np_image.max()\n",
    "    img_min = np_image.min()\n",
    "    img_stretched = 255*((np_image - img_min)/(img_max - img_min)) #apply stretch\n",
    "    \n",
    "    img_stretched = numpy_to_pil(img_stretched)\n",
    "    \n",
    "    return img_stretched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "075ec8ef",
   "metadata": {
    "id": "075ec8ef"
   },
   "outputs": [],
   "source": [
    "# def histogram_stretch_clip(image, clip_percent=0.0):\n",
    "#     np_image = np.array(image).astype(np.uint8)\n",
    "    \n",
    "#     if clip_percent > 1:\n",
    "#         print(\"please enter the percent as a decimal value. Exe: 0.1 clips 10% of image boundary\")\n",
    "        \n",
    "#     # Calculate the histogram of the image\n",
    "#     hist, _ = np.histogram(np_image, bins=256, range=(0, 255))\n",
    "#     # Calculate the cumulative sum of the histogram\n",
    "#     cumsum = np.cumsum(hist)\n",
    "\n",
    "#     # Determine the number of pixels to clip\n",
    "#     num_pixels = int(clip_percent * np_image.size)\n",
    "    \n",
    "#     # Find the threshold for clipping the top 10% of the histogram\n",
    "#     threshold = np.argmax(cumsum >= cumsum[-1] - num_pixels)\n",
    "\n",
    "#     # Perform histogram stretching\n",
    "#     img_min = np.percentile(np_image, clip_percent*100)\n",
    "#     img_max = threshold\n",
    "#     np_image = (np_image - img_min) * 255 / (img_max - img_min)\n",
    "#     np_image[np_image > 255] = 255\n",
    "#     np_image = np.clip(np_image, 0, 255)\n",
    "\n",
    "#     img_PIL_stretch = Image.fromarray(np_image.astype(np.uint8))\n",
    "#     return img_PIL_stretch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "686fa183",
   "metadata": {},
   "outputs": [],
   "source": [
    "def histogram_stretch_clip(image, clip_percent=0.0):\n",
    "    np_image = pil_to_numpy(image)    # if data is PIL, convert it to NumPy\n",
    "    # np_image = np.array(image).astype(np.uint8)\n",
    "    \n",
    "    if clip_percent > 1:\n",
    "        print(\"please enter the percent as a decimal value. Exe: 0.1 clips 10% of image boundary\")\n",
    "        \n",
    "    # Calculate the histogram of the image\n",
    "    hist, _ = np.histogram(np_image, bins=256, range=(0, 255))\n",
    "    # Calculate the cumulative sum of the histogram\n",
    "    cumsum = np.cumsum(hist)\n",
    "\n",
    "    # Determine the number of pixels to clip\n",
    "    num_pixels = int(clip_percent * np_image.size)\n",
    "    \n",
    "    # Find the threshold for clipping the top 10% of the histogram\n",
    "    threshold = np.argmax(cumsum >= cumsum[-1] - num_pixels)\n",
    "\n",
    "    # Perform histogram stretching\n",
    "    img_min = np.percentile(np_image, clip_percent*100)\n",
    "    img_max = threshold\n",
    "    np_image = (np_image - img_min) * 255 / (img_max - img_min)\n",
    "#     np_image[np_image > 255] = 255\n",
    "    np_image = np.clip(np_image, 0, 255)\n",
    "    \n",
    "    img_stretch_clip = numpy_to_pil(np_image)\n",
    "    \n",
    "    return img_stretch_clip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "acbe5d70",
   "metadata": {
    "id": "acbe5d70"
   },
   "outputs": [],
   "source": [
    "def hist_matching(image, c, c_t):\n",
    "    np_image = np.array(image).astype(np.uint8)\n",
    "\n",
    "    pixels = np.arange(256)\n",
    "    # find closest pixel-matches corresponding to the CDF of the input image, given the value of the CDF H of\n",
    "    # the template image at the corresponding pixels, s.t. c_t = H(pixels) <=> pixels = H-1(c_t)\n",
    "    new_pixels = np.interp(c, c_t, pixels)\n",
    "    im = (np.reshape(new_pixels[np_image.ravel()], np_image.shape)).astype(np.uint8)\n",
    "    \n",
    "    im_PIL = Image.fromarray(im)\n",
    "    \n",
    "    return im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1eeacd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' uses numpy histogram '''\n",
    "''' 2nd fastest 0.144'''\n",
    "def cdf(image, normalize=True):\n",
    "    image = pil_to_numpy(image).astype(np.uint8)\n",
    "\n",
    "    # Calculate the histogram of the image\n",
    "    hist, _ = np.histogram(image.flatten(), bins=256, range=(0, 256))\n",
    "\n",
    "    # Calculate cumulative distribution\n",
    "    cdf = np.zeros_like(hist, dtype=np.float64)\n",
    "    cumsum = 0\n",
    "    for i, h in enumerate(hist):\n",
    "        cumsum += h\n",
    "        cdf[i] = cumsum\n",
    "\n",
    "    # Normalize the CDF \n",
    "    if normalize:\n",
    "        cdf = cdf / cdf[-1]\n",
    "\n",
    "    return cdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02fb49ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Uses numpy histogram and cumsum '''\n",
    "''' 1st fastest 0.128'''\n",
    "def cdf_fast(image, normalize=True):\n",
    "    image = pil_to_numpy(image).astype(np.uint8)\n",
    "\n",
    "    # Calculate histogram of the image\n",
    "    hist, _ = np.histogram(image.flatten(), bins=256, range=(0, 256))\n",
    "\n",
    "    # Calculate cumulative distribution\n",
    "    cdf = np.cumsum(hist).astype(np.float64)\n",
    "    if normalize:\n",
    "        cdf = cdf / cdf[-1]\n",
    "\n",
    "    return cdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e0de1d3",
   "metadata": {
    "id": "4e0de1d3"
   },
   "outputs": [],
   "source": [
    "# def image_distance(image1, image2):\n",
    "#     hist1 = np.array(image1.histogram(), dtype='int64')\n",
    "#     hist2 = np.array(image2.histogram(), dtype='int64')\n",
    "\n",
    "#     # Calculate the distance between the two histograms\n",
    "#     #distance = np.sum(((hist1 - hist2)**2)/(np.maximum(hist1, hist2)))\n",
    "#     distance = euclidean_distances(hist1.reshape(1,-1), hist2.reshape(1,-1))\n",
    "    \n",
    "#     #print(\"Histogram1: \\n\", hist1.reshape(1,-1), \"\\nHistogram2: \\n\", hist2.reshape(1,-1))\n",
    "#     #print(\"\\nDistance = \", distance[0][0])\n",
    "#     print(distance[0][0])\n",
    "    \n",
    "#     return distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "927ddf7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_distance(image1, image2, type='euclidean', display_hist=False):\n",
    "    hist1 = np.array(image1.histogram(), dtype='int64')\n",
    "    hist2 = np.array(image2.histogram(), dtype='int64')\n",
    "    \n",
    "    #display histogram data if desired\n",
    "    if display_hist == True:\n",
    "        print(\"Histogram1: \\n\", hist1.reshape(1,-1), \"\\nHistogram2: \\n\", hist2.reshape(1,-1))\n",
    "        \n",
    "    #if the histograms can't be matched send warning\n",
    "    if len(hist1) != len(hist2):\n",
    "        raise ValueError(\"Histograms must have the same length\")\n",
    "    \n",
    "    distance = 0\n",
    "    if type == 'euclidean': \n",
    "        #calculate distance pixelwise\n",
    "        for i in range(len(hist1)):\n",
    "            distance += (hist1[i] - hist2[i])**2\n",
    "        distance = np.sqrt(distance)\n",
    "    elif type == 'linear':\n",
    "        for i in range(len(hist1)):\n",
    "            distance += np.abs(hist1[i] - hist2[i])\n",
    "        distance /= len(hist1)\n",
    "    else:\n",
    "        print(\"No Distance Calculation Method Specified\")\n",
    "        \n",
    "#     #CHI SQUARED PSEUDOCODE \n",
    "#     distance = 0\n",
    "#     for i in range(len(hist1)):\n",
    "#         distance += (hist1[i] - hist2[i]) ** 2\n",
    "#         distance /= np.max(hist1[i], h2[i])\n",
    "    print(\"Distance = \", distance)\n",
    "    \n",
    "    return distance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0757757b",
   "metadata": {},
   "source": [
    "[GO TO TOP](#top)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e33f5b05",
   "metadata": {},
   "source": [
    "<a id=\"color\"></a>\n",
    "-----------------------------\n",
    "## Color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4269dfba",
   "metadata": {
    "id": "4269dfba"
   },
   "outputs": [],
   "source": [
    "\"\"\"Conversion functions between RGB and other color systems.\n",
    "This modules provides two functions for each color system ABC:\n",
    "  rgb_to_abc(r, g, b) --> a, b, c\n",
    "  abc_to_rgb(a, b, c) --> r, g, b\n",
    "All inputs and outputs are triples of floats in the range [0.0...1.0]\n",
    "(with the exception of I and Q, which covers a slightly larger range).\n",
    "Inputs outside the valid range may cause exceptions or invalid outputs.\n",
    "Supported color systems:\n",
    "RGB: Red, Green, Blue components\n",
    "YIQ: Luminance, Chrominance (used by composite video signals)\n",
    "HLS: Hue, Luminance, Saturation\n",
    "HSV: Hue, Saturation, Value\n",
    "\"\"\"\n",
    "\n",
    "# References:\n",
    "# http://en.wikipedia.org/wiki/YIQ\n",
    "# http://en.wikipedia.org/wiki/HLS_color_space\n",
    "# http://en.wikipedia.org/wiki/HSV_color_space\n",
    "\n",
    "__all__ = [\"rgb_to_yiq\",\"yiq_to_rgb\",\"rgb_to_hls\",\"hls_to_rgb\",\n",
    "           \"rgb_to_hsv\",\"hsv_to_rgb\"]\n",
    "\n",
    "# Some floating point constants\n",
    "\n",
    "ONE_THIRD = 1.0/3.0\n",
    "ONE_SIXTH = 1.0/6.0\n",
    "TWO_THIRD = 2.0/3.0\n",
    "\n",
    "# YIQ: used by composite video signals (linear combinations of RGB)\n",
    "# Y: perceived gray level (0.0 == black, 1.0 == white)\n",
    "# I, Q: color components\n",
    "#\n",
    "# There are a great many versions of the constants used in these formulae.\n",
    "# The ones in this library uses constants from the FCC version of NTSC.\n",
    "\n",
    "def rgb_to_yiq(r, g, b):\n",
    "    y = 0.30*r + 0.59*g + 0.11*b\n",
    "    i = 0.74*(r-y) - 0.27*(b-y)\n",
    "    q = 0.48*(r-y) + 0.41*(b-y)\n",
    "    return (y, i, q)\n",
    "\n",
    "def yiq_to_rgb(y, i, q):\n",
    "    # r = y + (0.27*q + 0.41*i) / (0.74*0.41 + 0.27*0.48)\n",
    "    # b = y + (0.74*q - 0.48*i) / (0.74*0.41 + 0.27*0.48)\n",
    "    # g = y - (0.30*(r-y) + 0.11*(b-y)) / 0.59\n",
    "\n",
    "    r = y + 0.9468822170900693*i + 0.6235565819861433*q\n",
    "    g = y - 0.27478764629897834*i - 0.6356910791873801*q\n",
    "    b = y - 1.1085450346420322*i + 1.7090069284064666*q\n",
    "\n",
    "    if r < 0.0:\n",
    "        r = 0.0\n",
    "    if g < 0.0:\n",
    "        g = 0.0\n",
    "    if b < 0.0:\n",
    "        b = 0.0\n",
    "    if r > 1.0:\n",
    "        r = 1.0\n",
    "    if g > 1.0:\n",
    "        g = 1.0\n",
    "    if b > 1.0:\n",
    "        b = 1.0\n",
    "    return (r, g, b)\n",
    "\n",
    "# HLS: Hue, Luminance, Saturation\n",
    "# H: position in the spectrum\n",
    "# L: color lightness\n",
    "# S: color saturation\n",
    "\n",
    "def rgb_to_hls(r, g, b):\n",
    "    maxc = max(r, g, b)\n",
    "    minc = min(r, g, b)\n",
    "    sumc = (maxc+minc)\n",
    "    rangec = (maxc-minc)\n",
    "    l = sumc/2.0\n",
    "    if minc == maxc:\n",
    "        return 0.0, l, 0.0\n",
    "    if l <= 0.5:\n",
    "        s = rangec / sumc\n",
    "    else:\n",
    "        s = rangec / (2.0-sumc)\n",
    "    rc = (maxc-r) / rangec\n",
    "    gc = (maxc-g) / rangec\n",
    "    bc = (maxc-b) / rangec\n",
    "    if r == maxc:\n",
    "        h = bc-gc\n",
    "    elif g == maxc:\n",
    "        h = 2.0+rc-bc\n",
    "    else:\n",
    "        h = 4.0+gc-rc\n",
    "    h = (h/6.0) % 1.0\n",
    "    return h, l, s\n",
    "\n",
    "def hls_to_rgb(h, l, s):\n",
    "    if s == 0.0:\n",
    "        return l, l, l\n",
    "    if l <= 0.5:\n",
    "        m2 = l * (1.0+s)\n",
    "    else:\n",
    "        m2 = l+s-(l*s)\n",
    "    m1 = 2.0*l - m2\n",
    "    return (_v(m1, m2, h+ONE_THIRD), _v(m1, m2, h), _v(m1, m2, h-ONE_THIRD))\n",
    "\n",
    "def _v(m1, m2, hue):\n",
    "    hue = hue % 1.0\n",
    "    if hue < ONE_SIXTH:\n",
    "        return m1 + (m2-m1)*hue*6.0\n",
    "    if hue < 0.5:\n",
    "        return m2\n",
    "    if hue < TWO_THIRD:\n",
    "        return m1 + (m2-m1)*(TWO_THIRD-hue)*6.0\n",
    "    return m1\n",
    "\n",
    "\n",
    "# HSV: Hue, Saturation, Value\n",
    "# H: position in the spectrum\n",
    "# S: color saturation (\"purity\")\n",
    "# V: color brightness\n",
    "\n",
    "def rgb_to_hsv(r, g, b):\n",
    "    maxc = max(r, g, b)\n",
    "    minc = min(r, g, b)\n",
    "    v = maxc\n",
    "    if minc == maxc:\n",
    "        return 0.0, 0.0, v\n",
    "    s = (maxc-minc) / maxc\n",
    "    rc = (maxc-r) / (maxc-minc)\n",
    "    gc = (maxc-g) / (maxc-minc)\n",
    "    bc = (maxc-b) / (maxc-minc)\n",
    "    if r == maxc:\n",
    "        h = bc-gc\n",
    "    elif g == maxc:\n",
    "        h = 2.0+rc-bc\n",
    "    else:\n",
    "        h = 4.0+gc-rc\n",
    "    h = (h/6.0) % 1.0\n",
    "    return h, s, v\n",
    "\n",
    "def hsv_to_rgb(h, s, v):\n",
    "    if s == 0.0:\n",
    "        return v, v, v\n",
    "    i = int(h*6.0) # XXX assume int() truncates!\n",
    "    f = (h*6.0) - i\n",
    "    p = v*(1.0 - s)\n",
    "    q = v*(1.0 - s*f)\n",
    "    t = v*(1.0 - s*(1.0-f))\n",
    "    i = i%6\n",
    "    if i == 0:\n",
    "        return v, t, p\n",
    "    if i == 1:\n",
    "        return q, v, p\n",
    "    if i == 2:\n",
    "        return p, v, t\n",
    "    if i == 3:\n",
    "        return p, q, v\n",
    "    if i == 4:\n",
    "        return t, p, v\n",
    "    if i == 5:\n",
    "        return v, p, q\n",
    "    # Cannot get here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "01c5cc3d",
   "metadata": {
    "id": "01c5cc3d"
   },
   "outputs": [],
   "source": [
    "def split_display_rgb(image, title, display=False, save=False):\n",
    "    ch_r, ch_g, ch_b = image.split()\n",
    "    \n",
    "    if display==True:\n",
    "        fig = plt.figure()\n",
    "        plt.subplot(1,3,1); plt.imshow(ch_r, cmap=plt.cm.Reds); plt.axis('off')\n",
    "        plt.subplot(1,3,2); plt.imshow(ch_g, cmap=plt.cm.Greens); plt.axis('off')\n",
    "        plt.subplot(1,3,3); plt.imshow(ch_b, cmap=plt.cm.Blues); plt.axis('off')      \n",
    "\n",
    "        if save == True:\n",
    "            _ = fig.savefig(title + '.png', dpi = 300, transparent=True)\n",
    "            \n",
    "        fig.tight_layout()\n",
    "        _ = plt.show()\n",
    "        \n",
    "    return ch_r, ch_g, ch_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4c6dae3b",
   "metadata": {
    "id": "4c6dae3b"
   },
   "outputs": [],
   "source": [
    "def grayscale_average_method(image, title, display=False, save=False):\n",
    "    r, g, b = image.split()\n",
    "    \n",
    "    arr_r = np.array(r)\n",
    "    arr_g = np.array(g)\n",
    "    arr_b = np.array(b)\n",
    "    \n",
    "    \n",
    "    r_mod = (1/3) * arr_r\n",
    "    g_mod = (1/3) * arr_g \n",
    "    b_mod = (1/3) * arr_b\n",
    "    \n",
    "    gray = r_mod + g_mod + b_mod\n",
    "    \n",
    "    gray_PIL = Image.fromarray(gray.astype(np.uint8))\n",
    "    \n",
    "    if display==True:\n",
    "        display_image(gray_PIL)\n",
    "    if save==True:\n",
    "        gray_PIL.save(title + \"_avg.jpg\")\n",
    "    \n",
    "    return gray_PIL  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "26e163e6",
   "metadata": {
    "id": "26e163e6"
   },
   "outputs": [],
   "source": [
    "def grayscale_luminosity_method(image, title, display=False, save=False):  \n",
    "    r, g, b = image.split()\n",
    "    \n",
    "    arr_r = np.array(r)\n",
    "    arr_g = np.array(g)\n",
    "    arr_b = np.array(b)\n",
    "    \n",
    "    r_mod = 0.21 * arr_r\n",
    "    g_mod = 0.72 * arr_g \n",
    "    b_mod = 0.07 * arr_b\n",
    "    \n",
    "#     r_mod = 0.299 * arr_r\n",
    "#     g_mod = 0.587 * arr_g \n",
    "#     b_mod = 0.114 * arr_b\n",
    "    \n",
    "    gray = r_mod + g_mod + b_mod\n",
    "    \n",
    "    gray_PIL = Image.fromarray(gray.astype(np.uint8))\n",
    "    \n",
    "    if display==True:\n",
    "        display_image(gray_PIL)\n",
    "    if save==True:\n",
    "        gray_PIL.save(title + \"_lum.jpg\")\n",
    "    \n",
    "    return gray_PIL  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "06571f4c",
   "metadata": {
    "id": "06571f4c"
   },
   "outputs": [],
   "source": [
    "def grayscale_lum_gamma_method(image, title=None, gamma=2, display=False, save=False):\n",
    "    r, g, b = image.split()\n",
    "    \n",
    "    arr_r = np.array(r)\n",
    "    arr_g = np.array(g)\n",
    "    arr_b = np.array(b)\n",
    "    \n",
    "    r_mod = 0.2126 * (arr_r**gamma)\n",
    "    g_mod = 0.7152 * (arr_g**gamma)\n",
    "    b_mod = 0.0722 * (arr_b**gamma)\n",
    "    \n",
    "    gray = (r_mod + g_mod + b_mod)**(1/gamma)\n",
    "    \n",
    "    gray_PIL = Image.fromarray(gray.astype(np.uint8))    \n",
    "    if display==True:\n",
    "        display_image(gray_PIL)\n",
    "    if save==True:\n",
    "        gray_PIL.save(title + \"_lum_gamma.jpg\")\n",
    "    \n",
    "    return gray_PIL "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cffea722",
   "metadata": {},
   "source": [
    "[GO TO TOP](#top)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08a4186e",
   "metadata": {},
   "source": [
    "<a id=\"noise-addition\"></a>\n",
    "-----------------------------\n",
    "## Noise Addition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8d6fb6e0",
   "metadata": {
    "id": "8d6fb6e0"
   },
   "outputs": [],
   "source": [
    "def addNoise_gaussian(pil_image=None, mode='', alpha=.5, m=0, v=0.1):\n",
    "    if pil_image is not None:\n",
    "        width, height = pil_image.size\n",
    "        base = np.array(pil_image) # Convert the PIL image to a numpy array\n",
    "    else:\n",
    "         # If no image provided, generate a 256x256 base image to use\n",
    "        width = 256\n",
    "        height = 256\n",
    "        base = np.zeros((height, width)) # Create a blank grayscale image\n",
    "    \n",
    "    # Generate Gaussian noise\n",
    "    mean = m\n",
    "    variance = v\n",
    "    sigma = np.sqrt(variance)\n",
    "        \n",
    "    if mode=='grayscale':\n",
    "        gaussian = np.random.normal(mean, sigma, (height, width))\n",
    "        # Scale the Gaussian noise to the range [0, 255]\n",
    "        gaussian = np.interp(gaussian, (gaussian.min(), gaussian.max()), (0, 255)).astype(np.uint8)\n",
    "        # Add the Gaussian noise to the image\n",
    "        combined = (base*(1-alpha) + gaussian*alpha) #.astype(np.uint8)\n",
    "                \n",
    "    if mode=='RGB':\n",
    "        #split by color channel\n",
    "        red = np.random.normal(mean, sigma, (height, width))\n",
    "        green = np.random.normal(mean, sigma, (height, width))\n",
    "        blue = np.random.normal(mean, sigma, (height, width))\n",
    "        # Stack the noise arrays to form an RGB image\n",
    "        noise_stack = np.stack([red, green, blue], axis=-1)\n",
    "        # Scale the noise to the range [0, 255]\n",
    "        noise = np.interp(noise_stack, (noise_stack.min(), noise_stack.max()), (0, 255)).astype(np.uint8)\n",
    "        combined = (alpha * noise + (1 - alpha) * base).astype(np.uint8)\n",
    "\n",
    "    # Convert the numpy array to a PIL image\n",
    "    outimage = Image.fromarray(combined)\n",
    "\n",
    "    # Display the image\n",
    "    #outimage.show()\n",
    "    \n",
    "    return outimage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ec57dc9c",
   "metadata": {
    "id": "ec57dc9c"
   },
   "outputs": [],
   "source": [
    "#  Add salt\n",
    "# and pepper noise to an image\n",
    "#  @param inimg The input image.\n",
    "#  @param q The probability. 0 < q < 1 .\n",
    "#  For each pixel in the image, generate a random number, say r.\n",
    "#       If (r < q), change the pixel's intensity to zero.\n",
    "#       If (r > 1-q), change the pixel's intensity to L\n",
    "#  The higher the q, the worse the noise\n",
    "#  return Image corrupted by salt and pepper noise.\n",
    "\n",
    "def addNoise_sap(pil_image=None, q=.05, w=256, h=256):\n",
    "    # Set seed for random number generator\n",
    "    random.seed(0)\n",
    "\n",
    "    if pil_image is not None:\n",
    "        width, height = pil_image.size\n",
    "        channel_count = len(pil_image.getbands())\n",
    "    else:\n",
    "        # Set image size\n",
    "        width = w\n",
    "        height = h\n",
    "        pil_image = Image.fromarray(np.full((height, width), 128, dtype=np.uint8)) # Create a blank grayscale image\n",
    "        channel_count = 1\n",
    "        \n",
    "    # Create a new output image\n",
    "    outimage = Image.new(pil_image.mode, pil_image.size)\n",
    "\n",
    "    # Add SAP noise to each pixel\n",
    "    for i in range(width):\n",
    "        for j in range(height):\n",
    "            for k in range(channel_count):\n",
    "                r = random.random()\n",
    "                pixel = pil_image.getpixel((i, j))\n",
    "\n",
    "                if r < q:\n",
    "                    outimage.putpixel((i, j), (0,) * channel_count)\n",
    "                elif r > 1 - q:\n",
    "                    outimage.putpixel((i, j), (255,) * channel_count)\n",
    "                else:\n",
    "                    outimage.putpixel((i, j), pixel)\n",
    "\n",
    "    # Display the image\n",
    "    #outimage.show()\n",
    "    \n",
    "    return outimage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4cce87c6",
   "metadata": {
    "id": "4cce87c6"
   },
   "outputs": [],
   "source": [
    "def addNoise_salt_and_pepper(pil_image=None, mode='', s_vs_p=0.5, amount=0.004):\n",
    "    if pil_image is not None:\n",
    "        width, height = pil_image.size\n",
    "        base = np.array(pil_image) # Convert the PIL image to a numpy array\n",
    "    else:\n",
    "        # Set image size\n",
    "        width = 256\n",
    "        height = 256\n",
    "        base = np.full((height, width), 128, dtype=np.uint8) # Create a blank grayscale image\n",
    "        \n",
    "    # Generate salt and pepper noise\n",
    "    noise = np.copy(base)\n",
    "    num_salt = np.ceil(amount * base.size * s_vs_p)\n",
    "    coords = [np.random.randint(0, i - 1, int(num_salt)) for i in base.shape]\n",
    "    noise[coords] = 255\n",
    "\n",
    "    num_pepper = np.ceil(amount* base.size * (1. - s_vs_p))\n",
    "    coords = [np.random.randint(0, i - 1, int(num_pepper)) for i in base.shape]\n",
    "    noise[coords] = 0\n",
    "        \n",
    "    if mode == 'RGB':\n",
    "        noise_stack = np.stack([noise, noise, noise], axis=-1)\n",
    "        noise = noise_stack.astype(np.uint8)\n",
    "\n",
    "    # Convert the numpy array to a PIL image\n",
    "    outimage = Image.fromarray(noise)\n",
    "\n",
    "    # Display the image\n",
    "    #outimage.show()\n",
    "\n",
    "    return outimage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "67a60d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def addNoise_rayleigh(pil_image=None, alpha = .5, scale=1, m=0):\n",
    "    if pil_image is not None:\n",
    "        width, height = pil_image.size\n",
    "        base = np.array(pil_image) # Convert the PIL image to a numpy array\n",
    "    else:\n",
    "        # Set image size\n",
    "        width = 256\n",
    "        height = 256\n",
    "        base = np.full((height, width), 128, dtype=np.uint8) # Create a blank grayscale image\n",
    "    mean = m\n",
    "    \n",
    "    # Convert the numpy array to a PIL image\n",
    "    #temp = Image.fromarray(base)\n",
    "    # Display the image\n",
    "    #temp.show()\n",
    "    \n",
    "    \n",
    "    noise = np.random.rayleigh(scale, size=(width, height))\n",
    "    noise -= mean\n",
    "    #noise *= np.sqrt(var / np.var(noise))\n",
    "    combined = np.uint8(np.clip((alpha * noise + (1 - alpha) * base), 0, 255))\n",
    "    \n",
    "\n",
    "    # Convert the numpy array to a PIL image\n",
    "    outimage = Image.fromarray(combined)\n",
    "    \n",
    "    return outimage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c2ab2f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def addNoise_uniform(pil_image=None, alpha = .5, scale=1, m=0):\n",
    "    if pil_image is not None:\n",
    "        width, height = pil_image.size\n",
    "        base = np.array(pil_image) # Convert the PIL image to a numpy array\n",
    "    else:\n",
    "        # Set image size\n",
    "        width = 256\n",
    "        height = 256\n",
    "        base = np.full((height, width), 128, dtype=np.uint8) # Create a blank grayscale image\n",
    "    mean = m\n",
    "    \n",
    "    # Convert the numpy array to a PIL image\n",
    "    #temp = Image.fromarray(base)\n",
    "    # Display the image\n",
    "    #temp.show()\n",
    "    \n",
    "    \n",
    "    noise = np.random.uniform(scale, size=(width, height))\n",
    "    noise -= mean\n",
    "    #noise *= np.sqrt(var / np.var(noise))\n",
    "    combined = np.uint8(np.clip((alpha * noise + (1 - alpha) * base), 0, 255))\n",
    "    \n",
    "\n",
    "    # Convert the numpy array to a PIL image\n",
    "    outimage = Image.fromarray(combined)\n",
    "   \n",
    "    return outimage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4d974a9",
   "metadata": {},
   "source": [
    "[GO TO TOP](#top)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87bdb08f",
   "metadata": {},
   "source": [
    "<a id=\"filtering-denoising\"></a>\n",
    "-----------------------------\n",
    "## Filtering (Denoising)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2114d451",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_gaussian_kernel(kernel_size=None, sigma=1, display=False):\n",
    "    \n",
    "    if kernel_size is not None:\n",
    "        # Ensure kernel size is odd\n",
    "        if kernel_size % 2 == 0:\n",
    "            print(\"Warning, kernel size has been incremented. Please ensure kernel dimensions are odd.\")\n",
    "            kernel_size += 1\n",
    "    else: \n",
    "        # Auto Calculate the kernel size\n",
    "        kernel_size = int(6 * sigma + 1) | 1\n",
    "    \n",
    "    # Create an empty kernel\n",
    "    kernel = np.zeros((kernel_size, kernel_size))\n",
    "\n",
    "    # Calculate the center of the kernel\n",
    "    center = kernel_size // 2\n",
    "\n",
    "    # Calculate the constant factor for the Gaussian function\n",
    "    factor = 1 / (2 * np.pi * sigma ** 2)\n",
    "\n",
    "    # Populate the kernel with the Gaussian function values\n",
    "    for i in range(kernel_size):\n",
    "        for j in range(kernel_size):\n",
    "            x = i - center\n",
    "            y = j - center\n",
    "            kernel[i, j] = factor * np.exp(-(x ** 2 + y ** 2) / (2 * sigma ** 2))\n",
    "\n",
    "    # Normalize the kernel\n",
    "    kernel /= np.sum(kernel)\n",
    "    \n",
    "    if display:\n",
    "        print(f\"kernel size ({kernel_size}x{kernel_size}), sigma={sigma}:\\n\", kernel)\n",
    "\n",
    "    return kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "4d7c4c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_gaussian(image, sigma = 3, alpha = .5):\n",
    "    # Convert to numpy array\n",
    "    img = np.array(image)\n",
    "\n",
    "    # Apply Gaussian filter\n",
    "    img_blur = cv2.GaussianBlur(img, (0, 0), sigma)\n",
    "    \n",
    "    combined = ((1-alpha)*img) + (alpha * img_blur)\n",
    "\n",
    "    # Convert back to PIL image\n",
    "    filtered_img = Image.fromarray(combined.astype(np.uint8))\n",
    " \n",
    "    return filtered_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdea3827",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_gaussian2(image, sigma=3):\n",
    "    # Convert the input image to a grayscale NumPy array\n",
    "    gray = pil_to_numpy(image)\n",
    "\n",
    "    # Compute the size of the Gaussian kernel\n",
    "    ksize = int(6 * sigma + 1) | 1\n",
    "\n",
    "    # Compute the border size\n",
    "    border = ksize // 2\n",
    "\n",
    "    # Create the Gaussian kernel\n",
    "    x, y = np.meshgrid(np.arange(ksize) - border, np.arange(ksize) - border)\n",
    "    kernel = np.exp(-(x**2 + y**2) / (2 * sigma**2))\n",
    "    kernel /= np.sum(kernel)\n",
    "    \n",
    "    # Pad the image with border pixels\n",
    "    padded = np.pad(gray, border, mode='edge')\n",
    "\n",
    "    # Apply the Gaussian filter to the padded image\n",
    "    filtered = np.zeros_like(gray)\n",
    "    for i in range(gray.shape[0]):\n",
    "        for j in range(gray.shape[1]):\n",
    "            patch = padded[i:i+ksize, j:j+ksize]\n",
    "            filtered[i, j] = np.sum(patch * kernel)\n",
    "\n",
    "    # Convert the filtered image back to a PIL Image\n",
    "    filtered = numpy_to_pil(filtered)\n",
    "\n",
    "    return filtered, kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e56a8a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_gaussian3(image, sigma):\n",
    "    \"\"\"\n",
    "    Applies a Gaussian filter to the input image with the specified sigma value.\n",
    "    Args:\n",
    "        image (PIL.Image): The input image.\n",
    "        sigma (float): The standard deviation of the Gaussian kernel.\n",
    "    Returns:\n",
    "        The filtered image as a NumPy array.\n",
    "    \"\"\"\n",
    "    # Convert the input image to a grayscale NumPy array\n",
    "    gray = pil_to_numpy(image)\n",
    "\n",
    "    # Create a Gaussian kernel with the specified sigma value\n",
    "    size = int(2 * np.ceil(3 * sigma) + 1)\n",
    "    x, y = np.meshgrid(np.linspace(-1, 1, size), np.linspace(-1, 1, size))\n",
    "    kernel = np.exp(-(x**2 + y**2) / (2 * sigma**2))\n",
    "    kernel /= np.sum(kernel)\n",
    "\n",
    "    # Pad the image with reflective padding to avoid boundary effects\n",
    "    pad_size = int(2 * np.ceil(3 * sigma))\n",
    "    padded = np.pad(gray, pad_size, mode='reflect')\n",
    "\n",
    "    # Apply the Gaussian filter to the padded image\n",
    "    filtered = np.zeros_like(gray)\n",
    "    for i in range(gray.shape[0]):\n",
    "        for j in range(gray.shape[1]):\n",
    "            patch = padded[i:i+size, j:j+size]\n",
    "            filtered[i, j] = np.sum(patch * kernel)\n",
    "\n",
    "    # Convert the filtered image back to a PIL Image\n",
    "    filtered = numpy_to_pil(filtered)\n",
    "    \n",
    "    return filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a35a7d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_gaussian4(image, sigma):\n",
    "    \"\"\"\n",
    "    Applies a Gaussian filter to the input image with the specified sigma value.\n",
    "    Args:\n",
    "        image (PIL.Image): The input image.\n",
    "        sigma (float): The standard deviation of the Gaussian kernel.\n",
    "    Returns:\n",
    "        The filtered image as a NumPy array.\n",
    "    \"\"\"\n",
    "    # Convert the input image to a grayscale NumPy array\n",
    "    gray = pil_to_numpy(image)\n",
    "\n",
    "    # Compute the size of the kernel\n",
    "    size = int(2 * np.ceil(3 * sigma) + 1)\n",
    "\n",
    "    # Create the Gaussian kernel\n",
    "    x, y = np.meshgrid(np.linspace(-1, 1, size), np.linspace(-1, 1, size))\n",
    "    kernel = np.exp(-(x**2 + y**2) / (2 * sigma**2))\n",
    "    kernel /= np.sum(kernel)\n",
    "\n",
    "    # Pad the image with symmetric padding to avoid boundary effects\n",
    "    pad_size = size // 2\n",
    "    padded = np.pad(gray, pad_size, mode='symmetric')\n",
    "\n",
    "    # Apply the Gaussian filter to the padded image\n",
    "    filtered = np.zeros_like(gray)\n",
    "    for i in range(gray.shape[0]):\n",
    "        for j in range(gray.shape[1]):\n",
    "            patch = padded[i:i+size, j:j+size]\n",
    "            filtered[i, j] = np.sum(patch * kernel)\n",
    "\n",
    "    # Convert the filtered image back to a PIL Image\n",
    "    filtered = numpy_to_pil(filtered)\n",
    "    return filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb1eccfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_gaussian5(image, sigma):\n",
    "    \"\"\"\n",
    "    Applies a Gaussian filter to the input image with the specified sigma value.\n",
    "    Args:\n",
    "        image (PIL.Image): The input image.\n",
    "        sigma (float): The standard deviation of the Gaussian kernel.\n",
    "    Returns:\n",
    "        The filtered image as a NumPy array.\n",
    "    \"\"\"\n",
    "    # Convert the input image to a grayscale NumPy array\n",
    "    gray = pil_to_numpy(image)\n",
    "\n",
    "    # Create a Gaussian kernel with the specified sigma value\n",
    "    size = int(2 * np.ceil(3 * sigma) + 1)\n",
    "    x, y = np.meshgrid(np.linspace(-1, 1, size), np.linspace(-1, 1, size))\n",
    "    kernel = np.exp(-(x**2 + y**2) / (2 * sigma**2))\n",
    "    kernel /= np.sum(kernel)\n",
    "    \n",
    "    # Pad the image with zeros to avoid border effects\n",
    "    padded = np.pad(gray, size, mode='constant')\n",
    "\n",
    "    # Apply the Gaussian filter to the padded image\n",
    "    filtered = np.zeros_like(gray)\n",
    "    for i in range(gray.shape[0]):\n",
    "        for j in range(gray.shape[1]):\n",
    "            patch = padded[i:i+size, j:j+size]\n",
    "            filtered[i, j] = np.sum(patch * kernel)\n",
    "\n",
    "    # Convert the filtered image back to a PIL Image\n",
    "    filtered = numpy_to_pil(filtered)\n",
    "    return filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5d06e2da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_bilateral(image, title='', sigma_spatial=10, fileName=''):\n",
    "    # Convert image to numpy array\n",
    "    img = np.array(image)\n",
    "    \n",
    "    # Create meshgrid of pixel coordinates\n",
    "    x, y = np.meshgrid(np.arange(img.shape[1]), np.arange(img.shape[0]))\n",
    "    \n",
    "    # Initialize filtered image\n",
    "    filtered_img = np.zeros_like(img)\n",
    "    \n",
    "    # Iterate over each pixel in the image\n",
    "    for i in range(img.shape[0]):\n",
    "        for j in range(img.shape[1]):\n",
    "            # Calculate spatial weights using Euclidean distance\n",
    "            spatial_weights = np.exp(-((x - x[i,j]) ** 2 + (y - y[i,j]) ** 2) / (2 * sigma_spatial ** 2))\n",
    "            \n",
    "            # Calculate range weights using intensity difference\n",
    "            range_weights = np.exp(-(img - img[i,j]) ** 2 / (2 * sigma_spatial ** 2))\n",
    "            \n",
    "            # Calculate combined weights\n",
    "            weights = range_weights * spatial_weights\n",
    "            \n",
    "            # Normalize weights\n",
    "            weight_sum = np.sum(weights)\n",
    "            if weight_sum == 0:\n",
    "                # If the sum of weights is zero, set weights to a uniform distribution\n",
    "                weights = np.ones_like(weights) / weights.size\n",
    "            else:\n",
    "                # Otherwise, normalize weights as usual\n",
    "                weights /= weight_sum\n",
    "            \n",
    "            # Apply weights to image\n",
    "            filtered_img[i,j] = np.sum(weights * img)\n",
    "            \n",
    "    # Convert filtered image back to PIL image\n",
    "    filtered_img = Image.fromarray(filtered_img)\n",
    "    \n",
    "    # Show original and filtered images using matplotlib\n",
    "    fig, axs = plt.subplots(nrows=1, ncols=2, figsize=(10, 5))\n",
    "    plt.axis('off')\n",
    "    axs[0].imshow(img, cmap='gray')\n",
    "    axs[0].set_title(title + ' Noisy')\n",
    "    axs[1].imshow(filtered_img, cmap='gray')\n",
    "    axs[1].set_title(title + ' Filtered (Sigma Spatial = {})'.format(sigma_spatial))\n",
    "        \n",
    "    fig.tight_layout()\n",
    "    _ = fig.savefig(fileName + '.png', dpi = 300, transparent=True)\n",
    "    plt.show()\n",
    "    \n",
    "    return filtered_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9882335d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_bilateral_fast(img, title='', sigma_spatial=10, fileName=''):\n",
    "    # Convert image to numpy array\n",
    "    img = np.array(img)\n",
    "\n",
    "    # Create meshgrid of pixel coordinates\n",
    "    x, y = np.meshgrid(np.arange(img.shape[1]), np.arange(img.shape[0]))\n",
    "\n",
    "    # Initialize filtered image\n",
    "    filtered_img = np.zeros_like(img)\n",
    "\n",
    "    # Calculate spatial weights using Euclidean distance\n",
    "    spatial_weights = np.exp(-((x - x[..., np.newaxis, np.newaxis]) ** 2 + (y - y[..., np.newaxis, np.newaxis]) ** 2) / (2 * sigma_spatial ** 2))\n",
    "\n",
    "    # Iterate over each pixel in the image\n",
    "    for c in range(img.shape[2]):\n",
    "        # Calculate range weights using intensity difference\n",
    "        range_weights = np.exp(-(img - img[..., c][..., np.newaxis, np.newaxis]) ** 2 / (2 * sigma_spatial ** 2))\n",
    "\n",
    "        # Calculate combined weights\n",
    "        weights = range_weights * spatial_weights\n",
    "\n",
    "        # Normalize weights\n",
    "        weight_sum = np.sum(weights, axis=(0, 1))\n",
    "        weights /= weight_sum\n",
    "\n",
    "        # Apply weights to image\n",
    "        filtered_img[..., c] = np.sum(weights * img, axis=(0, 1))\n",
    "\n",
    "    # Convert filtered image back to PIL image\n",
    "    filtered_img = Image.fromarray(filtered_img)\n",
    "\n",
    "    # Show original and filtered images using matplotlib\n",
    "    fig, axs = plt.subplots(nrows=1, ncols=2, figsize=(10, 5))\n",
    "    plt.axis('off')\n",
    "    axs[0].imshow(img, cmap='gray')\n",
    "    axs[0].set_title(title + ' Noisy')\n",
    "    axs[1].imshow(filtered_img, cmap='gray')\n",
    "    axs[1].set_title(title + ' Filtered (Sigma Spatial = {})'.format(sigma_spatial))\n",
    "\n",
    "    fig.tight_layout()\n",
    "    _ = fig.savefig(fileName + '.png', dpi = 300, transparent=True)\n",
    "    plt.show()\n",
    "\n",
    "    return filtered_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3887cb77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_geometric(img, title='', kernel_size=3, fileName=''):\n",
    "    # Convert image to numpy array\n",
    "    img = np.array(img)\n",
    "    \n",
    "    # Initialize filtered image\n",
    "    filtered_img = np.zeros_like(img)\n",
    "    \n",
    "    # Iterate over each pixel in the image\n",
    "    for i in range(img.shape[0]):\n",
    "        for j in range(img.shape[1]):\n",
    "            # Get kernel centered at current pixel\n",
    "            kernel = img[max(0, i-kernel_size//2):min(img.shape[0], i+kernel_size//2+1),\n",
    "                          max(0, j-kernel_size//2):min(img.shape[1], j+kernel_size//2+1)]\n",
    "            # Calculate geometric mean of kernel\n",
    "            kernel_log = np.log(kernel + 0.001)  # add a small constant to avoid zero or negative values\n",
    "            filtered_img[i,j] = np.exp(np.mean(kernel_log))\n",
    "    \n",
    "    # Convert filtered image back to PIL image\n",
    "    filtered_img = Image.fromarray(filtered_img)\n",
    "    \n",
    "    # Show original and filtered images using matplotlib\n",
    "    fig, axs = plt.subplots(nrows=1, ncols=2, figsize=(10, 5))\n",
    "    plt.axis('off')\n",
    "    axs[0].imshow(img, cmap='gray')\n",
    "    axs[0].set_title(title + ' Noisy')\n",
    "    axs[1].imshow(filtered_img, cmap='gray')\n",
    "    axs[1].set_title(title + ' Filtered (Kernel Size = {})'.format(kernel_size))\n",
    "        \n",
    "    fig.tight_layout()\n",
    "    #_ = fig.savefig(fileName + '.png', dpi=300, transparent=True)\n",
    "    plt.show()\n",
    "    \n",
    "    return filtered_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cdc969ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_geo_alpha_trimmed(img, d=10, kernel_size=3):\n",
    "    # Convert image to numpy array\n",
    "    img = np.array(img)\n",
    "    \n",
    "    # Initialize filtered image\n",
    "    filtered_img = np.zeros_like(img)\n",
    "    \n",
    "    # Iterate over each pixel in the image\n",
    "    for i in range(img.shape[0]):\n",
    "        for j in range(img.shape[1]):\n",
    "            # Get kernel centered at current pixel\n",
    "            kernel = img[max(0, i-kernel_size//2):min(img.shape[0], i+kernel_size//2+1),\n",
    "                          max(0, j-kernel_size//2):min(img.shape[1], j+kernel_size//2+1)]\n",
    "            # Sort pixel values in kernel\n",
    "            sorted_kernel = np.sort(kernel.flatten())\n",
    "            # Exclude d/2 largest and d/2 smallest values\n",
    "            trimmed_kernel = sorted_kernel[d//2:-d//2]\n",
    "            # Calculate geometric mean of trimmed kernel\n",
    "            kernel_log = np.log(trimmed_kernel + 0.001)  # add a small constant to avoid zero or negative values\n",
    "            filtered_img[i,j] = np.exp(np.mean(kernel_log))\n",
    "\n",
    "    # Convert filtered image back to PIL image\n",
    "    filtered_img = Image.fromarray(filtered_img)\n",
    "    \n",
    "    return filtered_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e061a143",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_median(data, kernel_size=3, boundary_mode='reflect'):\n",
    "    # Check kernel size is odd\n",
    "    if kernel_size % 2 == 0:\n",
    "        raise ValueError(\"Kernel size must be odd\")\n",
    "    \n",
    "    # Apply median filter with custom parameters\n",
    "    filtered_img = median_filter(data, size=kernel_size, mode=boundary_mode)\n",
    "    \n",
    "    return filtered_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8296becb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_mmm(image, kernel_size=3, filter_type='median'):\n",
    "     # Convert image to numpy array\n",
    "    img = np.array(image)\n",
    "    \n",
    "    # Pad the image with zeros to handle edges\n",
    "    pad_width = kernel_size // 2\n",
    "    padded_image = np.pad(img, pad_width, mode='constant', constant_values=0)\n",
    "    \n",
    "    # Define the filter function based on the filter type\n",
    "    if filter_type == 'median':\n",
    "        filter_func = lambda x: np.median(x)\n",
    "    elif filter_type == 'max':\n",
    "        filter_func = lambda x: np.max(x)\n",
    "    elif filter_type == 'min':\n",
    "        filter_func = lambda x: np.min(x)\n",
    "    else:\n",
    "        raise ValueError('Invalid filter type. Allowed values are \"median\", \"max\", and \"min\".')\n",
    "    \n",
    "    # Apply the filter to each pixel in the image\n",
    "    filtered_image = np.zeros_like(img)\n",
    "    for i in range(img.shape[0]):\n",
    "        for j in range(img.shape[1]):\n",
    "            neighborhood = padded_image[i:i+kernel_size, j:j+kernel_size]\n",
    "            filtered_image[i, j] = filter_func(neighborhood)\n",
    "    \n",
    "    # Crop the image to its original size\n",
    "    cropped_image = filtered_image[pad_width:-pad_width, pad_width:-pad_width]\n",
    "    \n",
    "    # Convert filtered image back to PIL image\n",
    "    filtered_img = Image.fromarray(cropped_image)\n",
    "    \n",
    "    return filtered_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a158f2be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_weighted_moving_avg(image, kernel):\n",
    "     # Convert image to numpy array\n",
    "    img = np.array(image)\n",
    "    \n",
    "    # Get kernel size\n",
    "    kernel_size = len(kernel)\n",
    "\n",
    "    # Pad image to handle borders\n",
    "    pad_width = kernel_size // 2\n",
    "    #padded_image = np.pad(image, ((pad_width, pad_width), (pad_width, pad_width)), mode='edge')\n",
    "    padded_image = np.pad(img, pad_width, mode='constant', constant_values=0)\n",
    "    \n",
    "    # Initialize output image\n",
    "    filtered_image = np.zeros_like(img)\n",
    "\n",
    "    # Apply filter to each pixel\n",
    "    for i in range(img.shape[0]):\n",
    "        for j in range(img.shape[1]):\n",
    "            patch = padded_image[i:i+kernel_size, j:j+kernel_size]\n",
    "            filtered_image[i, j] = np.sum(patch * kernel)\n",
    "            \n",
    "    # Crop the image to its original size\n",
    "    cropped_image = filtered_image[pad_width:-pad_width, pad_width:-pad_width]\n",
    "            \n",
    "    # Convert filtered image back to PIL image\n",
    "    filtered_img = Image.fromarray(cropped_image)\n",
    "    \n",
    "    return filtered_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "27be7dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_alpha_trimmed(img, d=10, kernel_size=3, alpha=0.2):\n",
    "    # Convert image to numpy array\n",
    "    img = np.array(img)\n",
    "    \n",
    "    # Initialize filtered image\n",
    "    filtered_img = np.zeros_like(img)\n",
    "    \n",
    "    # Iterate over each pixel in the image\n",
    "    for i in range(img.shape[0]):\n",
    "        for j in range(img.shape[1]):\n",
    "            # Get kernel centered at current pixel\n",
    "            kernel = img[max(0, i-kernel_size//2):min(img.shape[0], i+kernel_size//2+1),\n",
    "                          max(0, j-kernel_size//2):min(img.shape[1], j+kernel_size//2+1)]\n",
    "            # Sort pixel values in kernel\n",
    "            sorted_kernel = np.sort(kernel.flatten())\n",
    "            # Exclude alpha fraction of the largest and smallest values\n",
    "            trimmed_kernel = sorted_kernel[int(alpha*len(sorted_kernel)):int((1-alpha)*len(sorted_kernel))]\n",
    "            # Calculate mean of trimmed kernel\n",
    "            filtered_img[i,j] = np.mean(trimmed_kernel)\n",
    "\n",
    "    # Convert filtered image back to PIL image\n",
    "    filtered_img = Image.fromarray(filtered_img.astype(np.uint8))\n",
    "    \n",
    "    return filtered_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "357aaf4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_nonlinear(image, alpha=0.2, kernel_size=3):\n",
    "    # Convert image to numpy array\n",
    "    img = np.array(image)\n",
    "    \n",
    "    # Initialize filtered image\n",
    "    filtered_img = np.zeros_like(img)\n",
    "    \n",
    "    # Iterate over each pixel in the image\n",
    "    for i in range(img.shape[0]):\n",
    "        for j in range(img.shape[1]):\n",
    "            # Get kernel centered at current pixel\n",
    "            kernel = img[max(0, i-kernel_size//2):min(img.shape[0], i+kernel_size//2+1),\n",
    "                          max(0, j-kernel_size//2):min(img.shape[1], j+kernel_size//2+1)]\n",
    "            # Sort pixel values in kernel\n",
    "            sorted_kernel = np.sort(kernel.flatten())\n",
    "            # Exclude alpha fraction of the largest and smallest values\n",
    "            trimmed_kernel = sorted_kernel[int(alpha*len(sorted_kernel)):-int(alpha*len(sorted_kernel))]\n",
    "            # Calculate geometric mean of trimmed kernel\n",
    "            kernel_log = np.log(trimmed_kernel + 0.001)  # add a small constant to avoid zero or negative values\n",
    "            filtered_img[i,j] = np.exp(np.mean(kernel_log))\n",
    "\n",
    "    # Convert filtered image back to PIL image\n",
    "    filtered_img = Image.fromarray(filtered_img)\n",
    "    \n",
    "    return filtered_img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dbc4572",
   "metadata": {},
   "source": [
    "[GO TO TOP](#top)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10387660",
   "metadata": {},
   "source": [
    "<a id=\"filtering-sharpening\"></a>\n",
    "-----------------------------\n",
    "## Filtering (Sharpening)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c8763d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "image can be PIL or numpy\n",
    "kernel is a weighted array:\n",
    "    exe   0  2  0\n",
    "          2  5  2\n",
    "          0  2  0\n",
    "alpha is the \"strength\" of the high pass filter's application to the og image\n",
    "'''\n",
    "\n",
    "def sharpen(image, kernel, alpha):\n",
    "    # Convert image to numpy array\n",
    "    img = np.array(image)\n",
    "    \n",
    "    # Normalize kernel weights to sum to 1\n",
    "    #kernel = kernel / (np.sum(kernel)+1e-8) #add small const to prevent divide by 0\n",
    "    \n",
    "    # Pad the image with zeros to handle edges\n",
    "    pad_width = len(kernel) // 2\n",
    "    padded_image = np.pad(img, pad_width, mode='constant', constant_values=0)\n",
    "    \n",
    "    # Apply the kernel to each pixel in the image\n",
    "    filtered_image = np.zeros_like(img)\n",
    "    for i in range(img.shape[0]):\n",
    "        for j in range(img.shape[1]):\n",
    "            neighborhood = padded_image[i:i+len(kernel), j:j+len(kernel)]\n",
    "            filtered_image[i, j] = np.sum(neighborhood * kernel)\n",
    "    \n",
    "    # Subtract the filtered image from the original to get the high-pass filtered image\n",
    "    highpass_image = img - filtered_image\n",
    "    \n",
    "    # Add the high-pass filtered image back to the original with a weight of 0.5 to create the sharpened image\n",
    "    sharpened_image = ((1-alpha)*img) + (alpha * highpass_image)\n",
    "    \n",
    "    # Convert filtered image back to PIL image\n",
    "    sharpened_img = Image.fromarray(sharpened_image)\n",
    "    \n",
    "    return sharpened_img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5980e5fb",
   "metadata": {
    "id": "5980e5fb"
   },
   "source": [
    "-----------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88514bba",
   "metadata": {},
   "source": [
    "[GO TO TOP](#top)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0ebcf25",
   "metadata": {
    "id": "a0ebcf25"
   },
   "source": [
    "<a id=\"thresholding--object-detection\"></a>\n",
    "## Thresholding | Object Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f05fb1f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_threshold(image, T):\n",
    "    # Convert PIL image to numpy array if necessary\n",
    "    if isinstance(image, Image.Image) and image.mode != 'L':\n",
    "        image = pil_to_numpy(image.convert('L'))\n",
    "    else:\n",
    "        image = pil_to_numpy(image)\n",
    "        \n",
    "    # Apply thresholding using boolean indexing\n",
    "    thresholded_image = np.zeros_like(image)\n",
    "    thresholded_image[image > T] = 255\n",
    "\n",
    "    # Convert to PIL type\n",
    "    thresholded_image = Image.fromarray(thresholded_image.astype('uint8'))\n",
    "\n",
    "    return thresholded_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "732b3965",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_threshold(image, *T):\n",
    "    # Convert PIL image to numpy array if necessary\n",
    "    if isinstance(image, Image.Image) and image.mode != 'L':\n",
    "        image = pil_to_numpy(image.convert('L'))\n",
    "    else:\n",
    "        image = pil_to_numpy(image)\n",
    "\n",
    "    # Initialize output image\n",
    "    thresholded_image = np.zeros_like(image)\n",
    "\n",
    "    # Calculate threshold values as average of closest T values\n",
    "    thresholds = [0] * (len(T) + 1)\n",
    "    for i in range(len(T) + 1):\n",
    "        if i == 0:\n",
    "            thresholds[i] = T[i] / 2\n",
    "        elif i == len(T):\n",
    "            thresholds[i] = (T[i-1] + 255) / 2\n",
    "        else:\n",
    "            thresholds[i] = (T[i-1] + T[i]) / 2\n",
    "\n",
    "    # Create threshold categories\n",
    "    for i in range(len(thresholds) - 1):\n",
    "        threshold_min = thresholds[i]\n",
    "        threshold_max = thresholds[i+1]\n",
    "        threshold_value = (threshold_min + threshold_max) // 2\n",
    "        thresholded_image[(image >= threshold_min) & (image < threshold_max)] = threshold_value\n",
    "    # Convert to PIL type\n",
    "    thresholded_image = Image.fromarray(thresholded_image.astype('uint8'))\n",
    "\n",
    "    return thresholded_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "65125230",
   "metadata": {},
   "outputs": [],
   "source": [
    "def threshold_moving_average(image, neighborhood=21, weight=.5):\n",
    "    # Convert image to grayscale\n",
    "    img = np.array(image)\n",
    "\n",
    "    # Define the neighborhood for thresholding\n",
    "    win_size = neighborhood\n",
    "\n",
    "    # Define the weight parameter for threshold calculation\n",
    "    k = weight\n",
    "\n",
    "    # Apply moving average thresholding\n",
    "    th = np.zeros_like(img)\n",
    "    for i in range(img.shape[0]):\n",
    "        for j in range(img.shape[1]):\n",
    "            # Calculate the local threshold using the moving average\n",
    "            mean = np.mean(img[max(0, i-win_size//2):min(img.shape[0], i+win_size//2+1), max(0, j-win_size//2):min(img.shape[1], j+win_size//2+1)])\n",
    "            th_val = mean * (1 + k)\n",
    "\n",
    "            # Apply thresholding\n",
    "            if img[i,j] > th_val:\n",
    "                th[i,j] = 255\n",
    "            else:\n",
    "                th[i,j] = 0\n",
    "\n",
    "    # Convert back to PIL Image\n",
    "    th = Image.fromarray(th)\n",
    "\n",
    "    return th"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8693df63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def threshold_gaussian(image, neighborhood=21, sigma=3, k=0.1):\n",
    "    # Define the image and kernel\n",
    "    img = np.array(image)\n",
    "    kernel = np.zeros((neighborhood, neighborhood))\n",
    "    center = neighborhood // 2\n",
    "\n",
    "    # Create a Gaussian kernel\n",
    "    for i in range(neighborhood):\n",
    "        for j in range(neighborhood):\n",
    "            kernel[i,j] = np.exp(-((i-center)**2 + (j-center)**2)/(2*sigma**2))\n",
    "\n",
    "    # Normalize the kernel\n",
    "    kernel /= np.sum(kernel)\n",
    "\n",
    "    # Add padding to the image\n",
    "    pad_size = neighborhood // 2\n",
    "    img_padded = np.pad(img, ((pad_size, pad_size), (pad_size, pad_size)), mode='reflect')\n",
    "\n",
    "    # Apply Gaussian filtering to the padded image\n",
    "    img_filtered = gaussian_filter(img_padded, sigma=sigma)\n",
    "\n",
    "    # Apply adaptive thresholding\n",
    "    thresholded = np.zeros_like(img)\n",
    "    for i in range(img.shape[0]):\n",
    "        for j in range(img.shape[1]):\n",
    "            # Calculate the threshold\n",
    "            threshold = k * np.mean(kernel * img_filtered[i:i+neighborhood, j:j+neighborhood])\n",
    "\n",
    "            # Apply thresholding\n",
    "            if img[i,j] > threshold:\n",
    "                thresholded[i,j] = 255\n",
    "            else:\n",
    "                thresholded[i,j] = 0\n",
    "\n",
    "    thresholded = Image.fromarray(thresholded)\n",
    "    return thresholded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b5d489a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def professor_provided_thresholding(image):\n",
    "    if image is None:\n",
    "        print(\"file could not be read, check with os.path.\")\n",
    "    img = image\n",
    "    img = cv2.medianBlur(img, 5)\n",
    "    th1 = cv2.adaptiveThreshold(img, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 11, 2)\n",
    "    th2 = cv2.adaptiveThreshold(img, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 2)\n",
    "    th3 = cv2.threshold(img, 127, 255, cv2.THRESH_BINARY_INV)\n",
    "\n",
    "    titles = ['Original Image', 'Adaptive Mean Thresholding', 'Adaptive Gaussian Thresholding', 'Global Thresholding']\n",
    "\n",
    "    images = [img, th1, th2, th3]\n",
    "\n",
    "    for i in range(4):\n",
    "        plt.subplot(2,2,i+1)\n",
    "        plt.imshow(images[i], cmap='gray')\n",
    "        plt.title(titles[i])\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "    plt.imshow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aa0edf44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def otsu_best_threshold(image):\n",
    "    if isinstance(image, np.ndarray):\n",
    "        # If image is a NumPy array, do nothing\n",
    "        im = image  \n",
    "    elif isinstance(image, Image.Image) and image.mode == 'L':\n",
    "        # If image is a PIL Image object, convert it to a NumPy array\n",
    "        im = pil_to_numpy(image)\n",
    "    else:\n",
    "        raise ValueError(\"Image format not supported. Please provide a NumPy array or a PIL Image object.\")\n",
    "        \n",
    "    threshold_range = np.arange(np.max(im)+1)\n",
    "    criterias = []\n",
    "    \n",
    "    for th in threshold_range:\n",
    "        # create the thresholded image\n",
    "        thresholded_im = np.zeros(im.shape)\n",
    "        thresholded_im[im >= th] = 1\n",
    "\n",
    "        # compute weights\n",
    "        nb_pixels = im.size\n",
    "        nb_pixels1 = np.count_nonzero(thresholded_im)\n",
    "        weight1 = nb_pixels1 / nb_pixels\n",
    "        weight0 = 1 - weight1\n",
    "\n",
    "        # if one the classes is empty, eg all pixels are below or above the threshold, that threshold will not be considered\n",
    "        # in the search for the best threshold\n",
    "        if weight1 == 0 or weight0 == 0:\n",
    "            continue\n",
    "\n",
    "        # find all pixels belonging to each class\n",
    "        val_pixels1 = im[thresholded_im == 1]\n",
    "        val_pixels0 = im[thresholded_im == 0]\n",
    "\n",
    "        # compute variance of these classes\n",
    "        var0 = np.var(val_pixels0) if len(val_pixels0) > 0 else 0\n",
    "        var1 = np.var(val_pixels1) if len(val_pixels1) > 0 else 0\n",
    "        criterias.append(weight0 * var0 + weight1 * var1)\n",
    "        \n",
    "    # best threshold is the one minimizing the Otsu criteria    \n",
    "    best_thresh = np.argmin(criterias)\n",
    "    \n",
    "    return best_thresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c7794a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def otsu_best_threshold(image):\n",
    "    if isinstance(image, np.ndarray):\n",
    "        # If image is a NumPy array, do nothing\n",
    "        im = image  \n",
    "    elif isinstance(image, Image.Image) and image.mode == 'L':\n",
    "        # If image is a PIL Image object, convert it to a NumPy array\n",
    "        im = pil_to_numpy(image)\n",
    "    else:\n",
    "        raise ValueError(\"Image format not supported. Please provide a NumPy array or a PIL Image object.\")\n",
    "        \n",
    "    # Compute histogram of the image using cv2\n",
    "    hist = cv2.calcHist([im], [0], None, [256], [0, 256]).flatten()\n",
    "    nb_pixels = im.size\n",
    "\n",
    "    # Compute cumulative sum of the histogram\n",
    "    cum_hist = np.cumsum(hist)\n",
    "    cum_hist_inv = np.cumsum(hist[::-1])[::-1]\n",
    "\n",
    "    # Compute cumulative mean, avoiding division by zero\n",
    "    cum_mean = np.cumsum(hist * np.arange(256)) / np.maximum(cum_hist, 1)\n",
    "    cum_mean_inv = (np.cumsum((hist * np.arange(256))[::-1])[::-1]) / np.maximum(cum_hist_inv, 1)\n",
    "\n",
    "    # Compute inter-class variance\n",
    "    variance = cum_hist[:-1] * cum_hist_inv[1:] * (cum_mean[:-1] - cum_mean_inv[1:])**2\n",
    "\n",
    "    # Find threshold that maximizes inter-class variance\n",
    "    best_thresh = np.argmax(variance)\n",
    "    \n",
    "    return best_thresh\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb4b3d5a",
   "metadata": {},
   "source": [
    "[GO TO TOP](#top)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48cfc473",
   "metadata": {},
   "source": [
    "<a id=\"niblack-bernsen-sauvola\"></a>\n",
    "### Niblack, Bernsen, Sauvola"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "842212c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def threshold_niblack(image, neighborhood = 21, weight = -0.2):\n",
    "    #define our image\n",
    "    img = np.array(image.convert('L'))\n",
    "    # Define the neighborhood for thresholding\n",
    "    win_size = neighborhood\n",
    "    # Define the weight parameter for threshold calculation\n",
    "    k = weight\n",
    "\n",
    "    # Apply Niblack thresholding\n",
    "    th = np.zeros_like(img)\n",
    "    for i in range(img.shape[0]):\n",
    "        for j in range(img.shape[1]):\n",
    "            # Calculate the local threshold using mean and standard deviation\n",
    "            mean, std_dev = cv2.meanStdDev(img[max(0, i-win_size//2):min(img.shape[0], i+win_size//2+1),\n",
    "                                               max(0, j-win_size//2):min(img.shape[1], j+win_size//2+1)])\n",
    "            th_val = mean + k * std_dev\n",
    "\n",
    "            # Apply thresholding\n",
    "            if img[i,j] > th_val:\n",
    "                th[i,j] = 255\n",
    "            else:\n",
    "                th[i,j] = 0\n",
    "    th = Image.fromarray(th)\n",
    "    return th"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c96b8316",
   "metadata": {},
   "outputs": [],
   "source": [
    "def threshold_sauvola(image, neighborhood = 21, weight = -0.2):\n",
    "    #define our image\n",
    "    img = np.array(image)\n",
    "    # Define the neighborhood for thresholding\n",
    "    win_size = neighborhood\n",
    "    # Define the weight parameter for threshold calculation\n",
    "    k = weight\n",
    "\n",
    "    # Define the R parameter for threshold calculation\n",
    "    R = 128\n",
    "\n",
    "    # Apply Sauvola thresholding\n",
    "    th = np.zeros_like(img)\n",
    "    for i in range(img.shape[0]):\n",
    "        for j in range(img.shape[1]):\n",
    "            # Calculate the local threshold using mean and standard deviation\n",
    "            mean, std_dev = cv2.meanStdDev(img[max(0, i-win_size//2):min(img.shape[0], i+win_size//2+1),\n",
    "                                               max(0, j-win_size//2):min(img.shape[1], j+win_size//2+1)])\n",
    "            th_val = mean * (1 + k * ((std_dev / R) - 1))\n",
    "\n",
    "            # Apply thresholding\n",
    "            if img[i,j] > th_val:\n",
    "                th[i,j] = 255\n",
    "            else:\n",
    "                th[i,j] = 0\n",
    "\n",
    "    th = Image.fromarray(th)\n",
    "    return th"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "65b10909",
   "metadata": {},
   "outputs": [],
   "source": [
    "def threshold_bernsen(image, neighborhood=21, contrast_threshold=15):\n",
    "    # Convert the image to grayscale\n",
    "    img = np.array(image)\n",
    "\n",
    "    # Apply Bernsen thresholding\n",
    "    th = np.zeros_like(img)\n",
    "    for i in range(img.shape[0]):\n",
    "        for j in range(img.shape[1]):\n",
    "            # Calculate the local contrast using the min and max pixel values in the neighborhood\n",
    "            window_min = np.min(img[max(0, i-neighborhood//2):min(img.shape[0], i+neighborhood//2+1),\n",
    "                                     max(0, j-neighborhood//2):min(img.shape[1], j+neighborhood//2+1)])\n",
    "            window_max = np.max(img[max(0, i-neighborhood//2):min(img.shape[0], i+neighborhood//2+1),\n",
    "                                     max(0, j-neighborhood//2):min(img.shape[1], j+neighborhood//2+1)])\n",
    "            contrast = window_max - window_min\n",
    "\n",
    "            # Apply thresholding based on local contrast\n",
    "            if contrast < contrast_threshold:\n",
    "                threshold = 255 // 2\n",
    "            else:\n",
    "                threshold = (window_min + window_max) // 2\n",
    "\n",
    "            # Apply thresholding\n",
    "            if img[i,j] > threshold:\n",
    "                th[i,j] = 255\n",
    "            else:\n",
    "                th[i,j] = 0\n",
    "\n",
    "    th = Image.fromarray(th)\n",
    "    return th"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f818afa4",
   "metadata": {},
   "source": [
    "[GO TO TOP](#top)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "736fb5a3",
   "metadata": {},
   "source": [
    "<a id=\"convolution--edge-detection\"></a>\n",
    "-----------------------------\n",
    "## Convolution & Edge Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "fbd7b4f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "GENERAL CONVOLUTION - Grayscale Only\n",
    "Takes:\n",
    "    - img: PIL or numpy array\n",
    "    - kernel (numpy.ndarray): A nxn kernel as a NumPy array.\n",
    "Returns:\n",
    "    - PIL Image\n",
    "'''\n",
    "def convolve_image(image, kernel, save=False, title=''):\n",
    "    img = np.array(image)\n",
    "    height, width = img.shape\n",
    "    k_height, k_width = kernel.shape\n",
    "\n",
    "    #Zero-Padding\n",
    "    pad_height = k_height // 2\n",
    "    pad_width = k_width // 2\n",
    "    padded = np.pad(img, ((pad_height, pad_height), (pad_width, pad_width)), mode='constant')\n",
    "    # Initialize the output image with zeros\n",
    "    output = np.zeros((height, width))\n",
    "\n",
    "    for i in range(height):\n",
    "        for j in range(width):\n",
    "            # Get the corresponding region in the padded image\n",
    "            region = padded[i:i+k_height, j:j+k_width]\n",
    "            # Perform element-wise multiplication between the region and the kernel\n",
    "            result = region * kernel\n",
    "            # Calculate the sum of the resulting matrix\n",
    "            output[i, j] = np.sum(result)\n",
    "            \n",
    "    #Trim zero-padded pixels\n",
    "#     output = output[pad_height:height+pad_height, pad_width:width+pad_width]\n",
    "\n",
    "    image_convoluted = Image.fromarray(output)\n",
    "    \n",
    "    if save == True:\n",
    "        _ = fig.savefig(title + '.png', dpi = 300, transparent=True)\n",
    "        \n",
    "    return image_convoluted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "3fe39413",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolve_image_gradient(image, x_kernel, y_kernel):\n",
    "    img = np.array(image)\n",
    "    height, width = img.shape\n",
    "    k_height, k_width = x_kernel.shape\n",
    "    assert x_kernel.shape == y_kernel.shape\n",
    "\n",
    "    #Zero-Padding\n",
    "    pad_height = k_height // 2\n",
    "    pad_width = k_width // 2\n",
    "    padded = np.pad(img, ((pad_height, pad_height), (pad_width, pad_width)), mode='constant')\n",
    "    \n",
    "    # Initialize the output images with zeros\n",
    "    x_output = np.zeros((height, width))\n",
    "    y_output = np.zeros((height, width))\n",
    "\n",
    "    for i in range(height):\n",
    "        for j in range(width):\n",
    "            # Get the corresponding region in the padded image\n",
    "            region = padded[i:i+k_height, j:j+k_width]\n",
    "            # Perform element-wise multiplication between the region and the x_kernel\n",
    "            x_result = region * x_kernel\n",
    "            # Perform element-wise multiplication between the region and the y_kernel\n",
    "            y_result = region * y_kernel\n",
    "            # Calculate the sum of the resulting matrices\n",
    "            x_output[i, j] = np.sum(x_result)\n",
    "            y_output[i, j] = np.sum(y_result)\n",
    "            \n",
    "    #Trim zero-padded pixels\n",
    "    x_output = x_output[pad_height:height+pad_height, pad_width:width+pad_width]\n",
    "    y_output = y_output[pad_height:height+pad_height, pad_width:width+pad_width]\n",
    "\n",
    "    x_difference = Image.fromarray(x_output)\n",
    "    y_difference = Image.fromarray(y_output)\n",
    "\n",
    "    return x_difference, y_difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "c3f5bb38",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sobel display\n",
    "def process_image_with_sobel(im, threshold_values, display=False, save=False):\n",
    "    # Convert input image to grayscale\n",
    "    im_gray = im.convert('L')\n",
    "    \n",
    "    # Compute x and y gradients using Sobel operator\n",
    "    x_diff, y_diff = convolve_image_gradient(im_gray, kernel3x3_sobel_x, kernel3x3_sobel_y)\n",
    "    if save == True:\n",
    "        save_image(x_diff, 'sobel_x')\n",
    "        save_image(y_diff, 'sobel_y')\n",
    "    \n",
    "    # Compute gradient magnitude and maximum\n",
    "    x_diff_np = np.array(x_diff)\n",
    "    y_diff_np = np.array(y_diff)\n",
    "    gradient_mag = ((x_diff_np**2) + (y_diff_np**2))**.5\n",
    "    gradient_max = np.maximum(x_diff_np, y_diff_np)\n",
    "    if save == True: \n",
    "        save_image(gradient_mag, 'sobel_mag')\n",
    "        save_image(gradient_max, 'sobel_max')\n",
    "    \n",
    "    # Compute the gradient direction in degrees\n",
    "    direction = np.degrees(np.arctan2(y_diff_np, x_diff_np))\n",
    "    grad_dir_PIL = Image.fromarray(direction.astype(np.uint8))\n",
    "    if save == True:\n",
    "        save_image(grad_dir_PIL, 'grad_direction_in_deg')\n",
    "    \n",
    "    # Apply thresholding to gradient magnitude and maximum for each threshold value\n",
    "    for threshold in threshold_values:\n",
    "        sobel_mag = single_threshold(Image.fromarray(gradient_mag), threshold)\n",
    "        sobel_max = single_threshold(Image.fromarray(gradient_max), threshold)\n",
    "        \n",
    "        # Save thresholded images with descriptive filenames\n",
    "        sobel_mag_filename = f'sobel_mag_T{threshold}'\n",
    "        sobel_max_filename = f'sobel_max_T{threshold}'\n",
    "        if save == True:\n",
    "            save_image(sobel_mag, sobel_mag_filename)\n",
    "            save_image(sobel_max, sobel_max_filename)\n",
    "        \n",
    "        # Display thresholded images using display_pair function\n",
    "        if display == True: \n",
    "            display_pair(sobel_mag, f'sobel mag T{threshold}', save, 6, 2)\n",
    "            display_pair(sobel_max, f'sobel max T{threshold}', save, 6, 2)\n",
    "        \n",
    "    return sobel_max, sobel_mag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "0b7d6ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #sobel display\n",
    "# def process_image_with_sobel(image, threshold_values, display=False, save=False):\n",
    "#     np_image = pil_to_numpy(image)\n",
    "    \n",
    "#     # Compute x and y gradients using Sobel operator\n",
    "#     x_diff, y_diff = convolve_image_gradient(np_image, kernel3x3_sobel_x, kernel3x3_sobel_y)\n",
    "#     if save == True: \n",
    "#         save_image(x_diff, 'sobel_x.jpg')\n",
    "#         save_image(y_diff, 'sobel_y.jpg')\n",
    "    \n",
    "#     # Compute gradient magnitude and maximum\n",
    "#     x_diff_np = pil_to_numpy(x_diff)\n",
    "#     y_diff_np = pil_to_numpy(y_diff)\n",
    "#     gradient_mag = ((x_diff_np**2) + (y_diff_np**2))**.5\n",
    "#     gradient_max = np.maximum(x_diff_np, y_diff_np)\n",
    "#     if save == True: \n",
    "#         save_image(gradient_mag, 'sobel_mag.jpg')\n",
    "#         save_image(gradient_max, 'sobel_max.jpg')\n",
    "    \n",
    "#     # Compute the gradient direction in degrees\n",
    "#     direction = np.degrees(np.arctan2(y_diff_np, x_diff_np))\n",
    "    \n",
    "#     # More PIL conversion\n",
    "#     gradient_mag_PIL = numpy_to_pil(gradient_mag)\n",
    "#     gradient_max_PIL = numpy_to_pil(gradient_max)\n",
    "#     grad_dir_PIL = numpy_to_pil(direction.astype(np.uint8))\n",
    "#     if save == True:\n",
    "#         save_image(grad_dir_PIL, 'grad_direction_in_deg.jpg')\n",
    "    \n",
    "#     # Apply thresholding to gradient magnitude and maximum for each threshold value\n",
    "#     for threshold in threshold_values:\n",
    "#         sobel_mag = single_threshold(gradient_mag_PIL, threshold)\n",
    "#         sobel_max = single_threshold(gradient_max_PIL, threshold)\n",
    "        \n",
    "#         # Save thresholded images with descriptive filenames\n",
    "#         sobel_mag_filename = f'sobel_mag_T{threshold}.jpg'\n",
    "#         sobel_max_filename = f'sobel_max_T{threshold}.jpg'\n",
    "#         if save == True:\n",
    "#             save_image(sobel_mag, sobel_mag_filename)\n",
    "#             save_image(sobel_max, sobel_max_filename)\n",
    "        \n",
    "#         # Display thresholded images using display_pair function\n",
    "#         if display == True:\n",
    "#             display_pair(sobel_mag, f'sobel mag T{threshold}', 6, 2, save)\n",
    "#             display_pair(sobel_max, f'sobel max T{threshold}', 6, 2, save)\n",
    "        \n",
    "#     return sobel_max, sobel_mag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "5981f0d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sobel display\n",
    "def process_batch_with_sobel(images, threshold_values, set='', display=False):\n",
    "    \n",
    "    # Convert input image to grayscale\n",
    "    sobelmax = []\n",
    "    \n",
    "    for image in images:\n",
    "        # Compute x and y gradients using Sobel operator\n",
    "        x_diff, y_diff = convolve_image_gradient(image, kernel3x3_sobel_x, kernel3x3_sobel_y)\n",
    "        save_image(x_diff, 'sobel_x')\n",
    "        save_image(y_diff, 'sobel_y')\n",
    "\n",
    "        # Compute gradient magnitude and maximum\n",
    "        x_diff_np = np.array(x_diff)\n",
    "        y_diff_np = np.array(y_diff)\n",
    "        gradient_mag = ((x_diff_np**2) + (y_diff_np**2))**.5\n",
    "        gradient_max = np.maximum(x_diff_np, y_diff_np)\n",
    "#         save_image(gradient_mag, 'sobel_mag')\n",
    "#         save_image(gradient_max, 'sobel_max')\n",
    "        \n",
    "        # Compute the gradient direction in degrees\n",
    "        direction = np.degrees(np.arctan2(y_diff_np, x_diff_np))\n",
    "        grad_dir_PIL = Image.fromarray(direction.astype(np.uint8))\n",
    "#         save_image(grad_dir_PIL, 'grad_direction_in_deg')\n",
    "\n",
    "        # Apply thresholding to gradient magnitude and maximum for each threshold value\n",
    "        for threshold in threshold_values:\n",
    "            sobel_mag = single_threshold(Image.fromarray(gradient_mag), threshold)\n",
    "            sobel_max = single_threshold(Image.fromarray(gradient_max), threshold)\n",
    "            \n",
    "            sobelmax.append(sobel_max)\n",
    "            \n",
    "            # Save thresholded images with descriptive filenames\n",
    "#             sobel_mag_filename = f'sobel_mag_T{threshold}'\n",
    "#             sobel_max_filename = f'sobel_max_T{threshold}'\n",
    "#             save_image(sobel_mag, sobel_mag_filename)\n",
    "#             save_image(sobel_max, sobel_max_filename)\n",
    "\n",
    "            # Display thresholded images using display_pair function\n",
    "#             display_pair(sobel_mag, f'sobel mag T{threshold}', thresh_save_status, 6, 2)\n",
    "            if display == True:\n",
    "                display_pair(sobel_max, f'sobel max T{threshold}', False, 6, 2)\n",
    "        \n",
    "    return sobelmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "dcac1cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image_with_gaussian(image, sigma = 1, alpha=1, threshold_values=[40,80]):\n",
    "    # convert to grayscale\n",
    "#     image_gray = image.convert('L')\n",
    "\n",
    "    # Apply Gaussian blurring\n",
    "    blurred = filter_gaussian(image_gray, sigma, alpha)\n",
    "    save_image(blurred, f'blurred_S{sigma}.jpg')\n",
    "    display_image(blurred)\n",
    "\n",
    "    # Apply Sobel convolution\n",
    "    x_diff, y_diff = convolve_image_gradient(blurred, kernel3x3_sobel_x, kernel3x3_sobel_y)\n",
    "    save_image(x_diff, 'x_diff_gauss.jpg')\n",
    "    save_image(y_diff, 'y_diff_gauss.jpg')\n",
    "\n",
    "    # Compute the gradient magnitude\n",
    "    x_diff_np = np.array(x_diff)\n",
    "    y_diff_np = np.array(y_diff)\n",
    "    gradient_mag = ((x_diff_np ** 2) + (y_diff_np ** 2)) ** 0.5\n",
    "    gradient_mag_PIL = Image.fromarray(gradient_mag)\n",
    "    save_image(gradient_mag_PIL, 'grad_magnitude.jpg')\n",
    "\n",
    "    \n",
    "\n",
    "    # Compute the gradient direction in degrees\n",
    "    grad_dir = np.degrees(np.arctan2(y_diff_np, x_diff_np))\n",
    "    grad_dir_PIL = Image.fromarray(grad_dir.astype(np.uint8))\n",
    "    save_image(grad_dir_PIL, 'grad_direction_in_deg.jpg')\n",
    "\n",
    "    # Loop over threshold values and apply thresholding\n",
    "    for threshold in threshold_values:\n",
    "        thresholded = single_threshold(gradient_mag_PIL, threshold)\n",
    "        save_image(thresholded, f'grad_mag_thresh{threshold}.jpg')\n",
    "        display_image(thresholded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "a53b9034",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image_with_canny(image, sigma = 0.75, alpha=1, threshold_low_values=[40,80], threshold_high_values=[120, 200]):\n",
    "    # convert to grayscale\n",
    "    image_gray = image.convert('L')\n",
    "\n",
    "    # Apply Gaussian blurring\n",
    "    blurred = filter_gaussian(image_gray, sigma, alpha)\n",
    "    save_image(blurred, f'blurred_S{sigma}.jpg')\n",
    "    display_image(blurred)\n",
    "    blurred = np.array(blurred)\n",
    "\n",
    "    # Apply Sobel convolution\n",
    "    x_diff, y_diff = convolve_image_gradient(blurred, kernel3x3_sobel_x, kernel3x3_sobel_y)\n",
    "    save_image(x_diff, 'x_diff_gauss.jpg')\n",
    "    save_image(y_diff, 'y_diff_gauss.jpg')\n",
    "\n",
    "    # Compute the gradient magnitude\n",
    "    x_diff_np = np.array(x_diff)\n",
    "    y_diff_np = np.array(y_diff)\n",
    "    gradient_mag = ((x_diff_np ** 2) + (y_diff_np ** 2)) ** 0.5\n",
    "    gradient_mag_PIL = Image.fromarray(gradient_mag)\n",
    "    save_image(gradient_mag_PIL, 'grad_magnitude.jpg')\n",
    "\n",
    "    # Compute the gradient direction in degrees\n",
    "    grad_dir = np.degrees(np.arctan2(y_diff_np, x_diff_np))\n",
    "    grad_dir_PIL = Image.fromarray(grad_dir.astype(np.uint8))\n",
    "    save_image(grad_dir_PIL, 'grad_direction_in_deg.jpg')\n",
    "    \n",
    "    # Loop over threshold values and apply thresholding\n",
    "    for threshold_low in threshold_low_values:\n",
    "        for threshold_high in threshold_high_values:\n",
    "            canny = canny = cv2.Canny(blurred, threshold_low, threshold_high)\n",
    "            save_image(canny, f'canny_thresh{threshold_low}_{threshold_high}.jpg')\n",
    "            display_image(canny)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "32c47961",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_robinson_direction(image, direction=None, threshold=30, return_feats=False, display=False, save=False):\n",
    "    \n",
    "    if direction is None:\n",
    "        raise TypeError(\"direction should not = None \\nUse: n, nw, w, sw, se, e, ne\")\n",
    "        \n",
    "    elif direction == 'n':\n",
    "    #-----------------NORTH----------------------\n",
    "        robinson_image = convolve_image(image, kernel3x3_robinson_N)\n",
    "        robinson_edge = single_threshold(robinson_image, threshold)\n",
    "    \n",
    "    elif direction == 'nw':\n",
    "    #-----------------NORTHWEST----------------------\n",
    "        robinson_image = convolve_image(image, kernel3x3_robinson_NW)\n",
    "        robinson_edge = single_threshold(robinson_image, threshold)\n",
    "    \n",
    "    elif direction == 'w':\n",
    "    #-----------------WEST----------------------\n",
    "        robinson_image = convolve_image(image, kernel3x3_robinson_W)\n",
    "        robinson_edge = single_threshold(robinson_image, threshold)\n",
    "\n",
    "    elif direction == 'sw':\n",
    "    #-----------------SOUTHWEST----------------------\n",
    "        robinson_image = convolve_image(image, kernel3x3_robinson_SW)\n",
    "        robinson_edge = single_threshold(robinson_image, threshold)\n",
    "\n",
    "    elif direction == 's':\n",
    "    #-----------------SOUTH----------------------\n",
    "        robinson_image = convolve_image(image, kernel3x3_robinson_S)\n",
    "        robinson_edge = single_threshold(robinson_image, threshold)\n",
    "\n",
    "    elif direction == 'se':\n",
    "    #-----------------SOUTHEAST----------------------\n",
    "        robinson_image = convolve_image(image, kernel3x3_robinson_SE)\n",
    "        robinson_edge = single_threshold(robinson_image, threshold)\n",
    "\n",
    "    elif direction == 'e':\n",
    "    #-----------------EAST----------------------\n",
    "        robinson_image = convolve_image(image, kernel3x3_robinson_E)\n",
    "        robinson_edge = single_threshold(robinson_image, threshold)\n",
    "\n",
    "    elif direction == 'ne':\n",
    "    #-----------------NORTHEAST----------------------\n",
    "        robinson_image = convolve_image(image, kernel3x3_robinson_NE)\n",
    "        robinson_edge = single_threshold(robinson_image, threshold)\n",
    "\n",
    "    \n",
    "    if display == True:\n",
    "        display_pair(robinson_image, f'Robinson Image {direction}', False, 6,2)\n",
    "        display_pair(robinson_edge, f'Robinson Edge {direction} T{threshold}', False, 6, 2)\n",
    " \n",
    "    \n",
    "    if save == True:\n",
    "        save_image(robinson_image, f\"{direction}_img_T{threshold}.jpg\")\n",
    "        save_image(robinson_edge, f\"{direction}_edge_T{threshold}.jpg\")\n",
    "        \n",
    "    if return_feats:\n",
    "        robinson_feats = pil_to_numpy(robinson_edge).ravel()\n",
    "        return robinson_feats\n",
    " \n",
    "    return robinson_image, robinson_edge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dd58b7b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image_with_robinson(image, threshold=30, display=False, save=False):\n",
    "    #-----------------NORTH----------------------\n",
    "    north = convolve_image(image, kernel3x3_robinson_N)\n",
    "    n_edge = single_threshold(north, threshold)\n",
    "    \n",
    "    #-----------------NORTHWEST----------------------\n",
    "    northwest = convolve_image(image, kernel3x3_robinson_NW)\n",
    "    nw_edge = single_threshold(northwest, threshold)\n",
    "\n",
    "    #-----------------WEST----------------------\n",
    "    west = convolve_image(image, kernel3x3_robinson_W)\n",
    "    w_edge = single_threshold(west, threshold)\n",
    "\n",
    "    #-----------------SOUTHWEST----------------------\n",
    "    southwest = convolve_image(image, kernel3x3_robinson_SW)\n",
    "    sw_edge = single_threshold(southwest, threshold)\n",
    "\n",
    "    #-----------------SOUTH----------------------\n",
    "    south = convolve_image(image, kernel3x3_robinson_S)\n",
    "    s_edge = single_threshold(south, threshold)\n",
    "\n",
    "    #-----------------SOUTHEAST----------------------\n",
    "    southeast = convolve_image(image, kernel3x3_robinson_SE)\n",
    "    se_edge = single_threshold(southeast, threshold)\n",
    "\n",
    "    #-----------------EAST----------------------\n",
    "    east = convolve_image(image, kernel3x3_robinson_E)\n",
    "    e_edge = single_threshold(east, threshold)\n",
    "\n",
    "    #-----------------NORTHEAST----------------------\n",
    "    northeast = convolve_image(image, kernel3x3_robinson_NE)\n",
    "    ne_edge = single_threshold(northeast, threshold)\n",
    "\n",
    "    \n",
    "    if display == True:\n",
    "        display_pair(north, 'North', False, 6,2)\n",
    "        display_pair(northwest, 'Northwest')\n",
    "        display_pair(west, 'West', False, 6, 2)\n",
    "        display_pair(southwest, 'Southwest')\n",
    "        display_pair(south, 'South', False, 6, 2)\n",
    "        display_pair(southeast, 'Southeast')\n",
    "        display_pair(east, 'East', False, 6, 2)\n",
    "        display_pair(northeast, 'Northeast') \n",
    "    \n",
    "    if save == True:\n",
    "        save_image(n_edge, f\"northT{threshold}.jpg\")\n",
    "        save_image(nw_edge, f\"northwestT{threshold}.jpg\")\n",
    "        save_image(w_edge, f\"westT{threshold}.jpg\")\n",
    "        save_image(sw_edge, f\"southwestT{threshold}.jpg\")\n",
    "        save_image(s_edge, f\"southT{threshold}.jpg\")\n",
    "        save_image(se_edge, f\"southeastT{threshold}.jpg\")\n",
    "        save_image(e_edge, f\"eastT{threshold}.jpg\")\n",
    "        save_image(ne_edge, f\"northeastT{threshold}.jpg\")\n",
    "        \n",
    "    return n_edge, nw_edge, w_edge, sw_edge, s_edge, se_edge, e_edge, ne_edge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "beab7d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hog_automated(image, o=8, ppc=(16, 16), cpb=(1, 1), v=True, display=False):\n",
    "    img_np = pil_to_numpy(image)\n",
    "    hog_feature, hog_image = hog(img_np, orientations=o, pixels_per_cell=ppc, \n",
    "                                 cells_per_block=cpb, visualize=v, channel_axis=None)\n",
    "    hog_image1_rescaled = exposure.rescale_intensity(hog_image, in_range=(0,10))\n",
    "   \n",
    "    #plot\n",
    "    if display:\n",
    "        fig, (axes1, axes2) = pylab.subplots(1, 2, figsize=(15, 10), sharex=True, sharey=True)\n",
    "        axes1.axis('off'), axes1.imshow(img_np, cmap=pylab.cm.gray),\n",
    "        #axes1.set_title('Input image')\n",
    "        axes2.axis('off'), axes2.imshow(hog_image1_rescaled, cmap=pylab.cm.gray),\n",
    "        #axes2.set_title('Histogram of Oriented Gradients')\n",
    "        axes2.figure.savefig('hog_image_rescaled.png', bbox_inches='tight', pad_inches=0, transparent=True)\n",
    "        pylab.show()\n",
    "\n",
    "    return hog_feature, hog_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "399d7214",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hog_batch(images, orientations=8, pixels_per_cell=(16, 16), cells_per_block=(1, 1)):\n",
    "    hog_np_images = []\n",
    "    hog_features = []\n",
    "    \n",
    "    for image in images:\n",
    "        img_np = np.array(image)\n",
    "        fd, hog_image = hog(img_np, orientations, pixels_per_cell, cells_per_block)\n",
    "        hog_image_rescaled = exposure.rescale_intensity(hog_image, in_range=(0,10))\n",
    "        hog_np_images.append(hog_image_rescaled)\n",
    "        hog_features.append(hog_features)\n",
    "        \n",
    "    return hog_features, hog_np_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "7810a9ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_hog(images, set_id=None, display=False, save=False):\n",
    "    # retrieve plot colors from main file\n",
    "    %store -r plt_color\n",
    "    %store -r label_color\n",
    "    %store -r title_color\n",
    "\n",
    "    hog_features = []\n",
    "    hog_images = []\n",
    "    \n",
    "    #     images = pil_to_numpy(images)\n",
    "    images_badcoder = []\n",
    "    if isinstance(images, (list, tuple, np.ndarray)):\n",
    "        images_badcoder = images\n",
    "        img_count = len(images)\n",
    "    else:\n",
    "        images_badcoder.append(images)\n",
    "        img_count = 1   \n",
    "    \n",
    "    i=1\n",
    "    for image in images_badcoder:\n",
    "        # Convert the PIL image to a NumPy array\n",
    "        np_image = np.array(image)\n",
    "\n",
    "        # Compute the HoG representation of the image\n",
    "        hog_feature, hog_image = hog(np_image, orientations=8, pixels_per_cell=(16, 16),\n",
    "                            cells_per_block=(1, 1), visualize=True, channel_axis=None)\n",
    "    \n",
    "        hog_features.append(hog_feature)\n",
    "        hog_images.append(hog_image)\n",
    "        \n",
    "        # Display the original image and its HoG representation side by side\n",
    "        if display == True:\n",
    "            fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 5), sharex=True, sharey=True)\n",
    "            ax1.imshow(image, cmap=plt.cm.gray)\n",
    "            ax1.axis('off')\n",
    "            ax1.set_title(f'{set_id}{i}', color = title_color)\n",
    "            ax2.imshow(hog_image, cmap=plt.cm.gray)\n",
    "            ax2.axis('off')\n",
    "            ax2.set_title('Histogram of Oriented Gradients', color = title_color)\n",
    "            if save == True:\n",
    "                _ = fig.savefig(f'{set_id}{i}_hog.png', dpi = 300, transparent=True)\n",
    "            plt.show()\n",
    "        i+=1\n",
    "    \n",
    "    hog_images = numpy_to_pil(hog_images)\n",
    "    return hog_features, hog_images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc9781ed",
   "metadata": {},
   "source": [
    "[GO TO TOP](#top)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0fc1896",
   "metadata": {},
   "source": [
    "<a id=\"morphology\"></a>\n",
    "-----------------------------\n",
    "## Morphology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "87b82e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHAPE_DICT = {\n",
    "#                 \"RECT\": cv2.MORPH_RECT,\n",
    "#                 \"CROSS\": cv2.MORPH_CROSS,\n",
    "#                 \"ELLIPSE\": cv2.MORPH_ELLIPSE,\n",
    "#                 \"HITMISS\": cv2.MORPH_HITMISS,\n",
    "#             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a04cbef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dilation(image, disk_sizes=[5, 10], shape=\"rect\", display = False, save = False):\n",
    "    # Convert PIL image to NumPy array\n",
    "    img = np.array(image)\n",
    "\n",
    "    # Check if shape is valid\n",
    "    if shape.upper() not in SHAPE_DICT:\n",
    "        raise ValueError(\"Invalid shape specified\")\n",
    "\n",
    "    # Get the cv2.MORPH_* value for the specified shape\n",
    "    shape_val = SHAPE_DICT[shape.upper()]\n",
    "\n",
    "    dilated_images = []\n",
    "    for disk in disk_sizes:\n",
    "        # Warn user about inaccurate kernels\n",
    "        if disk % 2 == 0 and shape == 'ellipse':\n",
    "            print(f\"WARNING: detected even disk size {disk} for ellipse kernel.\",\n",
    "                  \"\\n\\tThis structure will not generate symmetricly.\")\n",
    "                \n",
    "        # Perform dilation with disk\n",
    "        structure = cv2.getStructuringElement(shape_val, (disk, disk))\n",
    "        BW = cv2.dilate(img, structure)\n",
    "    \n",
    "        # Display the dilated image\n",
    "        if display == True:\n",
    "            print(\"\\nStructure:\\n\",structure)\n",
    "            display_image(BW, '', False, 3)\n",
    "\n",
    "        # Save the dilated image\n",
    "        if save == True:\n",
    "            save_image(BW, f'dilation_{shape}{disk}.jpg')\n",
    "\n",
    "        # Convert NumPy array to PIL image\n",
    "        dilated_images.append(Image.fromarray(BW))\n",
    "\n",
    "    return tuple(dilated_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c3fd492e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dilate_batch(images, disk_sizes=[5, 10], shape=\"rect\", display = False, save = False):\n",
    "    # Convert PIL image to NumPy array\n",
    "\n",
    "    pil_dilated = []\n",
    "    \n",
    "    # Check if shape is valid\n",
    "    if shape.upper() not in SHAPE_DICT:\n",
    "        raise ValueError(\"Invalid shape specified\")\n",
    "\n",
    "    # Get the cv2.MORPH_* value for the specified shape\n",
    "    shape_val = SHAPE_DICT[shape.upper()]\n",
    "\n",
    "    for image in images:\n",
    "        img = np.array(image)\n",
    "        for disk in disk_sizes:\n",
    "            # Warn user about inaccurate kernels\n",
    "            if disk % 2 == 0 and shape == 'ellipse':\n",
    "                print(f\"WARNING: detected even disk size {disk} for ellipse kernel.\",\n",
    "                  \"\\n\\tThis structure will not generate symmetricly.\")\n",
    "            \n",
    "            # Perform dilation with disk\n",
    "            structure = cv2.getStructuringElement(shape_val, (disk, disk))\n",
    "            BW = cv2.dilate(img, structure)\n",
    "\n",
    "            # Display the dilated image\n",
    "            if display == True:\n",
    "                print(\"\\nStructure:\\n\",structure)\n",
    "                display_image(BW, '', False, 3)\n",
    "\n",
    "            # Save the dilated image\n",
    "            if save == True:\n",
    "                save_image(BW, f'dilation_{shape}{disk}.jpg')\n",
    "\n",
    "            # Convert NumPy array to PIL image\n",
    "            BW = Image.fromarray(BW)\n",
    "        pil_dilated.append(BW)\n",
    "\n",
    "    return pil_dilated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bf95eb4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def erosion(image, disk_sizes=[5, 10], shape=\"rect\", display = False, save = False):\n",
    "    # Convert PIL image to NumPy array\n",
    "    img = np.array(image)\n",
    "\n",
    "    # Check if shape is valid\n",
    "    if shape.upper() not in SHAPE_DICT:\n",
    "        raise ValueError(\"Invalid shape specified\")\n",
    "\n",
    "    # Get the cv2.MORPH_* value for the specified shape\n",
    "    shape_val = SHAPE_DICT[shape.upper()]\n",
    "\n",
    "    eroded_images = []\n",
    "    for disk in disk_sizes:\n",
    "        # Warn user about inaccurate kernels\n",
    "        if disk % 2 == 0 and shape == 'ellipse':\n",
    "            print(f\"WARNING: detected even disk size {disk} for ellipse kernel.\",\n",
    "                  \"\\n\\tThis structure will not generate symmetricly.\")\n",
    "                \n",
    "        # Perform dilation with disk\n",
    "        structure = cv2.getStructuringElement(shape_val, (disk, disk))\n",
    "        BW = cv2.erode(img, structure)\n",
    "    \n",
    "        # Display the dilated image\n",
    "        if display == True:\n",
    "            print(\"\\nStructure:\\n\",structure)\n",
    "            display_image(BW, '', False, 3)\n",
    "\n",
    "        # Save the dilated image\n",
    "        if save == True:\n",
    "            save_image(BW, f'erosion_{shape}{disk}.jpg')\n",
    "\n",
    "        # Convert NumPy array to PIL image\n",
    "        eroded_images.append(Image.fromarray(BW))\n",
    "\n",
    "    return tuple(eroded_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1d6b8464",
   "metadata": {},
   "outputs": [],
   "source": [
    "def erode_batch(images, disk_sizes=[5, 10], shape=\"rect\", display = False, save = False):\n",
    "    # Convert PIL image to NumPy array\n",
    "\n",
    "    pil_eroded = []\n",
    "    \n",
    "    # Check if shape is valid\n",
    "    if shape.upper() not in SHAPE_DICT:\n",
    "        raise ValueError(\"Invalid shape specified\")\n",
    "\n",
    "    # Get the cv2.MORPH_* value for the specified shape\n",
    "    shape_val = SHAPE_DICT[shape.upper()]\n",
    "\n",
    "    for image in images:\n",
    "        img = np.array(image)\n",
    "        for disk in disk_sizes:\n",
    "            # Warn user about inaccurate kernels\n",
    "            if disk % 2 == 0 and shape == 'ellipse':\n",
    "                print(f\"WARNING: detected even disk size {disk} for ellipse kernel.\",\n",
    "                  \"\\n\\tThis structure will not generate symmetricly.\")\n",
    "                \n",
    "            # Perform dilation with disk\n",
    "            structure = cv2.getStructuringElement(shape_val, (disk, disk))\n",
    "            BW = cv2.erode(img, structure)\n",
    "\n",
    "            # Display the dilated image\n",
    "            if display == True:\n",
    "                print(\"\\nStructure:\\n\",structure)\n",
    "                display_image(BW, '', False, 3)\n",
    "\n",
    "            # Save the dilated image\n",
    "            if save == True:\n",
    "                save_image(BW, f'erosion_{shape}{disk}.jpg')\n",
    "\n",
    "            # Convert NumPy array to PIL image\n",
    "            BW = Image.fromarray(BW)\n",
    "        pil_eroded.append(BW)\n",
    "\n",
    "    return pil_eroded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8f453cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#erode then dilate\n",
    "def opening(image, disk_sizes=[5, 10], shape=\"rect\", show_struct=False, display=False, save=False):\n",
    "    # Convert PIL image to NumPy array\n",
    "    img = np.array(image)\n",
    "\n",
    "    # Check if shape is valid\n",
    "    if shape.upper() not in SHAPE_DICT:\n",
    "        raise ValueError(\"Invalid shape specified\")\n",
    "\n",
    "    # Get the cv2.MORPH_* value for the specified shape\n",
    "    shape_val = SHAPE_DICT[shape.upper()]\n",
    "    \n",
    "    opened_images = []\n",
    "    for disk in disk_sizes:\n",
    "        # Warn user about inaccurate kernels\n",
    "        if disk % 2 == 0 and shape == 'ellipse':\n",
    "            print(f\"WARNING: detected even disk size {disk} for ellipse kernel.\",\n",
    "                  \"\\n\\tThis structure will not generate symmetricly.\")\n",
    "            \n",
    "        # Get Structural Element\n",
    "        structure = cv2.getStructuringElement(shape_val, (disk, disk))\n",
    "    \n",
    "        # Perform Closing (Dilation then Erosion)\n",
    "        eroded = cv2.erode(img, structure)\n",
    "        opened = cv2.dilate(eroded, structure)\n",
    "        \n",
    "        # Show the structural element\n",
    "        if show_struct: \n",
    "            print(\"\\nStructure:\\n\",structure)\n",
    "            \n",
    "        # Display the dilated image\n",
    "        if display == True:\n",
    "            display_image(eroded, 'Eroded before Opening', False, 3)\n",
    "            display_image(opened, 'Opened', False, 3)\n",
    "\n",
    "        # Save the dilated image\n",
    "        if save == True:\n",
    "            save_image(eroded, f'eroded_{shape}{disk}.jpg')\n",
    "            save_image(opened, f'opened_{shape}{disk}.jpg')\n",
    "\n",
    "        # Convert NumPy array to PIL image\n",
    "        opened_images.append(Image.fromarray(opened))\n",
    "\n",
    "    return tuple(opened_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "df54d87b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dilate then erode\n",
    "def closing(image, disk_sizes=[5, 10], shape=\"rect\", show_struct=False, display=False, save=False):\n",
    "    # Convert PIL image to NumPy array\n",
    "    img = np.array(image)\n",
    "\n",
    "    # Check if shape is valid\n",
    "    if shape.upper() not in SHAPE_DICT:\n",
    "        raise ValueError(\"Invalid shape specified\")\n",
    "\n",
    "    # Get the cv2.MORPH_* value for the specified shape\n",
    "    shape_val = SHAPE_DICT[shape.upper()]\n",
    "    \n",
    "    closed_images = []\n",
    "    for disk in disk_sizes:\n",
    "        # Warn user about inaccurate kernels\n",
    "        if disk % 2 == 0 and shape == 'ellipse':\n",
    "            print(f\"WARNING: detected even disk size {disk} for ellipse kernel.\",\n",
    "                  \"\\n\\tThis structure will not generate symmetricly.\")\n",
    "        # Get Structural Element\n",
    "        structure = cv2.getStructuringElement(shape_val, (disk, disk))\n",
    "        \n",
    "        # Perform Closing (Dilation then Erosion)\n",
    "        dilated = cv2.dilate(img, structure)\n",
    "        closed = cv2.erode(dilated, structure)\n",
    "        \n",
    "        # Show the structural element\n",
    "        if show_struct: \n",
    "            print(\"\\nDisk:\\n\",disk,\"\\nStructure:\\n\",structure)\n",
    "            \n",
    "        # Display the dilated image\n",
    "        if display == True:\n",
    "            display_image(dilated, 'Dilated Before Closing', False, 3)\n",
    "            display_image(closed, 'Closed', False, 3)\n",
    "\n",
    "        # Save the dilated image\n",
    "        if save == True:\n",
    "            save_image(dilated, f'dilated_{shape}{disk}.jpg')\n",
    "            save_image(closed, f'closed_{shape}{disk}.jpg')\n",
    "\n",
    "        # Convert NumPy array to PIL image\n",
    "        closed_images.append(Image.fromarray(closed))\n",
    "\n",
    "    return tuple(closed_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38ec9d35",
   "metadata": {},
   "source": [
    "[GO TO TOP](#top)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b964cd8d",
   "metadata": {},
   "source": [
    "<a id=\"midterm-general\"></a>\n",
    "-----------------------------\n",
    "## Midterm General"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "c78abb52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BATCH PROCESS\n",
    "#images should be np images\n",
    "def matching_CDF(images, set='', display=False, save=False):\n",
    "    np_matched = []\n",
    "    \n",
    "    if detect_type(images) not in ('numpy_set', 'pil_set'):\n",
    "        raise TypeError(\"matching_CDF function has not recieved a set of images to compare.\")\n",
    "    \n",
    "    i=1\n",
    "    total_dist = 0\n",
    "    for image in images:\n",
    "        #histogram matching\n",
    "        match = hist_matching(image, cdf(image), cdf(clean16combo))\n",
    "        \n",
    "        #add to matched array\n",
    "        np_matched.append(match)\n",
    "        \n",
    "        #display\n",
    "        match = Image.fromarray(match)\n",
    "        total_dist += image_distance(clean16combo, match, display_hist=False)   \n",
    "        if display == True:\n",
    "            display_pair(match, f\"{set}{i} + Match\", save, m=6, n=2)\n",
    "            display_hist(match, f\"{set}{i}_histmatch\", save=save)\n",
    "        if save == True:\n",
    "            save_image(match, f\"{set}{i}_histmatch.jpg\")\n",
    "        \n",
    "        i+=1\n",
    "        \n",
    "    avg_dist = total_dist / i\n",
    "    print(\"AVERAGE DISTANCE =\", avg_dist)\n",
    "    return np_matched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "4bff6582",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_mask(image, slope, start_height, fill_value, mask_color=0):\n",
    "    \n",
    "    width, height = image.size\n",
    "    new_image = Image.new(image.mode, image.size)\n",
    "    draw = ImageDraw.Draw(new_image)\n",
    "    \n",
    "    x1 = 0\n",
    "    y1 = int(start_height)\n",
    "    x2 = width\n",
    "    y2 = int(start_height + slope * (width - 1))\n",
    "    \n",
    "    mask_image = Image.new('L', image.size, fill_value)\n",
    "    mask_draw = ImageDraw.Draw(mask_image)\n",
    "    mask_draw.polygon([(x1, y1), (x2, y2), (x2, height), (x1, height)], fill=255 - fill_value)\n",
    "    masked_image = Image.composite(image, Image.new('L', image.size, mask_color), mask_image)\n",
    "    merged_image = Image.alpha_composite(new_image.convert('RGBA'), masked_image.convert('RGBA'))\n",
    "    \n",
    "    return merged_image.convert('L')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f670d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "def crop_to_panel(images, mask_color=0, set_id=None):\n",
    "    images = numpy_to_pil(images)\n",
    "    cropped_set = []\n",
    "    \n",
    "    fill1 = 255\n",
    "    fill2 = 0\n",
    "    fill3 = 0 \n",
    "    \n",
    "    if detect_type(images) == 'pil_single':\n",
    "        cropped = apply_mask(images, 0.17, 135, fill1, mask_color)\n",
    "        cropped = apply_mask(cropped, 0.15, 10, fill2, mask_color)\n",
    "        cropped = apply_mask(cropped, -2, 180, fill3, mask_color)\n",
    "        return cropped\n",
    "    else:\n",
    "        counter=0\n",
    "        for image in images:\n",
    "            cropped = apply_mask(image, 0.17, 135, fill1, mask_color)\n",
    "            cropped = apply_mask(cropped, 0.15, 10, fill2, mask_color)\n",
    "            cropped = apply_mask(cropped, -2, 180, fill3, mask_color)\n",
    "            cropped_set.append(cropped)\n",
    "#             #save the 15th image\n",
    "#             if counter == 15:\n",
    "#                 save_image(cropped, f\"{set_id}{counter}_cropped.jpg\")            \n",
    "#             counter += 1\n",
    "        return cropped_set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "272b2a45",
   "metadata": {},
   "source": [
    "[GO TO TOP](#top)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2de2b51e",
   "metadata": {},
   "source": [
    "<a id=\"midterm-procedures\"></a>\n",
    "-----------------------------\n",
    "## Midterm Procedures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4dbfee00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def solar_system(image_set, benchmark = None, set_id=None, \n",
    "                 part1_params=None, part2_params=None, part3_params=None, \n",
    "                 part4_params=None, part5_params=None, part6_params=None, part7_params=None,\n",
    "                 abort_after=None, \n",
    "                 display_originals = True, display_steps = True, display_finals = True, \n",
    "                 fileName=None, save=True):\n",
    "\n",
    "    # ======================================= SETUP =======================================    \n",
    "    \n",
    "    #Determine if image_set is a single image or a list/tuple/np.ndarray\n",
    "    if isinstance(image_set, (list, tuple, np.ndarray)):\n",
    "        set_size = len(image_set)\n",
    "    else:\n",
    "        set_size = 1\n",
    "        \n",
    "    #Display Input Set\n",
    "    if display_originals:\n",
    "        titles = [f\"{set_id}{i+1} Og.\" for i in range(set_size)]\n",
    "        plot_nxn(image_set, titles=titles, fileName=f'{set_id}_Original', save=save)\n",
    "\n",
    "    # ================================ BEGIN STEPS =========================================\n",
    "    #---------------PART 1------------------------------------------------------------------\n",
    "    #-input project database images---------------------------------------------------------\n",
    "    #---------------------------------------------------------------------------------------\n",
    "    pil_step1 = image_set\n",
    "    #pil_step1 = selection_procedure(...)\n",
    "       \n",
    "    #Abort 1 Procedure\n",
    "    if abort_after == 1:\n",
    "        #image_set_final = pil_step1\n",
    "        print(\"\\nProcessing aborted after Part 1 \\n\\tReturned image(s) are unmodified.\\n\")\n",
    "        return pil_step1\n",
    "    \n",
    "    #---------------PART 2------------------------------------------------------------------\n",
    "    #-apply image restoration and enhancement methods to improve quality--------------------\n",
    "    #---------------------------------------------------------------------------------------\n",
    "    pil_step2 = pil_step1\n",
    "    pil_step2 = enhancement_procedure(pil_step2, f'{set_id}', params=part2_params)\n",
    "    \n",
    "    #Display step\n",
    "    if display_steps:\n",
    "        plot_nxn(pil_step2, fileName = f'STEP 2 - {set_id} Enhancement', save=True)\n",
    "    \n",
    "    #Abort 2 Procedure\n",
    "    if abort_after == 2:\n",
    "        print(\"\\nProcessing aborted after Part 2 \\n\\tReturned image(s) are enhanced.\\n\")\n",
    "        return pil_step2\n",
    "    \n",
    "    #---------------PART 3------------------------------------------------------------------\n",
    "    #-retreive binary segmented images via segmentation methods-----------------------------\n",
    "    #---------------------------------------------------------------------------------------\n",
    "    pil_step3 = pil_step2\n",
    "    pil_step3 = segmentation_procedure(pil_step3, set_id=set_id, params=part3_params)\n",
    "    \n",
    "    #Display step\n",
    "    if display_steps:\n",
    "        plot_nxn(pil_step3, fileName = f'STEP 3 - {set_id} Segmentation', save=True)\n",
    "    \n",
    "    #Abort 3 Procedure\n",
    "    if abort_after == 3:\n",
    "        print(\"\\nProcessing aborted after Part 3 \\n\\tReturned image(s) are binary segmented.\\n\")\n",
    "        return pil_step3\n",
    "    \n",
    "    #---------------PART 4------------------------------------------------------------------\n",
    "    #-obtain isolated object in via multiplication of (enhanced * segmented binary)---------\n",
    "    #---------------------------------------------------------------------------------------\n",
    "    pil_step4 = pil_step3\n",
    "    pil_step4 = multiplicative_procedure(pil_step2, pil_step4, set_id=set_id, params=part4_params)\n",
    "    \n",
    "    #Display step\n",
    "    if display_steps:\n",
    "        plot_nxn(pil_step4, fileName = f'STEP 4 - {set_id} Multiplicative', save=True)\n",
    "    \n",
    "    #Abort 4 Procedure\n",
    "    if abort_after == 4:\n",
    "        print(\"\\nProcessing aborted after Part 4 \\n\\tReturned image(s) are gray-level segmented (object isolated).\\n\")\n",
    "        return pil_step4\n",
    "    \n",
    "    #---------------PART 5------------------------------------------------------------------\n",
    "    #-generate feature information (Histogram or HoG) via segmented gray-level images-------\n",
    "    #---------------------------------------------------------------------------------------\n",
    "    pil_step5 = pil_step4\n",
    "    pil_step5, features, benchmark_features = feature_procedure(pil_step5, benchmark, set_id=set_id, params=None)\n",
    "    \n",
    "    #Display step\n",
    "    if display_steps:\n",
    "        print(\"image features[0]: \", features[0])\n",
    "        print(\"benchmark features: \", benchmark_features)\n",
    "\n",
    "    #Abort 5 Procedure\n",
    "    if abort_after == 5:\n",
    "        print(\"\\nProcessing aborted after Part 5.\",\n",
    "              \" \\n\\tHistogram data has been generated.\",\n",
    "              \"\\n\\tReturned \\n\\t\\t- image(s) are gray-level segmented (object isolated)\",\n",
    "             \"\\n\\t\\t- feature data (list) \\n\\t\\t- benchmark features (single)\\n\")\n",
    "        return pil_step5, features, benchmark_features\n",
    "    \n",
    "    #---------------PART 6------------------------------------------------------------------\n",
    "    #-similarity data has been calculated using a benchmark img & segmented gray images-----\n",
    "    #---------------------------------------------------------------------------------------       \n",
    "    pil_step6 = pil_step5\n",
    "    pil_step6, hist_distances, feat_distances = similarity_procedure(pil_step6, benchmark, features, benchmark_features,\n",
    "                                                             set_id=set_id, params=None)\n",
    "    #Display step\n",
    "    if display_steps:\n",
    "        print(\"Image Histogram Distances\\n\", hist_distances)\n",
    "        print(\"Image Feature Distances\\n\", feat_distances)\n",
    "    \n",
    "    #Abort 6 Procedure\n",
    "    if abort_after == 6:\n",
    "        print(\"\\nProcessing aborted after Part 6\",\n",
    "              \" \\n\\tSimilarity data has been calculated.\",\n",
    "              \"\\n\\tReturned \\n\\t\\t- image(s) are gray-level segmented (object isolated)\",\n",
    "             \"\\n\\t\\t- histogram difference calculations \\n\\t\\t- feature distance calculations\\n\")\n",
    "        return pil_step6, hist_distances, feat_distances\n",
    "    \n",
    "    #---------------PART 7------------------------------------------------------------------\n",
    "    #---------------------------------------------------------------------------------------\n",
    "    #---------------------------------------------------------------------------------------  \n",
    "    pil_step7 = pil_step6\n",
    "    #pil_step7 = accuracy_evaluation_procedure(...)\n",
    "    \n",
    "    #Abort 7 Procedure\n",
    "    if abort_after == 7:\n",
    "        print(\"\\nProcessing aborted after Part 7\",\n",
    "              \" \\n\\tClassification accuracy has been evaluated. Returned image(s) are gray-level segmented (object isolated).\\n\")\n",
    "        return pil_step7\n",
    "    \n",
    "    \n",
    "    # ================================== END STEPS ===========================================\n",
    "    #Display final set images if desired.\n",
    "    image_set_final = pil_step7\n",
    "    print(\"All 7 steps have completed.\")\n",
    "    if display_finals:\n",
    "        titles = [f\"{set_id}{i+1} Final\" for i in range(set_size)]\n",
    "        plot_nxn(image_set_final, titles=titles, fileName=f'{set_id}_Final', save=save)\n",
    "\n",
    "    return image_set_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c724edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 2 - Enhancement\n",
    "def enhancement_procedure(images, set_id=None, params=None):\n",
    "    \"\"\"\n",
    "    This function performs image enhancement on a set of images using a combination of histogram stretching, gamma adjustment, and equalization.\n",
    "\n",
    "    Parameters:\n",
    "    images (PIL.Image.Image or list of PIL.Image.Image or numpy.ndarray or list of numpy.ndarray): An instance of PIL.Image.Image or a list of instances of PIL.Image.Image, or a 2D numpy array or a list of 2D numpy arrays representing the image(s) to enhance.\n",
    "    set_id (str): An optional string to use as a prefix for display and/or save filenames.\n",
    "    params (dict): An optional dictionary containing custom parameters to use for the enhancement.\n",
    "\n",
    "    Returns:\n",
    "    list (PIL.Image.Image(s)): representing the enhanced images\n",
    "    \"\"\"\n",
    "    \n",
    "    np_enhanced = []\n",
    "    print(\"STEP 2: Performing the following tasks...\")\n",
    "    \n",
    "    # DEFAULT PARAMETERS \n",
    "    print(\"- setting default parameters: gamma, alpha, hist_clip, equalize_clip, display, save\")\n",
    "    gamma = 0.75\n",
    "    alpha = 0.5\n",
    "    hist_clip = 0.005\n",
    "    equalize_clip = 0.03\n",
    "    display = False\n",
    "    save = False\n",
    "\n",
    "    # UNPACK CUSTOM PARAMETERS\n",
    "    if params is not None:\n",
    "        print(\"- unpacking custom parameters\")\n",
    "        print(\"ERROR: Custom Parameters not set up for this step. Terminating Process\")\n",
    "        return images\n",
    "\n",
    "    # CONVERSIONS\n",
    "    images = pil_to_numpy(images)    # if data is PIL, convert it to NumPy\n",
    "\n",
    "    i=1\n",
    "    total_dist = 0\n",
    "    print(\"- histogram stretching\")\n",
    "    print(\"- gamma adjustment\")\n",
    "    print(\"- equalization\")\n",
    "    print(\"- image alpha combination\")\n",
    "    for image in images:\n",
    "        #histogram stretch + clipping\n",
    "        image_stretch = histogram_stretch_clip(image, hist_clip)\n",
    "        image_gamma = image_stretch.point(lambda x: 255*(x/255)**gamma)  \n",
    "        image_gamma = np.array(image_gamma).astype(np.uint8)\n",
    "        \n",
    "#         #stretch again (NEW ADDITION)\n",
    "#         image_stretch2 = histogram_stretch_clip(image_gamma, hist_clip)\n",
    "#         image_gamma = image_stretch2\n",
    "        \n",
    "        #equalization\n",
    "        image_equalized = exposure.equalize_hist(image)*255\n",
    "        # image_equalized = exposure.equalize_adapthist(image, clip_limit=equalize_clip)*255\n",
    "\n",
    "        #combine both parts\n",
    "        part1 = pil_to_numpy(image_gamma)\n",
    "        part2 = pil_to_numpy(image_equalized)\n",
    "        image_combo = (alpha)*part1 + (1-alpha)*part2\n",
    "        \n",
    "        #append to array\n",
    "        np_enhanced.append(image_combo)\n",
    "\n",
    "        #display\n",
    "        image_combo = Image.fromarray(image_combo)\n",
    "        # total_dist += image_distance(clean16combo, image_combo, display_hist=False)   \n",
    "        if display == True:\n",
    "            display_pair(image_combo, f\"{set_id}{i} + Combo\", save, m=6, n=2)\n",
    "            display_hist(image_combo, f\"{set_id}{i}_enhanced\", save=save)      \n",
    "        if save == True:\n",
    "            save_image(image_combo, f\"{set_id}{i}_enhanced.jpg\")\n",
    "        \n",
    "        i+=1\n",
    "    \n",
    "    pil_enhanced = numpy_to_pil(np_enhanced)\n",
    "    \n",
    "    return pil_enhanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "192d3766",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 3 - Segmentation\n",
    "def segmentation_procedure(images, set_id=None, params=None):\n",
    "    \"\"\"\n",
    "    This function performs image segmentation on a set of images using various methods including single T thresholding and Sobel segmentation.\n",
    "\n",
    "    Parameters:\n",
    "    images (numpy.ndarray or list of numpy.ndarray): A 2D numpy array or a list of 2D numpy arrays representing the grayscale image(s) to segment.\n",
    "    set_id (str): An optional string to use as a prefix for display and/or save filenames, must be either 'clean' or 'dirty'\n",
    "    params (dict): An optional dictionary containing custom parameters to use for the segmentation.\n",
    "    \n",
    "    Returns:\n",
    "    list (PIL.Image.Image(s)): representing the segmented images\n",
    "    \"\"\"\n",
    "    segmented = []\n",
    "    otsu_values = []\n",
    "    print(\"STEP 3: Performing the following tasks...\")\n",
    "    \n",
    "    # DEFAULT PARAMETERS\n",
    "    print(\"- setting default parameters: segmentation_method, otsu_predefined, invert_region,\",\n",
    "              \"\\n\\t\\tmorphology, disk, manual_crop, crop_bg_value, display, save\")\n",
    "    segmentation_method = None\n",
    "    otsu_predefined = None\n",
    "    invert_region = False\n",
    "    morphology = None\n",
    "    disk = None\n",
    "    manual_crop = True\n",
    "    crop_bg_value = 0\n",
    "    display = False\n",
    "    save = False\n",
    "    \n",
    "    # UNPACK CUSTOM PARAMETERS\n",
    "    if params is not None:\n",
    "        print(\"- unpacking custom parameters\")\n",
    "        segmentation_method = params.get(\"segmentation_method\")\n",
    "        otsu_predefined = params.get(\"otsu_predefined\")\n",
    "        invert_region = params.get(\"invert_region\")\n",
    "        morphology = params.get(\"morphology\")\n",
    "        disk = params.get(\"disk\")\n",
    "        manual_crop = params.get(\"manual_crop\")\n",
    "        crop_bg_value = params.get(\"crop_bg_value\")\n",
    "        display = params.get(\"display\")\n",
    "        save = params.get(\"save\")\n",
    "        \n",
    "    if set_id == 'clean':\n",
    "        dilate_disk = [10]\n",
    "        erode_disk = [6]\n",
    "        open_disk = [10]\n",
    "        close_disk = [10]\n",
    "    elif set_id == 'dirty':\n",
    "        dilate_disk = [4]\n",
    "        erode_disk = [6]\n",
    "        open_disk = [10]\n",
    "        close_disk = [10]\n",
    "    elif disk is not None:\n",
    "        print(f\"\\t\\tWARNING! Because set is neither \\'clean\\' nor \\'dirty\\', Disk size used = {disk}.\")\n",
    "    elif morphology is not None:\n",
    "        raise NameError(\"ERROR! When DISK = NONE, set_id must be either \\'clean\\' or \\'dirty\\'\")\n",
    "        return images;\n",
    "        \n",
    "    # CONVERSIONS\n",
    "    images = numpy_to_pil(images)  \n",
    "\n",
    "#     # CROPPING\n",
    "#     if manual_crop:\n",
    "#         print(\"- cropping\")\n",
    "#         images = crop_to_panel(images, crop_bg_value)\n",
    "    \n",
    "    # ----------- SEGMENTATION ---------\n",
    "    counter = 1\n",
    "    \n",
    "    # SINGLE T HALFWAY\n",
    "    if segmentation_method == 'single_T_halfway':\n",
    "        print(\"- single thresholding at 128\")\n",
    "        for image in images:\n",
    "            single_thresh = single_threshold(image, [128])\n",
    "            segmented.append(single_thresh)     \n",
    "            if save == True:\n",
    "                save_image(single_thresh, f'{set_id}{counter}_single_T{best_thresh}')\n",
    "            counter += 1 \n",
    "    \n",
    "    # SINGLE T SEGMENTATION \n",
    "    elif segmentation_method == 'single_T':\n",
    "        print(\"- single thresholding via otsu T\")\n",
    "        for image in images:\n",
    "            best_thresh = otsu_best_threshold(image)\n",
    "            otsu_values.append(best_thresh)\n",
    "\n",
    "            single_thresh = single_threshold(image, [best_thresh])\n",
    "            segmented.append(single_thresh)     \n",
    "            if save == True:\n",
    "                save_image(single_thresh, f'{set_id}{counter}_single_T{best_thresh}')\n",
    "            counter += 1 \n",
    "            \n",
    "    # SOBEL SEGMENTATION       \n",
    "    elif segmentation_method == 'sobel':\n",
    "        print(\"- sobel segmentation + otsu thresholding\")\n",
    "        for image in images:\n",
    "            best_thresh = otsu_best_threshold(image)\n",
    "            otsu_values.append(best_thresh)\n",
    "\n",
    "            sobel_max, sobel_mag = process_image_with_sobel(image, [best_thresh], display=display, save=save)\n",
    "            segmented.append(sobel_max)     \n",
    "            if save:\n",
    "                save_image(sobel_max, f'{set_id}{counter}_sobel_max_T{best_thresh}')\n",
    "            counter += 1    \n",
    "    else:\n",
    "        print(\"- NOTICE! No segmentation performed.\")\n",
    "        segmented = images\n",
    "    \n",
    "    # INVERSION\n",
    "    if invert_region:\n",
    "        print(\"- inversion\")\n",
    "        invert_segmented = []\n",
    "\n",
    "        for image in segmented:\n",
    "            temp = pil_to_numpy(image)\n",
    "            inverted = np.abs(255 - temp)\n",
    "            inverted = numpy_to_pil(inverted)\n",
    "            invert_segmented.append(inverted)\n",
    "            segmented = invert_segmented\n",
    "\n",
    "        if display:\n",
    "            plot_nxn(segmented, fileName='invert_region', save=True)  \n",
    "    \n",
    "    # MORPHOLOGY    \n",
    "    if morphology == 'dilate':\n",
    "        print(\"- morphological dilaton\")\n",
    "        if disk == None: \n",
    "            segmented = dilate_batch(segmented, disk_sizes=dilate_disk, display=display, save=save)\n",
    "        else: \n",
    "            segmented = dilate_batch(segmented, disk_sizes=disk, display=display, save=save)\n",
    "\n",
    "    elif morphology == 'erode':\n",
    "        print(\"- morphological erosion\")\n",
    "        if disk == None:\n",
    "            segmented = erode_batch(segmented, disk_sizes=erode_disk, display=display, save=save)\n",
    "        else:\n",
    "            segmented = erode_batch(segmented, disk_sizes=disk, display=display, save=save)\n",
    "            \n",
    "#     elif morphology == 'open':\n",
    "#            print(\"- morphological opening\")     \n",
    "#         segmented = \n",
    "#     elif morphology == 'close':\n",
    "#            print(\"- morphological closing\")\n",
    "#         segmented =\n",
    "\n",
    "    # CROPPING     \n",
    "    if manual_crop:\n",
    "        print(\"- cropping\")\n",
    "        segmented = crop_to_panel(segmented, crop_bg_value) \n",
    "        \n",
    "    # RETURN PROPERLY SIZED IMAGES\n",
    "    segmented = resize_images(segmented, height=192, width=192, display_status=False)\n",
    "\n",
    "    segmented = numpy_to_pil(segmented)\n",
    "    return segmented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4b192e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 4 - Multiplicative Gray-Level Segmentation\n",
    "#future improvement: images_binary should be a parameter. images_gray should be renamed to images.\n",
    "def multiplicative_procedure(images_gray, images_binary, set_id=None, params=None):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "    images_gray (numpy.ndarray or list of numpy.ndarray): A 2D numpy array or a list of 2D numpy arrays representing the grayscale image(s) to segment.\n",
    "    images_binary (numpy.ndarray or list of numpy.ndarray): A 2D numpy array or a list of 2D numpy arrays representing the binary segmented image(s) used to enhance the grayscale image.\n",
    "    set_id (str): An optional string to use as a prefix for display and/or save filenames, must be either 'clean' or 'dirty'\n",
    "    params (dict): An optional dictionary containing custom parameters to use for the multiplicative segmentation.\n",
    "\n",
    "    Returns:\n",
    "    list (PIL.Image.Image(s)): representing the multiplied images.\n",
    "    \"\"\"\n",
    "    multiplied = []\n",
    "    print(\"STEP 4: Performing the following tasks...\")\n",
    "    \n",
    "    # DEFAULT PARAMETERS\n",
    "    print(\"- setting default parameters: display, save\")\n",
    "    display = False\n",
    "    save = False    \n",
    "    # UNPACK CUSTOM PARAMETERS\n",
    "    if params is not None:\n",
    "        print(\"- unpacking custom parameters\")\n",
    "        print(\"ERROR: Custom Parameters not set up for this step. Terminating Process\")\n",
    "        return images_binary\n",
    "    \n",
    "    # CONVERSIONS & RESIZING\n",
    "    images_gray = numpy_to_pil(images_gray)  \n",
    "    images_binary = numpy_to_pil(images_binary)\n",
    "    print(\"- resizing images to 192x192\")\n",
    "    images_gray = resize_images(images_gray, height=192, width=192, display_status=False)\n",
    "    images_binary = resize_images(images_binary, height=192, width=192, display_status=False)\n",
    "        \n",
    "    images_gray = pil_to_numpy(images_gray)  \n",
    "    images_binary = pil_to_numpy(images_binary)\n",
    "\n",
    "    # MULTIPLICATION\n",
    "    counter = 1\n",
    "    print(\"- multiplying (grayscale enhanced * binary segmented) images\")\n",
    "    for im_g, im_b in zip(images_gray, images_binary):\n",
    "        gray_masked = im_g * im_b\n",
    "        multiplied.append(gray_masked)     \n",
    "        if save == True:\n",
    "            save_image(gray_masked, f'{set_id}{counter}_multiplied')\n",
    "        counter += 1\n",
    "    \n",
    "    multiplied = numpy_to_pil(multiplied)\n",
    "    return multiplied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6896ef04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 5 - Feature Retrieval (histogram data or HoG)\n",
    "def feature_procedure(images, benchmark=None, set_id=None, params=None):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "    images (numpy.ndarray or list of numpy.ndarray): A 2D numpy array or a list of 2D numpy arrays representing the image(s) to retrieve features from.\n",
    "    benchmark (numpy.ndarray or None): An optional 2D numpy array representing the benchmark image used for feature comparison.\n",
    "    set_id (str): An optional string to use as a prefix for display and/or save filenames, must be either 'clean' or 'dirty'\n",
    "    params (dict): An optional dictionary containing custom parameters to use for feature retrieval.\n",
    "\n",
    "    Returns:\n",
    "    tuple (numpy.ndarray or list of numpy.ndarray, list, numpy.ndarray or None): \n",
    "        - images: A 2D numpy array or a list of 2D numpy arrays representing the image(s) passed as input.\n",
    "        - feature_set: A list of feature data generated from the input image(s) using histogram data or HoG.\n",
    "        - benchmark_features: A 1D numpy array representing the feature data generated from the benchmark image, if provided. Returns None if benchmark is not provided.\n",
    "\n",
    "    \"\"\"\n",
    "    feature_set = []\n",
    "    print(\"STEP 5: Performing the following tasks...\")\n",
    "\n",
    "    # DEFAULT PARAMETERS\n",
    "    print(\"- setting default parameters: feature_type, display, save, use_hog\")\n",
    "    feature_type = 'hog'\n",
    "    display = False\n",
    "    save = False\n",
    "    # UNPACK PARAMETERS\n",
    "    if params is not None:\n",
    "        print(\"- unpacking custom parameters\")\n",
    "        print(\"ERROR: Custom Parameters not set up for this step. Terminating Process\")\n",
    "        return images\n",
    "        \n",
    "    # CONVERSIONS\n",
    "    images = numpy_to_pil(images)  \n",
    "\n",
    "    # RETRIEVE FEATURE DATA\n",
    "    if feature_type == 'hist':\n",
    "        print(\"- Histogram feature data generation\")\n",
    "        for image in images:\n",
    "            hist = image.histogram()\n",
    "            if display == True:\n",
    "                display_hist(image)\n",
    "            feature_set.append(hist)\n",
    "        if benchmark is not None:\n",
    "            benchmark_features = benchmark.histogram()\n",
    "    elif feature_type == 'hog':\n",
    "        print(\"- HoG feature data generation\")\n",
    "        hog_features, hog_images = display_hog(images, set_id=set_id, display=display, save=save)\n",
    "        feature_set = hog_features\n",
    "        if display == True: \n",
    "            plot_nxn(hog_images, fileName = f\"{set_id}_hog\", save=save)\n",
    "        if benchmark is not None:\n",
    "            benchmark_hog_features, benchmark_hog_image = display_hog(benchmark, set_id=set_id, display=display, save=save)\n",
    "            benchmark_features = benchmark_hog_features[0]\n",
    "            \n",
    "    return images, feature_set, benchmark_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "178bf6a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## STEP 6 - Calculate Similarity\n",
    "def similarity_procedure(images, benchmark, features, benchmark_features, set_id=None, params=None):\n",
    "    \"\"\"\n",
    "    This function calculates the similarity between the input images and a benchmark image using a specified distance measure on both the image data and feature data.\n",
    "    \n",
    "    Parameters:\n",
    "    images (numpy.ndarray or list of numpy.ndarray): A 2D numpy array or a list of 2D numpy arrays representing the image(s) to calculate similarity for.\n",
    "    benchmark (numpy.ndarray): A 2D numpy array representing the benchmark image.\n",
    "    features (list): A list of feature data generated from the input image(s) using histogram data or HoG.\n",
    "    benchmark_features (numpy.ndarray): A 1D numpy array representing the feature data generated from the benchmark image.\n",
    "    set_id (str): An optional string to use as a prefix for display and/or save filenames, must be either 'clean' or 'dirty'\n",
    "    params (dict): An optional dictionary containing custom parameters to use for calculating similarity.\n",
    "\n",
    "    Returns:\n",
    "    tuple (numpy.ndarray or list of numpy.ndarray, list, list): \n",
    "    - images: A 2D numpy array or a list of 2D numpy arrays representing the image(s) passed as input.\n",
    "    - image_distances: A list of distances calculated between the input images and the benchmark image using the specified distance measure on image data.\n",
    "    - feature_distances: A list of distances calculated between the input images' features and the benchmark image's features using the specified distance measure on feature data.\n",
    "    \"\"\"\n",
    "    image_distances = []\n",
    "    feature_distances = []\n",
    "    print(\"STEP 6: Performing the following tasks...\")\n",
    "    \n",
    "    # DEFAULT PARAMETERS\n",
    "    print(\"- setting default parameters: measure, display, save\")\n",
    "    measure = 'chi2'\n",
    "    display = False\n",
    "    save = False\n",
    "    # UNPACK PARAMETERS\n",
    "    if params is not None:\n",
    "        print(\"- unpacking custom parameters\")\n",
    "        print(\"ERROR: Custom Parameters not set up for this step. Terminating Process\")\n",
    "        return images\n",
    "    \n",
    "    # calculate differences\n",
    "    print(f\"- calculating {measure} measure on image data\")\n",
    "    for image in images:\n",
    "        distance = calculate_data_distance(image, benchmark, measure=measure)\n",
    "        image_distances.append(distance)\n",
    "\n",
    "    print(f\"- calculating {measure} measure on feature data\")\n",
    "    \n",
    "    for feature in features:     \n",
    "        distance = calculate_data_distance(feature, benchmark_features, data_mode='feature', measure=measure)\n",
    "        feature_distances.append(distance)\n",
    "\n",
    "#     if measure == 'chi2':\n",
    "#         print(\"- calculating chi2 measure\")\n",
    "#         image_distance = chi_squared_onimages(images, benchmark)\n",
    "#         feature_distance = chi_squared_onfeatures(features, benchmark_features)\n",
    "\n",
    "    return images, image_distances, feature_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f90c9f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # STEP 6 - Calculate Similarity\n",
    "# def similarity_procedure(images, benchmark, features, benchmark_features, set_id=None, params=None):\n",
    "#     distances = []\n",
    "#     print(\"STEP 6: Performing the following tasks...\")\n",
    "    \n",
    "#     # DEFAULT PARAMETERS\n",
    "#     print(\"- setting default parameters: measure, display, save\")\n",
    "#     measure = 'chi2'\n",
    "#     display = False\n",
    "#     save = False\n",
    "#     # UNPACK PARAMETERS\n",
    "#     if params is not None:\n",
    "#         print(\"- unpacking custom parameters\")\n",
    "#         print(\"ERROR: Custom Parameters not set up for this step. Terminating Process\")\n",
    "#         return images\n",
    "    \n",
    "# #     # generate benchmark features\n",
    "# #     benchmark_features, benchmark_hog_images = display_hog(benchmark_set, set_id='dirty', display=display, save=save)\n",
    "\n",
    "#     # calculate differences\n",
    "#     if measure == 'linear':\n",
    "#         print(\"- WARNING: linear calculation is not built\")\n",
    "#     if measure == 'chi2':\n",
    "#         print(\"- calculating chi2 measure\")\n",
    "#         image_distance = chi_squared_onimages(images, benchmark)\n",
    "#         feature_distance = chi_squared_onfeatures(features, benchmark_features)\n",
    "\n",
    "# #       \n",
    "# #         for hog_features in hog_features_set:\n",
    "# #             # calculate the chi-squared distance between the histograms\n",
    "# # #             distance = chi2(hog_features_benchmark[0], hog_features)\n",
    "# #             distance = chisquare(hog_features_benchmark[0], hog_features)\n",
    "# #             chi2_dists.append(distance)\n",
    "# #             print(distance)\n",
    "\n",
    "#     return images, image_distance, feature_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d98adc5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def similarity_procedure(images, benchmark, set_id=None, measure=None, params=None, display=False, save=False):\n",
    "#     # generate two hog descriptors\n",
    "# reference_img = final_clean[6]\n",
    "# dist_set=[]\n",
    "# #for dirty_image in final_dirty:\n",
    "# dis_set = chi_squared(final_dirty, reference_img)   \n",
    "#     if measure == 'linear':\n",
    "#         print(\"not built\")\n",
    "#         print(\"not built\")\n",
    "#     if measure == 'chi2':\n",
    "#         chi2_dists = []\n",
    "#         hog_features_benchmark, hog_images_benchmark = display_hog(benchmark, set_id='dirty', display=display, save=save)\n",
    "#         hog_features_set, hog_set = display_hog(images, set_id='dirty', display=display, save=save)\n",
    "# #         distance = chi2_distance(hog_features_benchmark[0], hog_features_set[0])\n",
    "# #         print(distance)\n",
    "\n",
    "#        distance = chi2_distance(hog_features_set, \n",
    "# #       \n",
    "# #         for hog_features in hog_features_set:\n",
    "# #             # calculate the chi-squared distance between the histograms\n",
    "# # #             distance = chi2(hog_features_benchmark[0], hog_features)\n",
    "# #             distance = chisquare(hog_features_benchmark[0], hog_features)\n",
    "# #             chi2_dists.append(distance)\n",
    "# #             print(distance)\n",
    "\n",
    "#     return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "007c37c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nlook at section 3's remainder to see if it's useful for HOG gradients\\n\\n\\nremainder = np.array(target_sobel_max) - np.array(reference_sobel_max)  \\n#print(np.array(target_sobel_max).min(), np.array(target_sobel_max).max())  \\nremainder = np.clip(remainder, 0, 255)  \\ndisplay_image(target_sobel_max)  \\ndisplay_image(reference_sobel_max)  \\ndisplay_image(remainder)  \\n\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "look at section 3's remainder to see if it's useful for HOG gradients\n",
    "\n",
    "\n",
    "remainder = np.array(target_sobel_max) - np.array(reference_sobel_max)  \n",
    "#print(np.array(target_sobel_max).min(), np.array(target_sobel_max).max())  \n",
    "remainder = np.clip(remainder, 0, 255)  \n",
    "display_image(target_sobel_max)  \n",
    "display_image(reference_sobel_max)  \n",
    "display_image(remainder)  \n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5c284da",
   "metadata": {},
   "source": [
    "[GO TO TOP](#top)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f27b578",
   "metadata": {},
   "source": [
    "<a id=\"feature-extraction\"></a>\n",
    "-----------------------------\n",
    "## Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09edbc87",
   "metadata": {},
   "source": [
    "#### Shape & Contour Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1e5b042d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_moments(image):\n",
    "    image = pil_to_numpy(image)\n",
    "    # find indices of all white pixels in the image\n",
    "    rows, cols = np.where(image == 255)\n",
    "    x_points = (cols.min(), cols.max())\n",
    "    y_points = (rows.min(), rows.max())\n",
    "    start_and_end = (x_points, y_points)\n",
    "#     print(\"Min(X,Y): (\", cols.min(), \",\", rows.min(),\") and Max(X,Y): (\",cols.max(), \",\", rows.max(),\")\")\n",
    "\n",
    "    # calculate mean x and y coordinates of white pixels\n",
    "    x_bar = np.mean(cols)\n",
    "    y_bar = np.mean(rows)\n",
    "    \n",
    "    # calculate second moments in x and y direction\n",
    "    mu20 = np.mean((cols - x_bar)**2)\n",
    "    mu02 = np.mean((rows - y_bar)**2)\n",
    "    mu11 = np.mean((cols - x_bar)*(rows - y_bar))\n",
    "\n",
    "    return x_bar, y_bar, mu20, mu02, mu11, start_and_end\n",
    "\n",
    "def calculate_axes(image, display=False):\n",
    "    image = pil_to_numpy(image)\n",
    "    # calculate moments of the object\n",
    "    x_bar, y_bar, mu20, mu02, mu11, start_and_end = calculate_moments(image)\n",
    "    \n",
    "    # calculate major and minor axes of the object\n",
    "    major_axis = np.sqrt(((mu20 + mu02) + np.sqrt((mu20 - mu02)**2 + 4*mu11**2))/2)\n",
    "    minor_axis = np.sqrt(((mu20 + mu02) - np.sqrt((mu20 - mu02)**2 + 4*mu11**2))/2)\n",
    "    \n",
    "    # calculate angle of rotation of the major axis\n",
    "    if mu20 > mu02:\n",
    "        angle = np.arctan((2*mu11)/(mu20 - mu02))/2\n",
    "    else:\n",
    "        angle = np.pi/2 - np.arctan((2*mu11)/np.abs(mu02 - mu20))/2\n",
    "        \n",
    "    # get the integer part and float part using divmod()\n",
    "    extra_int, angle = divmod(angle, 1)\n",
    "    \n",
    "    if display:\n",
    "#         print(\"\\nx_bar: \", x_bar,\n",
    "#               \"\\ny_bar: \", y_bar,\n",
    "#               \"\\nmu20: \", mu20,\n",
    "#               \"\\nmu02: \", mu02,\n",
    "#               \"\\nmu11: \", mu11)\n",
    "        print(\"\\nmajor_axis: \", major_axis,\n",
    "              \"\\nminor_axis: \", minor_axis,\n",
    "              \"\\nangle: \", angle) \n",
    "    return major_axis, minor_axis, x_bar, y_bar, angle, start_and_end\n",
    "\n",
    "def visualize_axes(image, x_bar, y_bar, x1, x2, x3, x4, y1, y2, y3, y4):\n",
    "        \n",
    "    # draw the major and minor axes on the image\n",
    "    image_with_axes = cv2.cvtColor(image, cv2.COLOR_GRAY2BGR)\n",
    "    cv2.line(image_with_axes, (x1, y1), (x2, y2), (0, 0, 255), thickness=2)\n",
    "    cv2.line(image_with_axes, (x3, y3), (x4, y4), (0, 255, 0), thickness=2)\n",
    "    cv2.circle(image_with_axes, (int(x_bar), int(y_bar)), 5, (255, 0, 0), -1)\n",
    "    return image_with_axes\n",
    "\n",
    "def major_minor_axes(image, display=False):\n",
    "    image = pil_to_numpy(image)\n",
    "    \n",
    "    #calculate axes\n",
    "    major_axis, minor_axis, x_bar, y_bar, angle, start_and_end = calculate_axes(image, display)\n",
    "    \n",
    "    #calculate line information\n",
    "    x_points = start_and_end[0]\n",
    "    y_points = start_and_end[1]\n",
    "    \n",
    "    # calculate the endpoints of the major axis\n",
    "    cos_angle = np.cos(angle)\n",
    "    sin_angle = np.sin(angle)\n",
    "    \n",
    "    major_slope = -sin_angle/cos_angle\n",
    "    major_intercept = y_bar - major_slope*x_bar\n",
    "    x1 = x_points[0]\n",
    "    y1 = int(major_slope*x1 + major_intercept)\n",
    "    x2 = x_points[1]\n",
    "    y2 = int(major_slope*x2 + major_intercept)\n",
    "        \n",
    "    # calculate the endpoints of the minor axis\n",
    "    minor_slope = cos_angle/sin_angle\n",
    "    minor_intercept = y_bar - minor_slope*x_bar\n",
    "    y3 = y_points[0]\n",
    "    x3 = int((y3 - minor_intercept)/minor_slope)\n",
    "    y4 = y_points[1]\n",
    "    x4 = int((y4 - minor_intercept)/minor_slope)\n",
    "        \n",
    "    # calculate major and minor line lengths\n",
    "    major_length = np.sqrt((x2-x1)**2 + (y2-y1)**2)\n",
    "    minor_length = np.sqrt((x4-x3)**2 + (y4-y3)**2)\n",
    "    \n",
    "    # print out major and minor line lengths\n",
    "    if display:\n",
    "        print(\"major color: blue | axis: x-horizontal\")\n",
    "        print(\"major start: (\", x1, \",\", y1, \") | major end (\", x2, \",\", y2, \") | major slope: \", major_slope, \"| major_intercept: \", major_intercept)\n",
    "        \n",
    "        print(\"minor color: green | axis: y-vertical\")\n",
    "        print(\"minor start: (\", x3, \",\", y3, \") | minor end (\", x4, \",\", y4, \") | minor slope: \", minor_slope, \"| minor_intercept: \", minor_intercept)\n",
    "    \n",
    "        print(\"major_length: \", major_length, \"\\nminor_length: \", minor_length)\n",
    "    \n",
    "    if display:\n",
    "        image_with_axes = visualize_axes(image, x_bar, y_bar, x1, x2, x3, x4, y1, y2, y3, y4)\n",
    "        return image_with_axes, major_length, minor_length, angle\n",
    "    else:\n",
    "        axes_features = np.array([major_length, minor_length, angle])\n",
    "        return axes_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eeca943",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_bounding_box(image, start_and_end, display=False):\n",
    "    # calculate the coordinates of the bounding box corners\n",
    "    x_points = start_and_end[0]\n",
    "    y_points = start_and_end[1] \n",
    "    \n",
    "    x1 = x_points[0]\n",
    "    y1 = y_points[0]\n",
    "    x2 = x_points[1]\n",
    "    y2 = y_points[0]\n",
    "    x3 = x_points[0]\n",
    "    y3 = y_points[1]\n",
    "    x4 = x_points[1]\n",
    "    y4 = y_points[1]\n",
    "    if display:\n",
    "        print(\"bounding box corners: (\", x1, \",\", y1, \"), (\", x2, \",\", y2, \"), (\", x3, \",\", y3, \"), (\", x4, \",\", y4, \")\")\n",
    "    \n",
    "    # draw the bounding box as a set of contours using the display_contours function\n",
    "#     contours = [[[x1, y1]], [[x2, y2]], [[x3, y3]], [[x4, y4]]]\n",
    "#     display_bounding_contours(image, contours)\n",
    "    # draw the bounding box on the image\n",
    "    image_with_axes = cv2.cvtColor(image, cv2.COLOR_GRAY2BGR)\n",
    "    cv2.rectangle(image_with_axes, (x1, y1), (x4, y4), (255, 0, 0), 2)\n",
    "\n",
    "    # return the bounding box coordinates\n",
    "#     return x1, y1, x2, y2, x3, y3, x4, y4\n",
    "    return image_with_axes\n",
    "\n",
    "def fill_bounding_box(image, start_and_end, fill_value=255):\n",
    "    x1 = start_and_end[0][0]\n",
    "    y1 = start_and_end[1][0]\n",
    "    x2 = start_and_end[0][1]\n",
    "    y2 = start_and_end[1][1]\n",
    "    \n",
    "    image = numpy_to_pil(image)\n",
    "    draw = ImageDraw.Draw(image)\n",
    "    draw.rectangle((x1,y1,x2,y2), fill=fill_value, outline=None)\n",
    "#     image.show()\n",
    "\n",
    "    return image.convert('L')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2525db0",
   "metadata": {},
   "source": [
    "#### LBP Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e3dc5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lbp_pixel(img, center, x, y):\n",
    "    img = pil_to_numpy(img)\n",
    "    value = 0\n",
    "    if img[x][y] >= center:\n",
    "        value = 1\n",
    "    return value\n",
    "\n",
    "def get_lbp_code(img, x, y):\n",
    "    img = pil_to_numpy(img)\n",
    "    center = img[x][y]\n",
    "    code = 0\n",
    "    code |= get_lbp_pixel(img, center, x-1, y-1) << 7\n",
    "    code |= get_lbp_pixel(img, center, x-1, y) << 6\n",
    "    code |= get_lbp_pixel(img, center, x-1, y+1) << 5\n",
    "    code |= get_lbp_pixel(img, center, x, y+1) << 4\n",
    "    code |= get_lbp_pixel(img, center, x+1, y+1) << 3\n",
    "    code |= get_lbp_pixel(img, center, x+1, y) << 2\n",
    "    code |= get_lbp_pixel(img, center, x+1, y-1) << 1\n",
    "    code |= get_lbp_pixel(img, center, x, y-1) << 0\n",
    "    return code\n",
    "\n",
    "def get_lbp_feature(img, title=None, status=None, m=None, n=None, display=False, save=False):\n",
    "    img = pil_to_numpy(img)\n",
    "    height, width = img.shape\n",
    "    lbp_img = np.zeros((height, width), np.uint8)\n",
    "    for i in range(1, height-1):\n",
    "        for j in range(1, width-1):\n",
    "            lbp_img[i][j] = get_lbp_code(img, i, j)\n",
    "    hist, _ = np.histogram(lbp_img.ravel(), bins=256, range=(0, 256))\n",
    "    hist = hist.astype(\"float\")\n",
    "    hist /= (hist.sum() + 1e-7)\n",
    "    \n",
    "    if display:\n",
    "        # retrieve plot colors from main file\n",
    "        %store -r plt_color\n",
    "        %store -r label_color\n",
    "        %store -r title_color\n",
    "\n",
    "        with plt.rc_context({'axes.edgecolor':label_color, 'xtick.color':label_color, 'ytick.color':label_color}):\n",
    "            if m is not None:\n",
    "                fig = plt.figure(figsize=(m,n))\n",
    "            else:\n",
    "                fig = plt.figure(figsize=(8,2))\n",
    "\n",
    "        # Plot the contour and the chain code\n",
    "        _ = fig.add_subplot(1,2,1)\n",
    "        plt.imshow(lbp_img, cmap='gray')\n",
    "        plt.axis('off')\n",
    "        plt.title(f'{status} LBP Image', color = title_color)\n",
    "\n",
    "        _ = fig.add_subplot(1,2,2)\n",
    "        plt.plot(hist, color= plt_color)\n",
    "        plt.axis('off')\n",
    "        plt.title(f'{status} LBP Histogram',  color = title_color)\n",
    "\n",
    "        if save == True:\n",
    "            _ = fig.savefig(f'{status}_LBP.png', dpi = 300, transparent=True, bbox_inches=\"tight\")\n",
    "        plt.show()\n",
    "\n",
    "    return hist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "702293dc",
   "metadata": {},
   "source": [
    "#### Circularity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "68c01daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_circularity(image, return_as='value', display=False):\n",
    "    area = np.sum(image > 0)\n",
    "    perimeter = np.sum(feature.canny(image))\n",
    "    circularity = 4 * np.pi * area / (perimeter ** 2) if perimeter > 0 else 0\n",
    "    \n",
    "    if display:\n",
    "        print(\"Circularity = \", circularity)\n",
    "    \n",
    "    if return_as == 'value':\n",
    "        return circularity\n",
    "    if return_as == 'feature':\n",
    "        circularity_feature = np.array([circularity])\n",
    "        return circularity_feature\n",
    "    else:\n",
    "        raise TypeError(\"return_as must be either 'value' for a float return, or 'feature' for an array return.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2c4c4b9",
   "metadata": {},
   "source": [
    "<a id=\"downsample-upsample\"></a>\n",
    "-----------------------------\n",
    "### DOWNSAMPLE AND UPSAMPLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "81362c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def upscale_with_zeros(image, factor=2, display=False):\n",
    "    image = pil_to_numpy(image)\n",
    "    height, width = image.shape\n",
    "    upscaled_image = np.zeros((height * factor, width * factor), dtype=image.dtype)\n",
    "    upscaled_image[::factor, ::factor] = image\n",
    "    \n",
    "    if display:\n",
    "        display_image(upscaled_image)\n",
    "        \n",
    "    upscaled_image = numpy_to_pil(upscaled_image)\n",
    "    return upscaled_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4fa161f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def downsample(img):\n",
    "#     return img.resize((img.width // 2, img.height // 2), Image.BICUBIC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "14c8d529",
   "metadata": {},
   "outputs": [],
   "source": [
    "def downscale_gaussian(image, factor, n, display=False):\n",
    "    def downscale_once(image, factor):\n",
    "        image = numpy_to_pil(image)\n",
    "        blurred_image, kernel = filter_gaussian2(image, sigma=1)\n",
    "        return pil_to_numpy(blurred_image)[::factor, ::factor], kernel\n",
    "\n",
    "    pyramid = []\n",
    "    pyramid.append(pil_to_numpy(image))\n",
    "    for _ in range(n):\n",
    "        image, kernel = downscale_once(image, factor)\n",
    "        pyramid.append(image)\n",
    "  \n",
    "    if display:\n",
    "        print(\"NEW RESOLUTIONS\")\n",
    "        for i, arr in enumerate(pyramid):\n",
    "            print(f\"downsize #{i}\", pyramid[i].shape)\n",
    "        plot_nxn(pyramid)\n",
    "        \n",
    "    pyramid = numpy_to_pil(pyramid)\n",
    "    return pyramid, kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6191c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def upscale_laplacian(pyramid, factor, display=False):\n",
    "# #     def upscale_once(image, factor):\n",
    "# #         image = numpy_to_pil(image)\n",
    "# #         upscaled_image = image.resize((image.width * factor, image.height * factor), Image.BICUBIC)\n",
    "# #         return pil_to_numpy(upscaled_image)\n",
    "    \n",
    "# #     laplacian_pyramid = [pyramid[-1]]\n",
    "# #     for i in range(len(pyramid) - 2, -1, -1):\n",
    "# #         upscaled_image = upscale_once(laplacian_pyramid[-1], factor)\n",
    "# #         laplacian_level = pyramid[i] - upscaled_image\n",
    "# #         laplacian_pyramid.append(laplacian_level)\n",
    "\n",
    "# #     reconstructed_image = pyramid[0] + laplacian_pyramid[-1]\n",
    "    \n",
    "#     if display:\n",
    "#         print(\"NEW RESOLUTIONS\")\n",
    "#         for i, arr in enumerate(pyramid):\n",
    "#             print(f\"upscaled #{i}\", pyramid[i].shape)\n",
    "#         plot_nxn(pyramid)\n",
    "        \n",
    "#     return pyramid, reconstructed_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "149dc263",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Your understanding of the Laplacian pyramid theory is mostly correct. However, there's a small correction. Instead of subtracting the original image from the Laplacian image, you actually subtract the upscaled and blurred image from the original image to obtain the Laplacian pyramid. The process can be summarized as:\n",
    "\n",
    "    Create a Gaussian pyramid by successively downsampling and blurring the original image.\n",
    "    For each level of the Gaussian pyramid:\n",
    "    a. Upscale the image to the size of the next level up.\n",
    "    b. Blur the upscaled image using the same Gaussian kernel.\n",
    "    c. Subtract the blurred, upscaled image from the Gaussian image at the next level up to obtain the Laplacian image for that level.\n",
    "\n",
    "To reconstruct the image from the Laplacian pyramid, you perform the inverse operations, starting from the smallest level and working your way up.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c7143c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def build_gaussian_pyramid(image, n):\n",
    "#     pyramid = [image]\n",
    "#     for _ in range(n - 1):\n",
    "#         image = image.filter(ImageFilter.GaussianBlur(radius=1))\n",
    "#         pyramid.append(image)\n",
    "#     return pyramid\n",
    "\n",
    "# def build_laplacian_pyramid(gaussian_pyramid):\n",
    "#     laplacian_pyramid = []\n",
    "#     for i in range(len(gaussian_pyramid) - 1):\n",
    "#         upsampled = upsample(gaussian_pyramid[i + 1])\n",
    "#         laplacian = Image.fromarray(np.subtract(np.array(gaussian_pyramid[i]), np.array(upsampled)))\n",
    "#         laplacian_pyramid.append(laplacian)\n",
    "#     laplacian_pyramid.append(gaussian_pyramid[-1])\n",
    "#     return laplacian_pyramid\n",
    "\n",
    "# def upscale_laplacian(laplacian_pyramid, n):\n",
    "#     result = laplacian_pyramid[-1]\n",
    "#     for i in range(n - 1, -1, -1):\n",
    "#         result = Image.fromarray(np.add(np.array(upsample(result)), np.array(laplacian_py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f98c30f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def upscale_laplacian(pyramid, factor, n):\n",
    "#     def upscale_once(image, factor):\n",
    "#         image = numpy_to_pil(image)\n",
    "#         width, height = image.size\n",
    "#         new_size = (int(width * factor), int(height * factor))\n",
    "#         upscaled_image = image.resize(new_size, resample=Image.BICUBIC)\n",
    "#         return pil_to_numpy(upscaled_image)\n",
    "\n",
    "#     laplacian_pyramid = []\n",
    "#     for i in range(n, 0, -1):\n",
    "#         image = pyramid[i]\n",
    "#         next_image = pyramid[i - 1] if i > 1 else None\n",
    "\n",
    "#         # Upscale the image and subtract it from the next level in the pyramid\n",
    "#         upscaled_image = upscale_once(image, factor)\n",
    "#         if next_image is not None:\n",
    "#             next_width, next_height = next_image.shape\n",
    "#             upscaled_image = upscaled_image[:next_width, :next_height]\n",
    "#             next_image = next_image - upscaled_image\n",
    "\n",
    "#         # Compute the Laplacian\n",
    "#         laplacian = convolve_image(image, kernel3x3_laplacian1)\n",
    "#         laplacian = np.array(laplacian)\n",
    "#         laplacian = laplacian - upscaled_image if next_image is not None else laplacian\n",
    "#         laplacian_pyramid.append(laplacian)\n",
    "\n",
    "#     # Reverse the Laplacian pyramid and add the original image at the top\n",
    "#     laplacian_pyramid = laplacian_pyramid[::-1]\n",
    "#     laplacian_pyramid.append(pyramid[0])\n",
    "\n",
    "#     return laplacian_pyramid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2926cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def upscale_laplacian(pyramid, factor, n):\n",
    "    pyramid = pil_to_numpy(pyramid)\n",
    "    \n",
    "    laplacian_pyramid = []\n",
    "    for i in range(n, 0, -1):\n",
    "        image = pyramid[i]\n",
    "        next_image = pyramid[i - 1] if i > 1 else None\n",
    "\n",
    "        # Upscale the image and subtract it from the next level in the pyramid\n",
    "        upscaled_image = upscale_with_zeros(image, factor)\n",
    "        upscaled_image = pil_to_numpy(upscaled_image)\n",
    "        print(\"Upscaled Image Shape1: \", upscaled_image.shape)\n",
    "        if next_image is not None:\n",
    "            next_width, next_height = next_image.shape\n",
    "            upscaled_image = upscaled_image[:next_width, :next_height]\n",
    "            next_image = next_image - upscaled_image\n",
    "\n",
    "        # Compute the Laplacian\n",
    "        laplacian = convolve_image(image, kernel3x3_laplacian1)\n",
    "        laplacian = np.array(laplacian)\n",
    "        print(\"Laplacian Shape: \", laplacian.shape)\n",
    "        print(\"Upscaled Image Shape2: \", upscaled_image.shape)\n",
    "        laplacian = laplacian - upscaled_image if next_image is not None else laplacian\n",
    "        laplacian_pyramid.append(laplacian)\n",
    "\n",
    "    # Reverse the Laplacian pyramid and add the original image at the top\n",
    "    laplacian_pyramid = laplacian_pyramid[::-1]\n",
    "    laplacian_pyramid.append(pyramid[0])\n",
    "\n",
    "    return laplacian_pyramid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c045a3b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "aafe984e",
   "metadata": {},
   "source": [
    "[GO TO TOP](#top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a4b9159",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def generate_gaussian_pyramid(image, num_levels, downscale_factor):\n",
    "#     pyramid = [image]\n",
    "#     for i in range(1, num_levels):\n",
    "#         image = image.filter(ImageFilter.GaussianBlur(downscale_factor))\n",
    "#         image = image.resize((image.width // 2, image.height // 2), Image.ANTIALIAS)\n",
    "#         pyramid.append(image)\n",
    "#     return pyramid\n",
    "\n",
    "# def generate_laplacian_pyramid(gaussian_pyramid):\n",
    "#     laplacian_pyramid = []\n",
    "#     for i in range(len(gaussian_pyramid) - 1):\n",
    "#         size = (gaussian_pyramid[i].width, gaussian_pyramid[i].height)\n",
    "#         upscale = gaussian_pyramid[i + 1].resize(size, Image.ANTIALIAS)\n",
    "#         laplacian = ImageChops.subtract(gaussian_pyramid[i], upscale)\n",
    "#         laplacian_pyramid.append(laplacian)\n",
    "#     laplacian_pyramid.append(gaussian_pyramid[-1])\n",
    "#     return laplacian_pyramid\n",
    "\n",
    "# def blend_pyramids(laplacian_pyramid1, laplacian_pyramid2, mask_pyramid):\n",
    "#     blended_pyramid = []\n",
    "#     for i in range(len(laplacian_pyramid1)):\n",
    "#         laplacian1 = np.asarray(laplacian_pyramid1[i])\n",
    "#         laplacian2 = np.asarray(laplacian_pyramid2[i])\n",
    "#         mask = np.asarray(mask_pyramid[i]) / 255.0\n",
    "#         blended = laplacian1 * mask + laplacian2 * (1.0 - mask)\n",
    "#         blended_pyramid.append(Image.fromarray(blended.astype(np.uint8)))\n",
    "#     return blended_pyramid\n",
    "\n",
    "# def reconstruct_image_from_laplacian_pyramid(laplacian_pyramid):\n",
    "#     image = laplacian_pyramid[-1]\n",
    "#     for i in range(len(laplacian_pyramid) - 2, -1, -1):\n",
    "#         size = (laplacian_pyramid[i].width, laplacian_pyramid[i].height)\n",
    "#         image = image.resize(size, Image.ANTIALIAS)\n",
    "#         image = ImageChops.add(image, laplacian_pyramid[i])\n",
    "#     return image\n",
    "\n",
    "# def image_blending(img1, img2, mask, num_levels=4, downscale_factor=2, laplacian_kernel=None):\n",
    "#     img1_gray = img1.convert(\"L\")\n",
    "#     img2_gray = img2.convert(\"L\")\n",
    "#     mask_gray = mask.convert(\"L\")\n",
    "    \n",
    "#     img1_gaussian = generate_gaussian_pyramid(img1_gray, num_levels, downscale_factor)\n",
    "#     img2_gaussian = generate_gaussian_pyramid(img2_gray, num_levels, downscale_factor)\n",
    "#     mask_gaussian = generate_gaussian_pyramid(mask_gray, num_levels, downscale_factor)\n",
    "\n",
    "#     img1_laplacian = generate_laplacian_pyramid(img1_gaussian)\n",
    "#     img2_laplacian = generate_laplacian_pyramid(img2_gaussian)\n",
    "\n",
    "#     blended_pyramid = blend_pyramids(img1_laplacian, img2_laplacian, mask_gaussian)\n",
    "#     blended_image = reconstruct_image_from_laplacian_pyramid(blended_pyramid)\n",
    "\n",
    "#     return blended_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbcd2d56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5b2979f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00c558b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c887d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# from PIL import Image, ImageFilter, ImageChops\n",
    "\n",
    "# def generate_gaussian_pyramid(image, num_levels, downscale_factor):\n",
    "#     pyramid = [image]\n",
    "#     for i in range(1, num_levels):\n",
    "#         image = image.filter(ImageFilter.GaussianBlur(downscale_factor))\n",
    "#         image = image.resize((image.width // 2, image.height // 2), Image.ANTIALIAS)\n",
    "#         pyramid.append(image)\n",
    "#     return pyramid\n",
    "\n",
    "# def apply_laplacian_kernel(image, kernel):\n",
    "#     return image.filter(ImageFilter.Kernel(kernel.size, kernel.kernel, kernel.scale))\n",
    "\n",
    "# def generate_laplacian_pyramid(gaussian_pyramid, laplacian_kernel):\n",
    "#     laplacian_pyramid = []\n",
    "#     for i in range(len(gaussian_pyramid) - 1):\n",
    "#         size = (gaussian_pyramid[i].width, gaussian_pyramid[i].height)\n",
    "#         upscale = gaussian_pyramid[i + 1].resize(size, Image.ANTIALIAS)\n",
    "#         laplacian = ImageChops.subtract(gaussian_pyramid[i], upscale)\n",
    "#         if laplacian_kernel:\n",
    "#             laplacian = apply_laplacian_kernel(laplacian, laplacian_kernel)\n",
    "#         laplacian_pyramid.append(laplacian)\n",
    "#     laplacian_pyramid.append(gaussian_pyramid[-1])\n",
    "#     return laplacian_pyramid\n",
    "\n",
    "# def blend_pyramids(laplacian_pyramid1, laplacian_pyramid2, mask_pyramid):\n",
    "#     blended_pyramid = []\n",
    "#     for i in range(len(laplacian_pyramid1)):\n",
    "#         laplacian1 = np.asarray(laplacian_pyramid1[i])\n",
    "#         laplacian2 = np.asarray(laplacian_pyramid2[i])\n",
    "#         mask = np.asarray(mask_pyramid[i]) / 255.0\n",
    "#         blended = laplacian1 * mask + laplacian2 * (1.0 - mask)\n",
    "#         blended_pyramid.append(Image.fromarray(blended.astype(np.uint8)))\n",
    "#     return blended_pyramid\n",
    "\n",
    "# def reconstruct_image_from_laplacian_pyramid(laplacian_pyramid):\n",
    "#     image = laplacian_pyramid[-1]\n",
    "#     for i in range(len(laplacian_pyramid) - 2, -1, -1):\n",
    "#         size = (laplacian_pyramid[i].width, laplacian_pyramid[i].height)\n",
    "#         image = image.resize(size, Image.ANTIALIAS)\n",
    "#         image = ImageChops.add(image, laplacian_pyramid[i])\n",
    "#     return image\n",
    "\n",
    "# def image_blending(img1, img2, mask, num_levels=4, downscale_factor=2, laplacian_kernel=None):\n",
    "#     img1_gray = img1.convert(\"L\")\n",
    "#     img2_gray = img2.convert(\"L\")\n",
    "#     mask_gray = mask.convert(\"L\")\n",
    "    \n",
    "#     img1_gaussian = generate_gaussian_pyramid(img1_gray, num_levels, downscale_factor)\n",
    "#     img2_gaussian = generate_gaussian_pyramid(img2_gray, num_levels, downscale_factor)\n",
    "#     mask_gaussian = generate_gaussian_pyramid(mask_gray, num_levels, downscale_factor)\n",
    "\n",
    "#     img1_laplacian = generate_laplacian_pyramid(img1_gaussian, laplacian_kernel)\n",
    "#     img2_laplacian = generate_laplacian_pyramid(img2_gaussian, laplacian_kernel)\n",
    "\n",
    "#     blended_pyramid = blend_pyramids(img1_laplacian,\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c086cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_laplacian_pyramid_fun(gaussian_pyramid, laplacian_kernel):\n",
    "    laplacian_pyramid = []\n",
    "    for i in range(len(gaussian_pyramid) - 1):\n",
    "        size = (gaussian_pyramid[i].width, gaussian_pyramid[i].height)\n",
    "#         print(f\"gaussian {i} size =\", size)\n",
    "#         print(f\"gaussian {i+1} size =\", pil_to_numpy(gaussian_pyramid[i+1]).shape)\n",
    "#         upscale = gaussian_pyramid[i + 1].resize(size, Image.ANTIALIAS)\n",
    "        upscale = upscale_with_zeros(gaussian_pyramid[i+1])\n",
    "#         print(f\"gaussian {i+1} upscale resize =\", pil_to_numpy(upscale).shape)\n",
    "        laplacian = ImageChops.subtract(gaussian_pyramid[i], upscale)\n",
    "        \n",
    "        if laplacian_kernel is not None:\n",
    "            laplacian = convolve_image(laplacian, laplacian_kernel)\n",
    "\n",
    "        laplacian_pyramid.append(laplacian)\n",
    "        \n",
    "    laplacian_pyramid.append(gaussian_pyramid[-1])\n",
    "    \n",
    "    return laplacian_pyramid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fee689b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image, ImageFilter, ImageChops\n",
    "\n",
    "def generate_laplacian_pyramid2(gaussian_pyramid, laplacian_kernel=None):\n",
    "    laplacian_pyramid = []\n",
    "    for i in range(len(gaussian_pyramid) - 1):\n",
    "#         size = (gaussian_pyramid[i].width, gaussian_pyramid[i].height)\n",
    "#         print(f\"gaussian {i} size =\", size)\n",
    "#         print(f\"gaussian {i+1} size =\", pil_to_numpy(gaussian_pyramid[i+1]).shape)\n",
    "#         upscale = gaussian_pyramid[i + 1].resize(size, Image.ANTIALIAS)\n",
    "        upscale = upscale_with_zeros(gaussian_pyramid[i+1])\n",
    "#         print(f\"gaussian {i+1} upscale resize =\", pil_to_numpy(upscale).shape)\n",
    "        laplacian = ImageChops.subtract(gaussian_pyramid[i], upscale)\n",
    "        \n",
    "        if laplacian_kernel is not None:\n",
    "            laplacian = convolve_image(laplacian, laplacian_kernel)\n",
    "\n",
    "        laplacian_pyramid.append(laplacian)\n",
    "    laplacian_pyramid.append(gaussian_pyramid[-1])\n",
    "    return laplacian_pyramid\n",
    "\n",
    "def blend_pyramids2(laplacian_pyramid1, laplacian_pyramid2, mask_pyramid):\n",
    "    blended_pyramid = []\n",
    "    for i in range(len(laplacian_pyramid1)):\n",
    "        laplacian1 = pil_to_numpy(laplacian_pyramid1[i])\n",
    "        laplacian2 = pil_to_numpy(laplacian_pyramid2[i])\n",
    "        mask = pil_to_numpy(mask_pyramid[i]) # / 255.0\n",
    "        \n",
    "        blended = (laplacian1 * mask) + (laplacian2 * (1 - mask))\n",
    "        blended_pyramid.append(Image.fromarray(blended.astype(np.uint8)))\n",
    "    return blended_pyramid\n",
    "\n",
    "def reconstruct_image_from_laplacian_pyramid2(laplacian_pyramid):\n",
    "    image = laplacian_pyramid[-1]\n",
    "    for i in range(len(laplacian_pyramid) - 2, -1, -1):\n",
    "        size = (laplacian_pyramid[i].width, laplacian_pyramid[i].height)\n",
    "        image = image.resize(size, Image.LANCZOS)\n",
    "        image = ImageChops.add(image, laplacian_pyramid[i])\n",
    "    return image\n",
    "\n",
    "def image_blending2(img1, img2, mask, num_levels=4, downscale_factor=2, laplacian_kernel=None):\n",
    "\n",
    "    gaussian_pyramid = []\n",
    "    laplacian_pyramid = []\n",
    "\n",
    "    img1_gaussian = downscale_gaussian(img1, downscale_factor, num_levels)\n",
    "    img2_gaussian = downscale_gaussian(img2, downscale_factor, num_levels)\n",
    "    mask_gaussian = downscale_gaussian(mask, downscale_factor, num_levels)\n",
    "\n",
    "    gaussian_pyramid += [img1_gaussian, img2_gaussian, mask_gaussian]\n",
    "\n",
    "    img1_laplacian = generate_laplacian_pyramid2(img1_gaussian, laplacian_kernel)\n",
    "    img2_laplacian = generate_laplacian_pyramid2(img2_gaussian, laplacian_kernel)\n",
    "\n",
    "    laplacian_pyramid += [img1_laplacian, img2_laplacian]\n",
    "\n",
    "    blended_pyramid = blend_pyramids2(img1_laplacian, img2_laplacian, mask_gaussian)\n",
    "    blended_image = reconstruct_image_from_laplacian_pyramid2(blended_pyramid)\n",
    "\n",
    "    return blended_image, blended_pyramid, gaussian_pyramid, laplacian_pyramid\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e36e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image, ImageFilter, ImageChops\n",
    "\n",
    "def apply_kernel(image, kernel):\n",
    "    return image.filter(kernel)\n",
    "\n",
    "def generate_gaussian_pyramid(image, num_levels, downscale_factor):\n",
    "    pyramid = [image]\n",
    "    for i in range(1, num_levels):\n",
    "        image = image.filter(ImageFilter.GaussianBlur(downscale_factor))\n",
    "        image = image.resize((image.width // 2, image.height // 2), Image.ANTIALIAS)\n",
    "        pyramid.append(image)\n",
    "    return pyramid\n",
    "\n",
    "def generate_laplacian_pyramid(gaussian_pyramid, laplacian_kernel):\n",
    "    laplacian_pyramid = []\n",
    "    for i in range(len(gaussian_pyramid) - 1):\n",
    "        size = (gaussian_pyramid[i].width, gaussian_pyramid[i].height)\n",
    "        upscale = gaussian_pyramid[i + 1].resize(size, Image.ANTIALIAS)\n",
    "        laplacian = ImageChops.subtract(gaussian_pyramid[i], upscale)\n",
    "        \n",
    "        if laplacian_kernel is not None:\n",
    "            laplacian = apply_kernel(laplacian, laplacian_kernel)\n",
    "\n",
    "        laplacian_pyramid.append(laplacian)\n",
    "    laplacian_pyramid.append(gaussian_pyramid[-1])\n",
    "    return laplacian_pyramid\n",
    "\n",
    "def blend_pyramids(laplacian_pyramid1, laplacian_pyramid2, mask_pyramid):\n",
    "    blended_pyramid = []\n",
    "    for i in range(len(laplacian_pyramid1)):\n",
    "        laplacian1 = np.asarray(laplacian_pyramid1[i])\n",
    "        laplacian2 = np.asarray(laplacian_pyramid2[i])\n",
    "        mask = np.asarray(mask_pyramid[i]) / 255.0\n",
    "        blended = laplacian1 * mask + laplacian2 * (1.0 - mask)\n",
    "        blended_pyramid.append(Image.fromarray(blended.astype(np.uint8)))\n",
    "    return blended_pyramid\n",
    "\n",
    "def reconstruct_image_from_laplacian_pyramid(laplacian_pyramid):\n",
    "    image = laplacian_pyramid[-1]\n",
    "    for i in range(len(laplacian_pyramid) - 2, -1, -1):\n",
    "        size = (laplacian_pyramid[i].width, laplacian_pyramid[i].height)\n",
    "        image = image.resize(size, Image.ANTIALIAS)\n",
    "        image = ImageChops.add(image, laplacian_pyramid[i])\n",
    "    return image\n",
    "\n",
    "def image_blending(img1, img2, mask, num_levels=4, downscale_factor=2, laplacian_kernel=None):\n",
    "    \n",
    "    img1_gray = img1.convert(\"L\")\n",
    "    img2_gray = img2.convert(\"L\")\n",
    "    mask_gray = mask.convert(\"L\")\n",
    "\n",
    "    img1_gaussian = generate_gaussian_pyramid(img1, num_levels, downscale_factor)\n",
    "    img2_gaussian = generate_gaussian_pyramid(img2, num_levels, downscale_factor)\n",
    "    mask_gaussian = generate_gaussian_pyramid(mask, num_levels, downscale_factor)\n",
    "\n",
    "    img1_laplacian = generate_laplacian_pyramid(img1_gaussian, laplacian_kernel)\n",
    "    img2_laplacian = generate_laplacian_pyramid(img2_gaussian, laplacian_kernel)\n",
    "\n",
    "    blended_pyramid = blend_pyramids(img1_laplacian, img2_laplacian, mask_gaussian)\n",
    "    blended_image = reconstruct_image_from_laplacian_pyramid(blended_pyramid)\n",
    "\n",
    "    return blended_image, img1_laplacian, img2_laplacian\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
