{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spectral Clustering Specific Function Definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Changelog Interval:** 3.20.23 - 3.27.23<br>\n",
    "**Author:** Laura Kaplan<br>\n",
    "**Purpose:** Testing randomly generated 5x5 RGB data for clustering potential<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NOTES\n",
    "This is a definitions file and is imported by generate_figures.ipynb\n",
    "\n",
    "IMPORTANT! The libraries cell should be commented-out when running from the generate_figures file (or redundant imports occur)  \n",
    "The libraries cell is kept here for easy-reference during debugging.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------\n",
    "# LIBRARIES\n",
    "Imported in main file: generate_figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import networkx as nx\n",
    "# import seaborn as sns; sns.set()\n",
    "# import pylab\n",
    "# %run ./def_file_general.ipynb\n",
    "# %run ./def_file_spectral.ipynb\n",
    "\n",
    "# #NUMPY\n",
    "# import numpy as np\n",
    "# from numpy.linalg import eig, eigh\n",
    "# np.set_printoptions(precision=2,suppress=True, linewidth = 10000)\n",
    "\n",
    "\n",
    "# #MATPLOTLIB\n",
    "# %matplotlib inline\n",
    "# import matplotlib.image as mpimg\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "# #PIL \n",
    "# from PIL import Image, ImageOps, ImageFont, ImageDraw\n",
    "# from PIL.ImageChops import add, subtract, multiply, difference, screen\n",
    "# import PIL.ImageStat as stat\n",
    "\n",
    "# #SCIPY\n",
    "# import scipy as sp\n",
    "# from scipy.ndimage import gaussian_filter\n",
    "# import scipy.ndimage.filters as filters\n",
    "# #from scipy.ndimage import affine_transform, zoom\n",
    "# #from scipy import misc\n",
    "\n",
    "# #SKIMAGE & SKLEARN\n",
    "# from skimage.io import imread, imsave, imshow, show, imread_collection, imshow_collection\n",
    "# from skimage import color, viewer, exposure, img_as_float, img_as_ubyte, io, data\n",
    "# from skimage.transform import SimilarityTransform, warp, swirl\n",
    "# from skimage.exposure import cumulative_distribution\n",
    "# from skimage.util import invert, random_noise, montage\n",
    "# from sklearn.cluster import KMeans, SpectralClustering\n",
    "# from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------\n",
    "# FUNCTIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### File & Code Management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_imports():\n",
    "    for name, val in globals().items():\n",
    "        if isinstance(val, types.ModuleType):\n",
    "            name = val.__name__.split(\".\")[0]\n",
    "        elif isinstance(val, type):\n",
    "            name = val.__module__.split(\".\")[0]\n",
    "            \n",
    "        poorly_named_packages = {\n",
    "            \"PIL\": \"Pillow\",\n",
    "            \"sklearn\": \"scikit-learn\"\n",
    "        }\n",
    "        if name in poorly_named_packages.keys():\n",
    "            name = poorly_named_packages[name]\n",
    "            \n",
    "        yield name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display & Convert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_img(image, title=''):\n",
    "    if isinstance(image, Image.Image):\n",
    "        _ = plt.title(title)\n",
    "#         _ = plt.set_cmap('grey')\n",
    "        _ = plt.axis('off')\n",
    "        _ = plt.imshow(image)\n",
    "    else:\n",
    "        print(\"The image is not a PIL type\")\n",
    "        _ = plt.title(title)\n",
    "#         _ = plt.set_cmap('grey')\n",
    "        _ = plt.axis('off')\n",
    "        _ = plt.imshow(Image.fromarray(image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save SINGLE image\n",
    "def save_image(image, filename, color_type='rgb'):\n",
    "    \"\"\"\n",
    "    Detects the format of the image file and saves it to disk with the given filename.\n",
    "\n",
    "    Parameters:\n",
    "        image (str, numpy.ndarray, PIL.Image, cv2.Image): The input image file, as a \n",
    "        path to an image file, a numpy array, a PIL image, or a cv2 image.\n",
    "        filename (str): The desired name of the output file, including the file extension.\n",
    "        color_type (str): The color mode of the input image. Valid values are 'gray', 'rgb', 'hsl', or 'hsv'. Default is 'rgb'.\n",
    "    \"\"\"\n",
    "    # Convert the input image to a PIL image\n",
    "    if isinstance(image, str):\n",
    "        with Image.open(image) as im:\n",
    "            pil_image = im.copy()\n",
    "    elif isinstance(image, np.ndarray):\n",
    "        if len(image.shape) == 2:\n",
    "            # Convert grayscale image to RGB for saving as PNG or JPEG\n",
    "            pil_image = Image.fromarray(image).convert(color_type.upper())\n",
    "        else:\n",
    "            pil_image = Image.fromarray(image, mode=color_type.upper())\n",
    "    elif isinstance(image, Image.Image):\n",
    "        if image.mode == 'L':\n",
    "            # Convert grayscale image to RGB for saving as PNG or JPEG\n",
    "            pil_image = ImageOps.grayscale(image).convert(color_type.upper())\n",
    "        else:\n",
    "            pil_image = image.copy()\n",
    "            if image.mode != color_type.upper():\n",
    "                pil_image = pil_image.convert(color_type.upper())\n",
    "    elif isinstance(image, cv2.UMat):\n",
    "        pil_image = Image.fromarray(cv2.UMat.get(image))\n",
    "    elif isinstance(image, cv2.Mat):\n",
    "        if len(image.shape) == 2:\n",
    "            # Convert grayscale image to RGB for saving as PNG or JPEG\n",
    "            pil_image = Image.fromarray(image).convert(color_type.upper())\n",
    "        else:\n",
    "            pil_image = Image.fromarray(cv2.cvtColor(image, cv2.COLOR_BGR2RGB), mode=color_type.upper())\n",
    "    elif isinstance(image, cv2.VideoCapture):\n",
    "        ret, frame = image.read()\n",
    "        if frame.ndim == 2:\n",
    "            # Convert grayscale image to RGB for saving as PNG or JPEG\n",
    "            pil_image = Image.fromarray(frame).convert(color_type.upper())\n",
    "        else:\n",
    "            pil_image = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB), mode=color_type.upper())\n",
    "    else:\n",
    "        raise ValueError(f'Invalid image type: {type(image)}')\n",
    "\n",
    "    # Get the file format of the image\n",
    "    file_format = pil_image.format\n",
    "\n",
    "    # Save the image to disk with the given filename and format\n",
    "    output_filename = filename + '.png'\n",
    "    pil_image.save(output_filename)\n",
    "    # with open(output_filename, 'wb') as f:\n",
    "        # pil_image.save(f)\n",
    "\n",
    "    print(f'Saved image to {output_filename}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_to_channels(image):\n",
    "    mode = image.mode\n",
    "    \n",
    "    if mode != 'RGB':\n",
    "        print(\"Input image is not RGB\")\n",
    "        gray_array = np.array(image)\n",
    "        return gray_array\n",
    "    else:\n",
    "        r, g, b = Image.split(image)\n",
    "        r_array = np.array(r)\n",
    "        g_array = np.array(g)\n",
    "        b_array = np.array(b)\n",
    "\n",
    "        return r_array, g_array, b_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create pic from arrays: single-channel OR multi-channel\n",
    "def channels_to_image(channel1, channel2=None, channel3=None):\n",
    "    rows, cols = channel1.shape\n",
    "    \n",
    "    if channel2 is None:\n",
    "        return Image.fromarray(channel1)\n",
    "    else:\n",
    "        rgbArray = np.zeros((rows,cols,3), 'uint8')\n",
    "        rgbArray[...,0] = red\n",
    "        rgbArray[...,1] = green\n",
    "        rgbArray[...,2] = blue\n",
    "        rgbImg = Image.fromarray(rgbArray)\n",
    "        return rgbImg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rgb_to_3Darray(red, green, blue):\n",
    "    stack = np.dstack((red, green, blue))\n",
    "    return stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_data_min_max(channel1, channel2=None, channel3=None):\n",
    "    if channel2 is None and channel3 is None:\n",
    "        color_setting = 'gray'\n",
    "    else:\n",
    "        color_setting = 'rgb'\n",
    "        \n",
    "        \n",
    "    if color_setting == \"rgb\":\n",
    "        print(\"Min red: \", np.min(channel1), \"   | Min green: \", np.min(channel2), \"   | Min blue: \", np.min(channel3))\n",
    "        print(\"Max red: \", np.max(channel1), \" | Max green: \", np.max(channel2), \" | Max blue: \", np.max(channel3))\n",
    "    elif color_setting == 'gray':\n",
    "        print(\"Min gray: \", np.min(channel1))\n",
    "        print(\"Max gray: \", np.max(channel1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_data_heatmap(channel1, channel2=None, channel3=None):\n",
    "    if channel2 is None and channel3 is None:\n",
    "        color_setting = 'gray'\n",
    "    else:\n",
    "        color_setting = 'rgb'\n",
    "    \n",
    "    '''heatmap displays stacked numeric information. more useful for smaller datasets.'''\n",
    "    if color_setting == 'rgb':\n",
    "        heat_rgb = sns.heatmap(channel1+channel2+channel3, annot=True, fmt=\"d\")\n",
    "        #plt.savefig(\"rgb_heatmap.png\", bbox_inches='tight', dpi = 100)\n",
    "    elif color_setting == 'gray':\n",
    "        heat_gray = sns.heatmap(channel1, annot=True, fmt=\"d\")\n",
    "        #plt.savefig(\"gray_heatmap.png\", bbox_inches='tight', dpi = 100)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lo, hi, cmap = _get_display_range(image)\n",
    "#display_img(img_pil, 'original image')\n",
    "#display_img(img_pil, 'Array As Picture', 'rgb')\n",
    "def display_data_images(channel1, channel2=None, channel3=None):\n",
    "    if channel2 is None and channel3 is None:\n",
    "        color_setting = 'gray'\n",
    "    else:\n",
    "        color_setting = 'rgb'\n",
    "    \n",
    "    if color_setting == 'rgb':\n",
    "        '''display image at actual size'''\n",
    "        pilImg = channels_to_image(channel1, channel2, channel3)\n",
    "        display(pilImg)\n",
    "        '''display image at increased scale'''\n",
    "        stackedRGB = rgb_to_3Darray(channel1, channel2, channel3)\n",
    "        plt.imshow(stackedRGB, vmin=0, vmax=255)\n",
    "\n",
    "    elif color_setting == 'gray':\n",
    "        '''display image at actual size'''\n",
    "        pilImg = channels_to_image(channel1)\n",
    "        display(pilImg)\n",
    "        '''display image at increased scale'''\n",
    "        plt.imshow(channel1, vmin=0, vmax=255, cmap='gray')\n",
    "\n",
    "    plt.grid(False)\n",
    "    plt.show()\n",
    "    # lo, hi, cmap = _get_display_range(image)\n",
    "    return pilImg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_initial_image_info(channel1, channel2=None, channel3=None, display_heatmap = True):\n",
    "    print(\"Channel Shape = \", channel1.shape)\n",
    "   \n",
    "    if channel2 is None and channel3 is None:\n",
    "        print(\"Pixel [2,2] Grayscale = \", channel1[2,2])\n",
    "        display_data_min_max(channel1)\n",
    "        pilImg = display_data_images(channel1)\n",
    "        if display_heatmap == True:\n",
    "            display_data_heatmap(channel1)\n",
    "    else:\n",
    "        print(\"Pixel [2,2] RGB = \", channel1[2,2], \",\", channel2[2,2], \",\", channel3[2,2])\n",
    "        print(\"Pixel [22,9] RGB = \", channel1[22,9], \",\", channel2[22,9], \",\", channel3[22,9])\n",
    "        print(\"Pixel [45,22] RGB = \", channel1[45,22], \",\", channel2[45,22], \",\", channel3[45,22])\n",
    "        display_data_min_max(channel1, channel2, channel3)\n",
    "        pilImg = display_data_images(channel1, channel2, channel3)\n",
    "        if display_heatmap == True:\n",
    "            display_data_heatmap(channel1, channel2, channel3)\n",
    "    return pilImg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_label_values(label_set, rows, cols, description=None):\n",
    "    if description is None:\n",
    "        description = \"Labels\"\n",
    "    print(f\"\\n{description}:\", label_set)\n",
    "    print(f\"\\n{description} - Array Formatted:\\n\", label_set.reshape(rows, cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_clustering(original_img, predicted_img, labels, centers, title1, title2, mode=None, show_scatter=False):\n",
    "    if mode is None:\n",
    "        print(\"\\nPlease specify whether the image should be displayed as RGB or Grayscale.\")\n",
    "        return False\n",
    "    \n",
    "    # SIDE BY SIDE PLOT\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
    "    if mode == 'gray':\n",
    "        axes[0].imshow(original_img, cmap='gray')\n",
    "    elif mode == 'rgb':\n",
    "        axes[0].imshow(original_img)\n",
    "    axes[0].grid(False)\n",
    "    axes[0].set_title(title1)\n",
    "    axes[1].imshow(predicted_img)\n",
    "    axes[1].grid(False)\n",
    "    axes[1].set_title(title2)\n",
    "    cluster_img = transform_plot_to_image(plt)\n",
    "    plt.show()\n",
    "    \n",
    "    if show_scatter:\n",
    "        # SCATTER PLOT (contains labels and centers)\n",
    "        fig = plt.figure(figsize=(5,5))\n",
    "        ax = fig.add_subplot(111, projection='3d', computed_zorder=False)\n",
    "        #--------FOR 2 CLUSTERS PLEASE USE:---------------\n",
    "        ax.scatter(vectors[:,0], vectors[:,1], c=labels, cmap='viridis', zorder=1)\n",
    "        ax.scatter(centers[:,0], centers[:,1], c='orange', marker='*', s=200, alpha=1, zorder=2)\n",
    "        ax.set_xlabel('X')\n",
    "        ax.set_ylabel('Y')\n",
    "        ax.set_zlabel('Z')\n",
    "        plt.show()\n",
    "        #--------FOR 3 CLUSTERS PLEASE USE:---------------\n",
    "        # ax.scatter(vectors[:,0], vectors[:,1], vectors[:,2], c=labels, cmap='viridis', zorder=1)\n",
    "        # ax.scatter(centers[:,0], centers[:,1], centers[:,2], c='orange', marker='*', s=200, , alpha=1, zorder=2)\n",
    "        # ax.set_xlabel('X')\n",
    "        # ax.set_ylabel('Y')\n",
    "        # ax.set_zlabel('Z')\n",
    "        \n",
    "    return cluster_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def visualize_clustering(original_img, shaped_labels, title1, title2, mode=None, display=False):\n",
    "#     if mode is None:\n",
    "#         raise TypeError(\"\\nPlease specify whether the image should be displayed as RGB or Grayscale.\")\n",
    "    \n",
    "#     # SIDE BY SIDE PLOT\n",
    "#     fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
    "#     if mode == 'gray':\n",
    "#         axes[0].imshow(original_img, cmap='gray')\n",
    "#     elif mode == 'rgb':\n",
    "#         axes[0].imshow(original_img)\n",
    "#     axes[0].grid(False)\n",
    "#     axes[0].set_title(title1)\n",
    "#     axes[1].imshow(shaped_labels)\n",
    "#     axes[1].grid(False)\n",
    "#     axes[1].set_title(title2)\n",
    "#     cluster_img = transform_plot_to_image(plt)\n",
    "    \n",
    "#     if display:\n",
    "#         plt.show()\n",
    "#     else:\n",
    "#         plt.close(fig)\n",
    "        \n",
    "#     return cluster_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_labeled_groups(shaped_labels, k, display_num=None):\n",
    "    grouped_indices = []\n",
    "\n",
    "    # Find the indices of values that match the groupNum\n",
    "    for groupNum in range(k):\n",
    "        indices = [(i, j) for i, row in enumerate(shaped_labels) for j, value in enumerate(row) if value == groupNum]\n",
    "        grouped_indices.append(indices)\n",
    "\n",
    "    # Display indices\n",
    "    if display_num >= k:\n",
    "        raise ValueError(\"Error. Your display_num should be a value equal to the label of the group you'd like to observe. \")\n",
    " \n",
    "    if display_num is not None:\n",
    "        print(f\"PIXELS IN GROUP {display_num}:\")\n",
    "        for i, (row, col) in enumerate(grouped_indices[display_num], start=1):\n",
    "            print(f\"pixel #{i}:  ({row},{col})\\tRow: {row}, Column: {col}\")\n",
    "\n",
    "    return grouped_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import BytesIO\n",
    "# def transform_plot_to_image(plot):\n",
    "#     # Convert plot to image\n",
    "#     buffer = BytesIO()\n",
    "#     plot.savefig(buffer, format='png')\n",
    "#     buffer.seek(0)\n",
    "#     img = Image.open(buffer)\n",
    "\n",
    "#     return img\n",
    "\n",
    "def transform_plot_to_image(plot, title=None, save=False):\n",
    "    # Convert plot to image\n",
    "    buffer = BytesIO()\n",
    "    _= plot.savefig(buffer, format='png', transparent=True, bbox_inches=\"tight\", pad_inches=0)\n",
    "    _= buffer.seek(0)\n",
    "    img = Image.open(buffer)\n",
    "\n",
    "    if save:\n",
    "        if title is None:\n",
    "            title = \"Unnamed_Plot\"\n",
    "        save_image(img, f\"{title}\")\n",
    "#         plot.savefig(title + '.png', dpi = 300, transparent=True)\n",
    "        \n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def figure1_eigenvector_scatter(vectors):\n",
    "    # Prepare the x-axis values: indices of the vals array\n",
    "    x = np.arange(len(vectors[1]))\n",
    "\n",
    "    # Prepare the y-axis values: values from the 2nd eigenvector\n",
    "    y = vectors[1]\n",
    "\n",
    "    # Calculate the distance from 0 for each value and normalize it\n",
    "    distances = np.abs(y)\n",
    "    normalized_distances = distances #/ np.max(distances)\n",
    "\n",
    "    # Create the scatter plot\n",
    "    fig = px.scatter(x=x, y=y, #color=normalized_distances, #color_continuous_scale=\"Viridis\", \n",
    "                     labels={\"x\": \"Index\", \"y\": \"Value\", \"color\": \"Distance from 0\"},\n",
    "                     title=\"Contents of the 2nd Eigenvector\")\n",
    "\n",
    "    # Set dark background color for the plot\n",
    "    fig.update_layout({\n",
    "     'plot_bgcolor': 'rgb(220, 220, 220)',  # Set the background color of the plotting area\n",
    "    'paper_bgcolor': 'rgb(220, 220, 220)', # Set the background color of the entire plot\n",
    "\n",
    "        'title': {\n",
    "            'y': 0.9,\n",
    "            'x': 0.5,\n",
    "            'xanchor': 'center',\n",
    "            'yanchor': 'top',\n",
    "            'font': {'color': 'black'} # Set title font color\n",
    "        },\n",
    "        'xaxis': {\n",
    "            'tickfont': {'color': 'black'}, # Set x-axis tick color\n",
    "            'title': {'font': {'color': 'black'}} # Set x-axis title font color\n",
    "        },\n",
    "        'yaxis': {\n",
    "            'tickfont': {'color': 'black'}, # Set y-axis tick color\n",
    "            'title': {'font': {'color': 'black'}} # Set y-axis title font color\n",
    "        },\n",
    "        'coloraxis': {\n",
    "            'colorbar': {'title': {'font': {'color': 'black'}}} # Set color bar title font color\n",
    "        }\n",
    "    })\n",
    "\n",
    "    # Display the plot\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_predefined_data(dataset_num, seed=42, display_options = True, display_data = True):\n",
    "    if display_options == True:\n",
    "        print(\"OPTIONS GO HERE\")    \n",
    "\n",
    "    if dataset_num == 1:\n",
    "        #------------------------------------------------------\n",
    "        #------------------DATASET 1---------------------------\n",
    "        #------------------------------------------------------\n",
    "        data_desc = \"5x5 Binary RGB Data (0 clusters)\"  \n",
    "        red = np.array([[0,0,1,1,1],[0,1,0,0,0],[0,1,1,0,0],[1,0,0,0,1],[1,0,0,1,0]])\n",
    "        green = np.array([[0,1,0,1,1],[0,1,0,0,1],[0,1,1,0,1],[1,1,0,1,1],[0,1,0,1,0]])\n",
    "        blue = np.array([[1,1,0,1,1],[0,0,1,0,0],[0,0,0,0,1],[0,1,1,0,0],[0,1,1,1,0]])\n",
    "    elif dataset_num == 2:\n",
    "        #------------------------------------------------------\n",
    "        #------------------DATASET 2---------------------------\n",
    "        #------------------------------------------------------\n",
    "        data_desc = \"2x2 RGB Data (2 clusters - half & half)\" \n",
    "        red = np.array([[20, 250],[20, 250]])\n",
    "        green = np.array([[20, 250],[20, 250]])\n",
    "        blue = np.array([[20, 250],[20, 250]])\n",
    "    elif dataset_num == 3:\n",
    "        #------------------------------------------------------\n",
    "        #------------------DATASET 3---------------------------\n",
    "        #------------------------------------------------------\n",
    "        data_desc = \"3x3 RGB Data (0 clusters)\"  \n",
    "        red = np.array([[123, 191, 31],[218, 129, 66],[159, 239, 211]])\n",
    "        green = np.array([[59,196,252],[111,15,76],[193,248,150]])\n",
    "        blue = np.array([[165,90,26],[20,199,47],[39,95,230]])\n",
    "    elif dataset_num == 4:\n",
    "        #------------------------------------------------------\n",
    "        #------------------DATASET 4---------------------------\n",
    "        #------------------------------------------------------\n",
    "        data_desc = \"3x3 RGB Data (2 clusters - half & half)\"  \n",
    "        red = np.array([[100, 191, 31],[100, 129, 66],[100, 239, 211]])\n",
    "        green = np.array([[100,196,252],[100,15,76],[100,248,150]])\n",
    "        blue = np.array([[100,90,26],[100,199,47],[100,205,230]])\n",
    "    elif dataset_num == 5:\n",
    "        #------------------------------------------------------\n",
    "        #------------------DATASET 5---------------------------\n",
    "        #------------------------------------------------------\n",
    "        data_desc = \"5x5 RGB Data (1 cluster - upper left)\" \n",
    "        red = np.array([[50, 50, 31, 78, 250],[50, 50, 66, 2, 34],[159, 239, 211, 74, 127],\n",
    "                         [42, 86, 158, 231, 151],[108, 110, 87, 128, 20]])\n",
    "        green = np.array([[50,50,252,255,9],[50,50,76,203,44],[193,248,150,205,158],\n",
    "                           [122,68,195,245,126],[75,250,70,56,157]])\n",
    "        blue = np.array([[50,50,26,83,129],[50,50,47,94,133],[39,95,230,30,209],\n",
    "                          [62,212,65,3,225],[196,169,195,8,70]])\n",
    "    elif dataset_num == 6:\n",
    "        #------------------------------------------------------\n",
    "        #------------------DATASET 6---------------------------\n",
    "        #------------------------------------------------------\n",
    "        data_desc = \"5x5 RGB Data (4 clusters - 4 corners)\"  \n",
    "        red = np.array([[50, 50, 100, 100, 100],[50, 50, 100, 100, 100],[150,150,200,200,200],\n",
    "                         [150,150,200,200,200],[150,150,200,200,200]])\n",
    "        green = np.array([[50, 50, 100, 100, 100],[50, 50, 100, 100, 100],[150,150,200,200,200],\n",
    "                         [150,150,200,200,200],[150,150,200,200,200]])\n",
    "        blue = np.array([[50, 50, 100, 100, 100],[50, 50, 100, 100, 100],[150,150,200,200,200],\n",
    "                         [150,150,200,200,200],[150,150,200,200,200]])\n",
    "\n",
    "    elif dataset_num == 7:\n",
    "        #------------------------------------------------------\n",
    "        #------------------DATASET 7---------------------------\n",
    "        #------------------------------------------------------\n",
    "        data_desc = \"6x6 RGB Data (4 clusters - 4 corners)\"  \n",
    "        red = np.array([[50, 50, 50, 100, 100, 100],[50, 50, 50, 100, 100, 100],[50, 50, 50, 100, 100, 100],\n",
    "                        [150, 150, 150, 200, 200, 200],[150, 150, 150, 200, 200, 200],[150, 150, 150, 200, 200, 200]])\n",
    "        green = np.array([[50, 50, 50, 100, 100, 100],[50, 50, 50, 100, 100, 100],[50, 50, 50, 100, 100, 100],\n",
    "                        [150, 150, 150, 200, 200, 200],[150, 150, 150, 200, 200, 200],[150, 150, 150, 200, 200, 200]])\n",
    "        blue = np.array([[50, 50, 50, 100, 100, 100],[50, 50, 50, 100, 100, 100],[50, 50, 50, 100, 100, 100],\n",
    "                        [150, 150, 150, 200, 200, 200],[150, 150, 150, 200, 200, 200],[150, 150, 150, 200, 200, 200]])\n",
    "    elif dataset_num == 8:\n",
    "        #------------------------------------------------------\n",
    "        #------------------DATASET 8---------------------------\n",
    "        #------------------------------------------------------\n",
    "        data_desc = \"6x6 RGB Data + Noise (4 clusters - 4 corners)\"  \n",
    "        red = np.array([[ 52, 48, 48, 99, 102, 99],\n",
    "        [ 48, 52, 48, 101, 101, 99],\n",
    "        [ 50, 52, 49, 98, 100, 104],\n",
    "        [154, 148, 150, 195, 198, 198],\n",
    "        [148, 154, 152, 204, 201, 197],\n",
    "        [146, 153, 152, 201, 200, 204]])\n",
    "\n",
    "        green = np.array([[ 52, 51, 50, 103, 98, 104],\n",
    "        [ 52, 51, 51, 98, 102, 102],\n",
    "        [ 48, 48, 48, 100, 95, 105],\n",
    "        [151, 152, 146, 195, 199, 203],\n",
    "        [152, 146, 151, 199, 195, 203],\n",
    "        [154, 154, 155, 198, 198, 203]])\n",
    "\n",
    "        blue = np.array([[ 49, 46, 49, 102, 105, 100],\n",
    "        [ 52, 51, 55, 100, 98, 105],\n",
    "        [ 50, 53, 54, 101, 101, 105],\n",
    "        [153, 152, 152, 202, 203, 195],\n",
    "        [155, 152, 151, 201, 202, 197],\n",
    "        [151, 151, 148, 201, 199, 202]])\n",
    "    elif dataset_num == 9:\n",
    "        #------------------------------------------------------\n",
    "        #------------------DATASET 9---------------------------\n",
    "        #------------------------------------------------------\n",
    "        data_desc = \"15x15 RGB Data (1 cluster - upper left)\"  \n",
    "\n",
    "        np.random.seed(seed) # set random seed for reproducibility\n",
    "        # create 3 numpy arrays with random pixel values between 0 and 255\n",
    "        red = np.random.randint(0, 256, size=(15, 15))\n",
    "        green = np.random.randint(0, 256, size=(15, 15))\n",
    "        blue = np.random.randint(0, 256, size=(15, 15))\n",
    "\n",
    "        # set upper left 25% of each array to white\n",
    "        red[:,:] = 50\n",
    "        green[:,:] = 50\n",
    "        blue[:,:] = 50\n",
    "\n",
    "        # set upper left 25% of each array to white\n",
    "        red[:7,:7] = 200\n",
    "        green[:7,:7] = 200\n",
    "        blue[:7,:7] = 200\n",
    "    elif dataset_num == 10:\n",
    "        #------------------------------------------------------\n",
    "        #------------------DATASET 10--------------------------\n",
    "        #------------------------------------------------------\n",
    "        data_desc = \"15x15 RGB Data (1 cluster - circle in center)\"\n",
    "\n",
    "        np.random.seed(seed) # set random seed for reproducibility\n",
    "        # create 3 numpy arrays with random pixel values between 0 and 255\n",
    "        red = np.random.randint(0, 256, size=(15, 15))\n",
    "        green = np.random.randint(0, 256, size=(15, 15))\n",
    "        blue = np.random.randint(0, 256, size=(15, 15))\n",
    "\n",
    "        # create 3 numpy arrays with random pixel values between 0 and 50\n",
    "        red = np.random.randint(0, 50, size=(15, 15))\n",
    "        green = np.random.randint(0, 50, size=(15, 15))\n",
    "        blue = np.random.randint(0, 50, size=(15, 15))\n",
    "\n",
    "        # # set upper left 25% of each array to white\n",
    "        # red[:,:] = 50\n",
    "        # green[:,:] = 50\n",
    "        # blue[:,:] = 50\n",
    "\n",
    "        # create a meshgrid of coordinates for the array\n",
    "        x, y = np.meshgrid(np.arange(red.shape[0]), np.arange(red.shape[1]))\n",
    "\n",
    "        # compute the distance from the center of the array\n",
    "        dist = np.sqrt((x - red.shape[0]/2)**2 + (y - red.shape[1]/2)**2)\n",
    "\n",
    "        # create a binary mask for the circular region\n",
    "        mask = (dist < red.shape[0]/4)\n",
    "\n",
    "        # apply the mask to the arrays and set the values to white\n",
    "        red[mask] = 200\n",
    "        green[mask] = 200\n",
    "        blue[mask] = 200\n",
    "\n",
    "        # apply a Gaussian blur to make the circle less sharp\n",
    "        red = gaussian_filter(red, sigma=.5)\n",
    "        green = gaussian_filter(green, sigma=.5)\n",
    "        blue = gaussian_filter(blue, sigma=.5)\n",
    "    else:\n",
    "        print(f\"{dataset_num} is not a recognized predefined dataset\")\n",
    "        return False\n",
    "\n",
    "#----------------------------------------------------\n",
    "    rgb_combined = (red + green + blue)/3\n",
    "    rows,cols = red.shape\n",
    "    dist_matrix = np.zeros((rows,cols))\n",
    "    \n",
    "    print(f\"\\nSelected Dataset #{dataset_num}:\", data_desc)\n",
    "    \n",
    "    if display_data == True:\n",
    "        print(\"\\nRED:\\n\", red, \"\\n\\nGREEN:\\n\",  green, \"\\n\\nBLUE:\\n\", blue)\n",
    "    \n",
    "    return red, green, blue, dist_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_random_pixel_data(s=None, range_start=0, range_end=255):\n",
    "    if s is None:\n",
    "        raise ValueError(\"Attempted to generate random pixels. s=None not permitted.\")\n",
    "    else:  \n",
    "        rand_values = np.random.choice((-1, 1), size=(s, s)) * np.random.randint(range_start, range_end, size=(s, s))\n",
    "#         green = np.random.choice((-1, 1), size=(s, s)) * np.random.randint(range_start, range_end, size=(s, s))\n",
    "#         blue = np.random.choice((-1, 1), size=(s, s)) * np.random.randint(range_start, range_end, size=(s, s))\n",
    " \n",
    "    return rand_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_color_test_data(size = 15, foreground_region = 'circle', background_value = 0, foreground_value = 255, \n",
    "                             add_background_noise = True, background_noise_range = 20,\n",
    "                             add_foreground_noise = True, foreground_noise_range = 20, \n",
    "                             boundary_blur = True, boundary_sigma = 0.5,\n",
    "                             display=False):\n",
    "    \n",
    "    seed = 42\n",
    "    s = size\n",
    "    f = foreground_value\n",
    "    b = background_value\n",
    "    fgn = foreground_noise_range\n",
    "    bgn = background_noise_range\n",
    "    bs = boundary_sigma\n",
    "\n",
    "    print(\"Image data generated with the following properties: \")\n",
    "\n",
    "    # set random seed for reproducibility\n",
    "    print(f\"\\t- random # seed = {seed}\")\n",
    "    np.random.seed(seed)    \n",
    "    \n",
    "    #------SET IMAGE SIZE---------\n",
    "    print(f\"\\t- resolution = {s}x{s}\")\n",
    "    red = np.zeros((s,s))\n",
    "    green = np.zeros((s,s))\n",
    "    blue = np.zeros((s,s))\n",
    "    \n",
    "    #------SET BACKGROUND---------\n",
    "    print(f\"\\t- background base value = {b}\")\n",
    "    red[:,:] = b\n",
    "    green[:,:] = b\n",
    "    blue[:,:] = b\n",
    "    \n",
    "    if add_background_noise == True: \n",
    "        print(f\"\\t- background noise added. Noise range = 0-{bgn}\")\n",
    "        # create 3 numpy arrays with random pixel values between 0 and bgn\n",
    "#         red += np.random.randint(0, bgn, size=(s, s))\n",
    "#         green += np.random.randint(0, bgn, size=(s, s))\n",
    "#         blue += np.random.randint(0, bgn, size=(s, s))\n",
    "        red, green, blue = (channel + generate_random_pixel_data(s, 0, bgn) for channel in (red, green, blue))\n",
    "        \n",
    "    #------SET FOREGROUND---------\n",
    "    # fill region with forced color to establish known objects\n",
    "    if foreground_region == 'corner':\n",
    "        print(f\"\\t- corner cluster created with value = {f}\")\n",
    "        # set upper left 25% of each array to user-specified \n",
    "        red[:s//2, :s//2] = f\n",
    "        green[:s//2, :s//2] = f\n",
    "        blue[:s//2, :s//2] = f\n",
    "\n",
    "    if foreground_region == 'circle':\n",
    "        print(f\"\\t- circle cluster created with value = {f}\")\n",
    "        # create a meshgrid of coordinates for the array\n",
    "        x, y = np.meshgrid(np.arange(red.shape[0]), np.arange(red.shape[1]))\n",
    "        # compute the distance from the center of the array\n",
    "        dist = np.sqrt((x - red.shape[0]/2)**2 + (y - red.shape[1]/2)**2)\n",
    "        # create a binary mask for the circular region\n",
    "        mask = (dist < red.shape[0]/4)\n",
    "        # apply the mask to the arrays. set value to user-specified color\n",
    "        red[mask] = f\n",
    "        green[mask] = f\n",
    "        blue[mask] = f\n",
    "    else:\n",
    "        print(\"\\t- no cluster specified. Data is entirely random.\")\n",
    "\n",
    "    if add_foreground_noise == True:\n",
    "        print(f\"\\t- foreground noise added. Noise range = 0-{fgn}\")\n",
    "        # create 3 numpy arrays with random pixel values between 0 and bgn\n",
    "#         red += np.random.choice((-1, 1), size=(s, s)) * np.random.randint(0, fgn, size=(s, s))\n",
    "#         green += np.random.choice((-1, 1), size=(s, s)) * np.random.randint(0, fgn, size=(s, s))\n",
    "#         blue += np.random.choice((-1, 1), size=(s, s)) * np.random.randint(0, fgn, size=(s, s))\n",
    "        red, green, blue = (channel + generate_random_pixel_data(s, 0, fgn) for channel in (red, green, blue))\n",
    "        \n",
    "    if boundary_blur == True:\n",
    "        print(f\"\\t- gaussian boundary blur applied with sigma = {bs}\")\n",
    "        # apply a Gaussian blur to fuzz the image regions\n",
    "#         red = gaussian_filter(red, sigma = bs).astype(int)\n",
    "#         green = gaussian_filter(green, sigma = bs).astype(int)\n",
    "#         blue = gaussian_filter(blue, sigma = bs).astype(int)\n",
    "        red, green, blue = (channel + generate_random_pixel_data(s, 0, fgn) for channel in (red, green, blue))\n",
    "\n",
    "    #clip the values in the circumstance they exceeded the 0-255 range\n",
    "    #during random number generation\n",
    "    red = np.clip(red, 0, 255).astype(int)\n",
    "    green = np.clip(green, 0, 255).astype(int)\n",
    "    blue = np.clip(blue, 0, 255).astype(int)\n",
    "\n",
    "    rows,cols = red.shape\n",
    "    dist_matrix = np.zeros((rows,cols))\n",
    "    \n",
    "    if display:\n",
    "        print(\"RED:\\n\", red, \"\\n\\nGREEN:\\n\",  green, \"\\n\\nBLUE:\\n\", blue)\n",
    "    \n",
    "    return red, green, blue, dist_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def generate_color_test_data(size = 15, forced_region = 'circle', forced_region_value = 200, \n",
    "#                        blur_boundaries = True, restrict_noise = True, noise_range = 50):\n",
    "#     s = size\n",
    "#     c = forced_region_value\n",
    "\n",
    "#     # set random seed for reproducibility\n",
    "#     np.random.seed(42)\n",
    "\n",
    "#     if restrict_noise == True: \n",
    "#         # create 3 numpy arrays with random pixel values between 0 and 50\n",
    "#         red = np.random.randint(0, noise_range, size=(s, s))\n",
    "#         green = np.random.randint(0, noise_range, size=(s, s))\n",
    "#         blue = np.random.randint(0, noise_range, size=(s, s))\n",
    "        \n",
    "#     else:     \n",
    "#         # create 3 numpy arrays with random pixel values between 0 and 255\n",
    "#         red = np.random.randint(0, 256, size=(s, s))\n",
    "#         green = np.random.randint(0, 256, size=(s, s))\n",
    "#         blue = np.random.randint(0, 256, size=(s, s))\n",
    "\n",
    "#     # fill region with forced color to establish known objects\n",
    "#     if forced_region == 'corner':\n",
    "#         # set upper left 25% of each array to user-specified \n",
    "#         red[:,:] = c\n",
    "#         green[:,:] = c\n",
    "#         blue[:,:] = c\n",
    "#         print(\"Corner Cluster Created\")\n",
    "\n",
    "#     if forced_region == 'circle':\n",
    "#         # create a meshgrid of coordinates for the array\n",
    "#         x, y = np.meshgrid(np.arange(red.shape[0]), np.arange(red.shape[1]))\n",
    "#         # compute the distance from the center of the array\n",
    "#         dist = np.sqrt((x - red.shape[0]/2)**2 + (y - red.shape[1]/2)**2)\n",
    "#         # create a binary mask for the circular region\n",
    "#         mask = (dist < red.shape[0]/4)\n",
    "#         # apply the mask to the arrays. set value to user-specified color\n",
    "#         red[mask] = c\n",
    "#         green[mask] = c\n",
    "#         blue[mask] = c\n",
    "#         print(\"Center-Circle Cluster Created\")\n",
    "#     else:\n",
    "#         print(\"No cluster specified. Data is entirely random.\")\n",
    "\n",
    "#     if blur_boundaries == True:\n",
    "#         # apply a Gaussian blur to make the circle less sharp\n",
    "#         red = gaussian_filter(red, sigma=.5)\n",
    "#         green = gaussian_filter(green, sigma=.5)\n",
    "#         blue = gaussian_filter(blue, sigma=.5)\n",
    "#         print(\"Gaussian noise has been added with sigma = 0.5\")\n",
    "\n",
    "#     rows,cols = red.shape\n",
    "#     dist_matrix = np.zeros((rows,cols))\n",
    "#     print(\"RED:\\n\", red, \"\\n\\nGREEN:\\n\",  green, \"\\n\\nBLUE:\\n\", blue)\n",
    "    \n",
    "#     return red, green, blue, dist_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_gray_test_data(size = 15, forced_region = 'circle', forced_region_value = 200, \n",
    "                       blur_boundaries = True, restrict_noise = True, noise_range = 50):\n",
    "    s = size\n",
    "    rows = s\n",
    "    cols = s\n",
    "    v = forced_region_value\n",
    "\n",
    "    # set random seed for reproducibility\n",
    "    np.random.seed(42)\n",
    "    \n",
    "    # set background values with predefined noise range\n",
    "    if restrict_noise == True: \n",
    "        # create 1 numpy array with random pixel values between 0 and 50\n",
    "        gray = np.random.randint(0, noise_range, size=(s, s))     \n",
    "    else:     \n",
    "        # create 1 numpy array with random pixel values between 0 and 255\n",
    "        gray = np.random.randint(0, 256, size=(s, s))\n",
    "\n",
    "    # fill region with forced value to establish known objects\n",
    "    if forced_region == 'corner':\n",
    "        # set upper left 25% of each array to user-specified \n",
    "        gray[:,:] = v\n",
    "        print(\"Corner Cluster Created\")\n",
    "\n",
    "    if forced_region == 'circle':\n",
    "        # create a meshgrid of coordinates for the array\n",
    "        x, y = np.meshgrid(np.arange(rows), np.arange(cols))\n",
    "        # compute the distance from the center of the array\n",
    "        dist = np.sqrt((x - rows/2)**2 + (y - cols/2)**2)\n",
    "        # create a binary mask for the circular region\n",
    "        mask = (dist < rows/4)\n",
    "        # apply the mask to the arrays. set value to user-specified color\n",
    "        gray[mask] = v\n",
    "        print(\"Center-Circle Cluster Created\")\n",
    "    else:\n",
    "        print(\"No cluster specified. Data is entirely random.\")\n",
    "\n",
    "    if blur_boundaries == True:\n",
    "        # apply a Gaussian blur to make the circle less sharp\n",
    "        gray = gaussian_filter(gray, sigma=.5)\n",
    "        print(\"Gaussian noise has been added with sigma = 0.5\")\n",
    "\n",
    "    dist_matrix = np.zeros((rows,cols))\n",
    "    print(\"GRAY:\\n\", gray)\n",
    "    \n",
    "    return gray, dist_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to draw a triangle\n",
    "def draw_triangle(draw, x, y, size, fill):\n",
    "    points = [(x, y), (x + size, y + size), (x - size, y + size)]\n",
    "    draw.polygon(points, fill=fill)\n",
    "\n",
    "def create_image_shapes(size=(50,50), num_shapes=3, display=True, filename='', save=False):\n",
    "    # Create a random color background image\n",
    "#     image = Image.new(\"RGB\", size, \"black\")\n",
    "    bg_color = tuple(random.randint(0, 255) for _ in range(3))\n",
    "    image = Image.new(\"RGB\", size, bg_color)\n",
    "    draw = ImageDraw.Draw(image)\n",
    "\n",
    "    # Define the shape names and their respective drawing functions\n",
    "    shapes = {\n",
    "        \"circle\": draw.ellipse,\n",
    "        \"square\": draw.rectangle,\n",
    "        \"triangle\": draw_triangle\n",
    "    }\n",
    "\n",
    "    # Generate three random shapes\n",
    "    for _ in range(num_shapes):\n",
    "        # Randomly select shape, size, placement, and color\n",
    "        shape_name = random.choice(list(shapes.keys()))\n",
    "        shape_size = random.randint(size[0]//6, size[0]//2)\n",
    "        x = random.randint(0, size[1] - shape_size)\n",
    "        y = random.randint(0, size[0] - shape_size)\n",
    "        color = tuple(random.randint(0, 255) for _ in range(3))\n",
    "\n",
    "        # Draw the shape on the image\n",
    "        if shape_name == \"triangle\":\n",
    "            shapes[shape_name](draw, x, y, shape_size, color)\n",
    "        else:\n",
    "            shapes[shape_name]([(x, y), (x + shape_size, y + shape_size)], fill=color)\n",
    "\n",
    "    # Display the generated image\n",
    "    if display:\n",
    "        display_image(image)\n",
    "    if save:\n",
    "        save_image(image, f\"generated_shapes_{filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_data_csv(data, filename): \n",
    "    # Define the file path for the CSV file\n",
    "    file_path = f\"{filename}.csv\"\n",
    "    # Save the NumPy array to a CSV file without truncation\n",
    "    np.savetxt(file_path, data, delimiter=\",\", fmt=\"%.16f\")\n",
    "    # Display action message\n",
    "    print(f\"\\ndata saved successfully as {file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FUNCTION DEFINITIONS: value adjacency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# R,G,B AS NEGATIVE EXPONENTIAL DISTRIBUTION --> COMBINE BY EUCLIDEAN DIST\n",
    "# PRE-NORMALIZED (/255)\n",
    "#---------------------- uncomment below ---------------------------------\n",
    "\n",
    "def rgb_distance(red, green, blue):\n",
    "    #retrieve list size\n",
    "    n = red.shape[0] * red.shape[1]\n",
    "    \n",
    "    #normalize RGB values to [0,1] range\n",
    "    red_norm = red.astype(float) / 255.0\n",
    "    green_norm = green.astype(float) / 255.0\n",
    "    blue_norm = blue.astype(float) / 255.0\n",
    "    \n",
    "    #create empty RGB adjacency matrices\n",
    "    r_adj = np.zeros((n, n),dtype='float')\n",
    "    g_adj = np.zeros((n, n),dtype='float')\n",
    "    b_adj = np.zeros((n, n),dtype='float')\n",
    "    rgb_adj = np.zeros((n,n),dtype='float')\n",
    "\n",
    "    #fill adjacency matrix \n",
    "    for i in range(n):\n",
    "        for j in range(i + 1, n):\n",
    "            x1, y1 = i // red.shape[1], i % red.shape[1]\n",
    "            x2, y2 = j // red.shape[1], j % red.shape[1]            \n",
    "            r_adj[i, j] = r_adj[j, i] = np.exp(-((red_norm[x1, y1] - red_norm[x2, y2])**2))\n",
    "            g_adj[i, j] = g_adj[j, i] = np.exp(-((green_norm[x1, y1] - green_norm[x2, y2])**2))\n",
    "            b_adj[i, j] = b_adj[j, i] = np.exp(-((blue_norm[x1, y1] - blue_norm[x2, y2])**2))  \n",
    "            \n",
    "    #calculate combined adjacency list and scale values back to [0,255] range\n",
    "    rgb_adj = np.sqrt(np.square(r_adj) + np.square(g_adj) + np.square(b_adj))/np.sqrt(3)\n",
    "#     rgb_adj *= 255.0\n",
    "    \n",
    "    return rgb_adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rgb_distance_fast(red, green, blue):\n",
    "    # Retrieve list size\n",
    "    n = red.shape[0] * red.shape[1]\n",
    "\n",
    "    # Normalize RGB values to [0,1] range\n",
    "    red_norm = red.astype(float) / 255.0\n",
    "    green_norm = green.astype(float) / 255.0\n",
    "    blue_norm = blue.astype(float) / 255.0\n",
    "\n",
    "    # Flatten color matrices\n",
    "    red_flat = red_norm.ravel()[:, np.newaxis]\n",
    "    green_flat = green_norm.ravel()[:, np.newaxis]\n",
    "    blue_flat = blue_norm.ravel()[:, np.newaxis]\n",
    "\n",
    "    # Compute squared differences and exponential values for each color channel\n",
    "    r_sq_diff = np.exp(-((red_flat - red_flat.T)**2))\n",
    "    g_sq_diff = np.exp(-((green_flat - green_flat.T)**2))\n",
    "    b_sq_diff = np.exp(-((blue_flat - blue_flat.T)**2))\n",
    "\n",
    "    # Calculate combined adjacency matrix\n",
    "    rgb_adj = np.sqrt(r_sq_diff**2 + g_sq_diff**2 + b_sq_diff**2) / np.sqrt(3)\n",
    "\n",
    "    # Force 0's along diagonal\n",
    "    np.fill_diagonal(rgb_adj, 0)\n",
    "\n",
    "    return rgb_adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRAY AS NEGATIVE EXPONENTIAL DISTRIBUTION \n",
    "# PRE-NORMALIZED (x/255)\n",
    "#---------------------- uncomment below ---------------------------------\n",
    "\n",
    "def gray_distance(gray):\n",
    "    #retrieve list size\n",
    "    n = gray.shape[0] * gray.shape[1]\n",
    "    \n",
    "    #normalize GRAY values to [0,1] range\n",
    "    gray_norm = gray.astype(float) / 255.0\n",
    "\n",
    "    #create empty RGB adjacency matrices\n",
    "    gray_adj = np.zeros((n, n),dtype='float')\n",
    "\n",
    "    #fill adjacency matrix \n",
    "    for i in range(n):\n",
    "        for j in range(i + 1, n):\n",
    "            x1, y1 = i // gray.shape[1], i % gray.shape[1]\n",
    "            x2, y2 = j // gray.shape[1], j % gray.shape[1]            \n",
    "            gray_adj[i, j] = gray_adj[j, i] = np.exp(-((gray_norm[x1, y1] - gray_norm[x2, y2])**2))\n",
    "\n",
    "    return gray_adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# R,G,B BY NEGATIVE EXPONENTIAL DIFF --> COMBINE BY EUCLIDEAN DIST\n",
    "#---------------------- uncomment below ---------------------------------\n",
    "\n",
    "# def rgb_distance_3_16_23(red, green, blue):\n",
    "#     #retrieve list size\n",
    "#     n = red.shape[0] * red.shape[1]\n",
    "    \n",
    "#     #create empty RGB adjacency matrices\n",
    "#     r_adj = np.zeros((n, n),dtype='float')\n",
    "#     g_adj = np.zeros((n, n),dtype='float')\n",
    "#     b_adj = np.zeros((n, n),dtype='float')\n",
    "#     rgb_adj = np.zeros((n,n),dtype='float')\n",
    "\n",
    "#     #fill adjacency matrix \n",
    "#     for i in range(n):\n",
    "#         for j in range(i + 1, n):\n",
    "#             x1, y1 = i // red.shape[1], i % red.shape[1]\n",
    "#             x2, y2 = j // red.shape[1], j % red.shape[1]            \n",
    "#             r_adj[i, j] = r_adj[j, i] = np.exp(-((red[x1, y1] - red[x2, y2])**2))\n",
    "#             g_adj[i, j] = g_adj[j, i] = np.exp(-((green[x1, y1] - green[x2, y2])**2))\n",
    "#             b_adj[i, j] = b_adj[j, i] = np.exp(-((blue[x1, y1] - blue[x2, y2])**2))  \n",
    "#             #print(\"pixel1 = (\", x1, y1, \") and Pixel2 = (\", x2, y2, \").\")    \n",
    "            \n",
    "#     #calculate combined adjacency list\n",
    "#     rgb_adj = np.sqrt(np.square(r_adj) + np.square(g_adj) + np.square(b_adj))/np.sqrt(3)\n",
    "    \n",
    "            \n",
    "#     return rgb_adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# R,G,B BY ABSOLUTE VALUE DIFF --> COMBINE BY NEGATIVE EXPONENTIAL DIFF\n",
    "#---------------------- uncomment below ---------------------------------\n",
    "\n",
    "# def rgb_distance(red, green, blue):\n",
    "#     #retrieve list size\n",
    "#     n = red.shape[0] * red.shape[1]\n",
    "#     #create empty RGB adjacency matrices\n",
    "#     r_adj = np.zeros((n, n),dtype='float')\n",
    "#     g_adj = np.zeros((n, n),dtype='float')\n",
    "#     b_adj = np.zeros((n, n),dtype='float')\n",
    "#     rgb_adj = np.zeros((n,n),dtype='float')\n",
    "\n",
    "#     #fill adjacency matrix \n",
    "#     for i in range(n):\n",
    "#         for j in range(i + 1, n):\n",
    "#             x1, y1 = i // red.shape[1], i % red.shape[1]\n",
    "#             x2, y2 = j // red.shape[1], j % red.shape[1]            \n",
    "#             r_adj[i, j] = r_adj[j, i] = abs(red[x1, y1] - red[x2, y2])\n",
    "#             g_adj[i, j] = g_adj[j, i] = abs(green[x1, y1] - green[x2, y2])\n",
    "#             b_adj[i, j] = b_adj[j, i] = abs(blue[x1, y1] - blue[x2, y2])\n",
    "#             #print(\"pixel1 = (\", x1, y1, \") and Pixel2 = (\", x2, y2, \").\")    \n",
    "            \n",
    "#     #calculate combined adjacency list\n",
    "#     rgb_adj = 1 - np.exp(-( np.square(r_adj) + np.square(g_adj) + np.square(b_adj) ))\n",
    "            \n",
    "#     return rgb_adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# R,G,B BY EUCLIDEAN DIST --> COMBINE BY EUCLIDEAN DIST\n",
    "#---------------------- uncomment below ---------------------------------\n",
    "\n",
    "# def rgb_distance(red, green, blue):\n",
    "#     #retrieve list size\n",
    "#     n = red.shape[0] * red.shape[1]\n",
    "    \n",
    "#     #create empty RGB adjacency matrices\n",
    "#     r_adj = np.zeros((n, n),dtype='float')\n",
    "#     g_adj = np.zeros((n, n),dtype='float')\n",
    "#     b_adj = np.zeros((n, n),dtype='float')\n",
    "#     rgb_adj = np.zeros((n,n),dtype='float')\n",
    "\n",
    "#     #fill adjacency matrix \n",
    "#     for i in range(n):\n",
    "#         for j in range(i + 1, n):\n",
    "#             x1, y1 = i // red.shape[1], i % red.shape[1]\n",
    "#             x2, y2 = j // red.shape[1], j % red.shape[1]\n",
    "#             r_adj[i, j] = r_adj[j, i] = abs(red[x1, y1] - red[x2, y2])\n",
    "#             g_adj[i, j] = g_adj[j, i] = abs(green[x1, y1] - green[x2, y2])\n",
    "#             b_adj[i, j] = b_adj[j, i] = abs(blue[x1, y1] - blue[x2, y2])\n",
    "    \n",
    "#     #combine red, green, & blue\n",
    "#     rgb_adj = np.sqrt(np.square(r_adj) + np.square(g_adj) + np.square(b_adj))/ 441.67\n",
    "\n",
    "#     #invert values so 0 is disconnected and 1 is fully connected\n",
    "#     for i in range(rows * cols):\n",
    "#         for j in range(i + 1, rows * cols):\n",
    "#             rgb_adj[i, j] = rgb_adj[j,i] = 1 - rgb_adj[i, j]\n",
    "                     \n",
    "#     return rgb_adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# def rgb_distance_old(red, green, blue):\n",
    "#     #convert arrays to lists\n",
    "#     red_1D = np.asarray(red.flatten())\n",
    "#     green_1D = np.asarray(red.flatten())\n",
    "#     blue_1D = np.asarray(red.flatten())\n",
    "\n",
    "#     #retrieve list size\n",
    "#     n = red_1D.size\n",
    "    \n",
    "#     #create RGB adjacency matrices\n",
    "#     r_adj = np.zeros((n, n),dtype='float')\n",
    "#     g_adj = np.zeros((n, n),dtype='float')\n",
    "#     b_adj = np.zeros((n, n),dtype='float')\n",
    "#     rgb_adj = np.zeros((n,n),dtype='float')\n",
    "\n",
    "#     # Loop over each node and compare it to every other node\n",
    "#     for i in range(n):\n",
    "#         for j in range(i, n):\n",
    "#             #if i != j:\n",
    "#             r_adj[i, j] = r_adj[j, i] = abs(red_1D[i] - red_1D[j])\n",
    "#             g_adj[i, j] = g_adj[j, i] = abs(green_1D[i] - green_1D[j])\n",
    "#             b_adj[i, j] = b_adj[j, i] = abs(blue_1D[i] - blue_1D[j])\n",
    "    \n",
    "#     #calculate combined adjacency list\n",
    "#     rgb_adj = np.sqrt(np.square(r_adj) + np.square(g_adj) + np.square(b_adj))\n",
    "#     #rgb_adj = np.square(r_adj) + np.square(g_adj) + np.square(b_adj)\n",
    "    \n",
    "#     #----------------------------normalized---------------------------------\n",
    "#     print(\"max = \", rgb_adj.max(), \"\\nNon-normalized RGB_adj =\\n\", rgb_adj, \"\\n\")\n",
    "#     #normalize\n",
    "#     rgb_adj = rgb_adj / 441.67\n",
    "#     #-----------------------------------------------------------------------\n",
    "    \n",
    "#     return rgb_adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def value_adjacency(channel1, channel2=None, channel3=None, version=0, display=False, save=False):\n",
    "    if channel2 is None and channel3 is None:\n",
    "        color_setting = 'gray'\n",
    "    else:\n",
    "        color_setting = 'rgb'\n",
    "    \n",
    "    if color_setting == 'rgb':\n",
    "        if version == 0:\n",
    "            rgb_adj = rgb_distance(red, green, blue)\n",
    "        elif version == 1:\n",
    "            rgb_adj = rgb_distance_fast(red, green, blue)\n",
    "        else:\n",
    "            raise ValueError(\"Version must be within selection range.\",\n",
    "                       \"\\nPlease choose from the following:\",\n",
    "                       \"\\n\\t- 0 : RGB exponential calculation slow\",\n",
    "                       \"\\n\\t- 1 : RGB exponential calculation fast\") \n",
    "        if save:\n",
    "            save_data_csv(rgb_adj, \"rgb_adjacency\")\n",
    "        if display:\n",
    "            print(\"-------------------------------------NORMALIZED DISTANCE RESULT-------------------------------------\\n\", rgb_adj)\n",
    "        return rgb_adj\n",
    "    \n",
    "    elif color_setting == 'gray':\n",
    "        gray_adj = gray_distance(gray)\n",
    "        if display:\n",
    "            print(\"-------------------------------------NORMALIZED DISTANCE RESULT-------------------------------------\\n\", gray_adj)\n",
    "        if save:\n",
    "            save_data_csv(gray_adj, \"gray_adjacency\")\n",
    "        return gray_adj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FUNCTION DEFINITIONS: distance adjacency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def euclidean_distance_0(matrix):\n",
    "    rows, cols = matrix.shape\n",
    "    dist_adj = np.zeros((rows * cols, rows * cols))\n",
    "                     \n",
    "    # Compute the Euclidean distance between each pair of pixels\n",
    "    for i in range(rows * cols):\n",
    "        for j in range(i + 1, rows * cols):\n",
    "            x1, y1 = np.unravel_index(i, matrix.shape)\n",
    "            x2, y2 = np.unravel_index(j, (rows, cols))\n",
    "            dist_adj[i, j] = dist_adj[j,i] = np.sqrt((x2 - x1)**2 + (y2 - y1)**2) \n",
    "            #dist_adj[i, j] = dist_adj[j,i] = (x2 - x1)**2 + (y2 - y1)**2      \n",
    "            \n",
    "    #----------------------------normalized---------------------------------\n",
    "    dist_adj = dist_adj / dist_adj.max()\n",
    "    #-----------------------------inverted----------------------------------\n",
    "    # maintains 0's along diagonal \n",
    "    for i in range(rows * cols):\n",
    "        for j in range(i + 1, rows * cols):\n",
    "#             dist_adj[i, j] = 1 - dist_adj[i, j]\n",
    "            dist_adj[i, j] = dist_adj[j,i] = 1 - dist_adj[i, j]\n",
    "            \n",
    "    return dist_adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#POTENTIALLY FASTER DISTANCE CALCULATION\n",
    "def euclidean_distance_1(matrix):\n",
    "    rows, cols = matrix.shape\n",
    "    dist_adj = np.zeros((rows * cols, rows * cols))\n",
    "    \n",
    "    #compute the distances from every element to (x, y).\n",
    "    for i in range(rows):\n",
    "        for j in range(cols):\n",
    "            XGrid, YGrid = np.meshgrid(np.arange(1, cols + 1), np.arange(1, rows + 1))\n",
    "            distances = np.sqrt((i+1 - XGrid)**2 + (j+1 - YGrid)**2)\n",
    "            #distances = (i+1 - XGrid)**2 + (j+1 - YGrid)**2\n",
    "            distances = distances.flatten()\n",
    "            dist_adj[(i*rows)+j,:] = distances[:]\n",
    "            \n",
    "    #----------------------------normalized---------------------------------\n",
    "    dist_adj = dist_adj / dist_adj.max()\n",
    "    #-----------------------------inverted----------------------------------\n",
    "    dist_adj = 1-dist_adj\n",
    "    np.fill_diagonal(dist_adj, 0)\n",
    "    \n",
    "    return dist_adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_distance_2(matrix):\n",
    "    rows, cols = matrix.shape\n",
    "    X, Y = np.indices(matrix.shape)\n",
    "    X, Y = X.ravel(), Y.ravel()\n",
    "    \n",
    "    dist_adj = np.sqrt((X[:, np.newaxis] - X)**2 + (Y[:, np.newaxis] - Y)**2)\n",
    "    #Normalize\n",
    "    dist_adj = dist_adj / dist_adj.max()\n",
    "    #Invert\n",
    "    dist_adj = 1 - dist_adj\n",
    "    #Replace 1's on diagonals with 0's \n",
    "    np.fill_diagonal(dist_adj, 0)\n",
    "    \n",
    "    return dist_adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance_adjacency(dist_matrix, version=0, display=False, save=False):\n",
    "    if version == 0:\n",
    "        dist_adj = euclidean_distance_0(dist_matrix)\n",
    "    elif version == 1:\n",
    "        dist_adj = euclidean_distance_1(dist_matrix)\n",
    "    elif version == 2:\n",
    "        dist_adj = euclidean_distance_2(dist_matrix)\n",
    "    else:\n",
    "        raise ValueError(\"Version must be within selection range.\",\n",
    "                   \"\\nPlease choose from the following:\",\n",
    "                   \"\\n\\t- 0 : euclidean distance slow\",\n",
    "                   \"\\n\\t- 1 : euclidean distance fast\",\n",
    "                   \"\\n\\t- 2 : euclidean distance - vectorization w. broadcasting\")\n",
    "        \n",
    "    if display:\n",
    "        print(\"-------------------------------------NORMALIZED DISTANCE RESULT-------------------------------------\\n\", dist_adj)\n",
    "    if save:\n",
    "        save_data_csv(dist_adj, \"distance_adjacency\")\n",
    "        \n",
    "    return dist_adj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FUNCTION DEFINITIONS: combine matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_adjacency(value_a, dist_a, alpha, display=False, save=False):\n",
    "    '''Higher alpha results in more weight on color and less weight on distance.'''\n",
    "    # complete_adj = (value_a + dist_a)/2\n",
    "    complete_adj = ((alpha)*value_a + (1-alpha)*dist_a)\n",
    "    if display:\n",
    "        print(\"-------------------------------------COMPLETE ADJACENCY RESULT-------------------------------------\\n\", complete_adj)\n",
    "    if save:\n",
    "        save_data_csv(complete_adj, \"complete_adjacency\")        \n",
    "    return complete_adj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Degree & Laplacian (D & L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_DL(adjacency_matrix, display=False, save=False):\n",
    "    \n",
    "    #compute degree matrix\n",
    "    D = np.diagflat(np.sum(adjacency_matrix, axis=1).T)\n",
    "    \n",
    "    #compute laplacian matrix\n",
    "    L = D - complete_adj\n",
    "    if save:\n",
    "        save_data_csv(L, \"laplacian_matrix\")\n",
    "    \n",
    "    #confirm Laplacian symmetry (important for eigenvector & eigenvalue calculations)\n",
    "    if np.array_equal(L, L.T):\n",
    "        print(\"The Laplacian is confirmed to be symmetric.\")\n",
    "    else:\n",
    "        print(\"WARNING! The Laplacian is NOT symmetric. Please check data.\")\n",
    "    \n",
    "    if display:\n",
    "        print(\"Degree Matrix:\\n\\n\", D)\n",
    "        print(\"Laplacian Matrix:\\n\\n\", L)\n",
    "    \n",
    "    return D, L"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eigenvalues & Eigenvectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#help(eigs) #help(eigsh) #help(lobpcg)\n",
    "def generate_eigens(L, eigen_type='eigh', sort=True, order='ascending', \n",
    "                    normalize=True, transpose=False, k=None, \n",
    "                    display=False, save=False):\n",
    "    \"\"\"\n",
    "    -\n",
    "    FUNCTIONS AVAILABLE: eig, eigh, eigs, eigsh, lobpcg\n",
    "    MODIFICATIONS AVAILABLE: sort (ascending/descending), normalize, transpose\n",
    "    NOTE! For eigs(), eigsh(), lobpcg(), please choose k.\n",
    "    -\n",
    "    \"\"\"\n",
    "    #display no-k estimator warning\n",
    "    if eigen_type=='eigs' or eigen_type=='eigsh' or eigen_type=='lobpcg' and k==None:\n",
    "        raise ValueError(\"ERROR! k cannot be None.\\n\",\n",
    "              \"To use eigenvector 'estimation' functions, please specify k number of vectors.\")\n",
    "        \n",
    "    #track modification status for validity check\n",
    "    mod_status = False\n",
    "        \n",
    "    print(\"\\nGenerating Vectors with Properties...\")\n",
    "    \n",
    "    if eigen_type == \"eig\":\n",
    "        descriptor = \"numpy_eig\"\n",
    "        values,vectors = eig(L)\n",
    "        print(\" - eig()\")\n",
    "\n",
    "    elif eigen_type == \"eigh\":\n",
    "        descriptor = \"numpy_eigh\"\n",
    "        values,vectors = eigh(L)  #use eigh since matrix is symmetric & real\n",
    "        print(\" - eigh()\")\n",
    "    \n",
    "    elif eigen_type == \"eigs\":\n",
    "        descriptor = \"scipy_eigs\"\n",
    "        values, vectors = eigs(L, k)\n",
    "        values = np.real(values)\n",
    "        vectors = np.real(vectors)\n",
    "        print(\" - scipy eigs()\")\n",
    "        \n",
    "    elif eigen_type == \"eigsh\":\n",
    "        descriptor = 'scipy_eigsh'\n",
    "        values, vectors = eigsh(L, k=k, which='LM')\n",
    "        print(\" - scipy eigsh() estimation\")\n",
    "        \n",
    "    elif eigen_type == \"lobpcg\":\n",
    "        descriptor = 'scipy_lobpcg'\n",
    "        Xshape = np.random.rand(L.shape[0], k)\n",
    "        #Xshape = np.array([L.shape[0], k])\n",
    "        values, vectors = lobpcg(L, X=Xshape, largest=True)\n",
    "        print(\" - scipy lobpcg() estimation\")\n",
    "            \n",
    "    if sort:\n",
    "        # values, vectors = values[np.argsort(-values)], vectors[:, np.argsort(-values)]\n",
    "        descriptor = descriptor + \"_sorted\"\n",
    "        mod_status = True\n",
    "        values,vectors = eigh(L)  #use eigh since matrix is symmetric & real\n",
    "        # Sort eigenvectors by eigenvalues ASCENDING\n",
    "        if order == 'ascending':\n",
    "            values = values.argsort()[::1]\n",
    "            vectors = vectors[:,values]\n",
    "        # Sort eigenvectors by eigenvalues DESCENDING\n",
    "        if order == 'descending':\n",
    "            values = values.argsort()[::-1]\n",
    "            vectors = vectors[:,values]\n",
    "        print(f\" - sorted {order}\")\n",
    "        \n",
    "    if normalize:\n",
    "        descriptor = descriptor + \"_normal\"\n",
    "        mod_status = True\n",
    "        # Using np.linalg.norm which performs L2 euclidean normalization.  \n",
    "        # axis=0 performs normalization over columns.\n",
    "        norms = np.linalg.norm(vectors, axis=0) \n",
    "        vectors = vectors / norms    \n",
    "        print(\" - normalized by linalg.norm (euclidean)\")\n",
    "        \n",
    "#     if non_normalize:\n",
    "#         descriptor = descriptor + \"_normal\"\n",
    "#         mod_status = True\n",
    "#         # Using np.linalg.norm which performs L2 euclidean normalization.  \n",
    "#         # axis=0 performs normalization over columns.\n",
    "#         norms = np.linalg.norm(vectors, axis=0) \n",
    "#         vectors = vectors / norms    \n",
    "#         print(\" - normalized by linalg.norm (euclidean)\")\n",
    "        \n",
    "    if transpose:\n",
    "        descriptor = descriptor + \"_T\"\n",
    "        mod_status = True\n",
    "        vectors = vectors.T\n",
    "        print(\" - transposed\")\n",
    "        \n",
    "    # OTHER\n",
    "    # descriptor = descriptor + \"_misc\"\n",
    "    # # # vectors /= vectors[0,:]  #divide all by first element in each column\n",
    "    # vectors /= vectors[:,0] #divide all by first element in each row \n",
    "    # print(\"\\nEigenvector(s) Divided (vertical vector view):\\n\", vectors)\n",
    "    # vectorsT = vectors.T\n",
    "    # print(\"\\nEigenvector(s) Transformed (horizontal vector view):\\n\", vectorsT)\n",
    "\n",
    "    if display:\n",
    "        print(\"\\nEigenvalues:\\n\", values)\n",
    "        print(\"\\nEigenvectors:\\n\", vectors)\n",
    "    \n",
    "    if save: \n",
    "        # Concatenate the eigenvalues and eigenvectors into a single NumPy array\n",
    "        eigen_concat = np.concatenate((values.reshape(-1, 1), vectors), axis=1)\n",
    "        # Define the file path for the CSV file\n",
    "        filename = f\"eigenvectors_{descriptor}\"\n",
    "        # Save to file\n",
    "        save_data_csv(eigen_concat, filename)\n",
    "        \n",
    "    return values, vectors, mod_status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Calculates the eigenvalues and eigenvectors of a matrix using the QR algorithm.\n",
    "    \n",
    "    Args:\n",
    "    A: ndarray, the input matrix\n",
    "    epsilon: float, the convergence criterion\n",
    "    max_iterations: int, the maximum number of iterations\n",
    "    \n",
    "    Returns:\n",
    "    eigenvalues: ndarray, the eigenvalues of A\n",
    "    eigenvectors: ndarray, the eigenvectors of A\n",
    "    \"\"\"\n",
    "def eigen_decomposition(A, epsilon=1e-10, max_iterations=1000):\n",
    "    n = A.shape[0]\n",
    "    Q = np.eye(n)\n",
    "    for i in range(max_iterations):\n",
    "        Q, R = np.linalg.qr(A.dot(Q))\n",
    "        A_new = R.dot(Q)\n",
    "        if np.abs(A - A_new).max() < epsilon:\n",
    "            break\n",
    "        A = A_new\n",
    "    eigenvalues = np.diag(A)\n",
    "    eigenvectors = Q\n",
    "    return eigenvalues, eigenvectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Validity and Quality Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_eigenvector_validity(values, vectors, mod_status):\n",
    "    \"\"\"\n",
    "    -\n",
    "    Check the validity of the eigenvalues and eigenvectors by...\n",
    "         1) diagonalizing the eigenvalues  \n",
    "         2) calculating (vectors)(values)(vectors)^(-1)  \n",
    "         3) comparing to original laplacian matrix. \n",
    "\n",
    "    IMPORTANT: This will not work on normalized or sorted eigenvalues. \n",
    "    This check should be ran on unmodified values and vectors only.\n",
    "    -\n",
    "    \"\"\"\n",
    "    if mod_status == True:\n",
    "        print(\"COMPARISON INVALID\\n\",\n",
    "              \"Vector orders or values have been modified and are no longer comparable.\")\n",
    "        return False\n",
    "    else: \n",
    "        # # diagonalize the eigenvalues\n",
    "        values_diag = np.diag(values)\n",
    "        # invert the eigenvectors\n",
    "        vectors_inv = np.linalg.inv(vectors)\n",
    "        #reconstruct the original matrix\n",
    "        L_reconstructed = vectors @ values_diag @ vectors_inv\n",
    "        #COMPARE\n",
    "        laplacian_comparison(L,L_reconstructed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def laplacian_comparison(matrix1, matrix2, abs_tol = 1e-08):\n",
    "    '''The checking behavior is identical to the matrix_comparison method \n",
    "    but laplacian_comparison contains different print statements for the user. \n",
    "    \\nThis method should be called by check_eigenvector_validity only.'''\n",
    "    \n",
    "    if(np.array_equal(matrix1 , matrix2)):\n",
    "        print(\"\\nL and the reconstructed L are EQUAL.\",\n",
    "              \"\\nTherefore our eigenvalues & vectors are valid.\\n\")\n",
    "        return \"PASS\"\n",
    "    elif(np.array_equiv(matrix1 , matrix2)):\n",
    "        print(\"\\nL and the reconstructed L are EQUIVALENT.\",\n",
    "              \"\\nThe two arrays can be broadcasted to be the same shape, with all elements are equal.\\n\")\n",
    "        return \"partial pass\"\n",
    "    elif(np.allclose(matrix1 , matrix2, atol=abs_tol)): #absolute tolerance between two elements for \"closeness\"\n",
    "        print(\"\\nL and the reconstructed L are CLOSE. Within absolute tolerance = \", abs_tol, \n",
    "              \"\\nThe two arrays can be broadcasted to be the same shape, and all elements are tolerably similar.\\n\")\n",
    "        return \"partial pass\"\n",
    "    else:\n",
    "        print(\"\\nWARNING!!!\\nL and reconstructed L are NOT the same!\",\n",
    "              \"\\nConfirm that comparison is being performed on non-sorted, non-normalized eigenvectors.\",\n",
    "              \"\\nError may exist.\\n\")\n",
    "        print(\"matrix 1:\\n\", matrix1)\n",
    "        print(\"matrix 2:\\n\", matrix2)\n",
    "        return \"FAIL\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matrix_comparison(matrix1, matrix2, abs_tol = 1e-08):\n",
    "\n",
    "    if(np.array_equal(matrix1 , matrix2)):\n",
    "        print(\"\\nMatrix 1 and Matrix 2 are EQUAL.\")\n",
    "        return \"PASS\"\n",
    "    elif(np.array_equiv(matrix1 , matrix2)):\n",
    "        print(\"\\nMatrix 1 and Matrix 2 are EQUIVALENT.\",\n",
    "              \"\\nThe two arrays can be broadcasted to be the same shape, with all elements are equal.\\n\")\n",
    "        return \"partial pass\"\n",
    "    elif(np.allclose(matrix1 , matrix2, atol=abs_tol)): #absolute tolerance between two elements for \"closeness\"\n",
    "        print(\"\\nMatrix 1 and Matrix 2 are CLOSE. Within absolute tolerance = \", abs_tol, \n",
    "              \"\\nThe two arrays can be broadcasted to be the same shape, and all elements are tolerably similar.\\n\")\n",
    "        return \"partial pass\"\n",
    "    else:\n",
    "        print(\"\\nWARNING!!!\\nMatrix 1 and Matrix 2 are NOT the same!\",\n",
    "              \"\\nConfirm that comparison is being performed on non-sorted, non-normalized versions.\",\n",
    "              \"\\nError may exist. Matrices are displayed below.\\n\")\n",
    "        print(\"matrix 1:\\n\", matrix1)\n",
    "        print(\"matrix 2:\\n\", matrix2)\n",
    "        return \"FAIL\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def perform_kmeans(fitting_data, k, display=True, save=True):\n",
    "           \n",
    "#     kmeans_model = KMeans(n_clusters=k, init='k-means++')\n",
    "    \n",
    "#     if fitting_data == vectors:\n",
    "#         kmeans_model.fit(fitting_data[:,:k])     # FIT\n",
    "#         prediction_labels = kmeans_model.predict(fitting_data[:,:k])     # PREDICT\n",
    "       \n",
    "#     elif fitting_data == complete_adj:\n",
    "#         kmeans_model.fit_predict(complete_adj)     # FIT + PREDICT           \n",
    "        \n",
    "#     else:\n",
    "#         print(\"Please specify whether you are fitting on \\n'vectors' for eigenvectors, or \\n'complete_adj' for adjacency\")\n",
    "#         return False\n",
    "    \n",
    "#     # RETRIEVE LABELS\n",
    "#     labels = kmeans_model.labels_\n",
    "    \n",
    "#     # SAVE\n",
    "#     if save == True:\n",
    "#         save_data_csv(labels.reshape(rows, cols), f\"kmeans_fit_labels_from_{fitting_data}\")\n",
    "#         # save_data_csv(prediction_labels.reshape(rows, cols), f\"kmeans_pred_labels_from_{fitting_data}\")\n",
    "        \n",
    "#     # DISPLAY LABELS\n",
    "#     print(f\"\\nFitted Labels on {fitting_data}:\", labels)\n",
    "#     print(\"Fitted Labels - Array Formatted:\\n\", labels.reshape(rows, cols))\n",
    "# #     print(\"\\nPredicted Labels: \", prediction_labels) \n",
    "# #     print(\"Predicted Labels - Array Formatted:\\n\", prediction_labels.reshape(rows, cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_cluster_figures_for_vectors(k=2, min_vectors=0, max_vectors=2, label_each=False, display=False):\n",
    "#     if max_vectors > k+1:\n",
    "#         raise ValueError(\"# of vectors for training must be <= k+1\")\n",
    "    \n",
    "    result_set = []        \n",
    "#     result_set.append(pilImg)\n",
    "    \n",
    "    for n in range(max_vectors):\n",
    "        n_vectors = n + min_vectors\n",
    "        if n_vectors <= 1:# or n_vectors > k:\n",
    "            continue\n",
    "\n",
    "        # INSTANTIATE MODEL\n",
    "        kmeans_model = KMeans(n_clusters=k, init='k-means++', n_init=10)          \n",
    "\n",
    "        # FIT\n",
    "        kmeans_model.fit(vectors[:, :n_vectors])       \n",
    "        labels = kmeans_model.labels_\n",
    "\n",
    "        # DISPLAY \n",
    "        results = labels.reshape(rows, cols)\n",
    "        if label_each:\n",
    "            result_img = retrieve_cluster_image(results, f'v={n_vectors}, k={k}')\n",
    "        else:\n",
    "            result_img = retrieve_cluster_image(results)\n",
    "        \n",
    "        result_set.append(result_img)\n",
    "        \n",
    "    return result_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_clustering_test_for_vectors(k=2, min_vectors=0, max_vectors=2, display=False):\n",
    "#     k = 8\n",
    "#     max_vectors = k+1\n",
    "\n",
    "    if max_vectors >= k+1:\n",
    "        print(\"# of vectors for training must be <= k+1\")\n",
    "        \n",
    "    result_set = []\n",
    "    \n",
    "    for n in range(max_vectors):\n",
    "        n_vectors = n + min_vectors\n",
    "        if n_vectors == 0 or n_vectors == 1:\n",
    "            continue\n",
    "\n",
    "        # INSTANTIATE MODEL\n",
    "        kmeans_model = KMeans(n_clusters=k, init='k-means++', n_init=10)          \n",
    "\n",
    "        # FIT\n",
    "        kmeans_model.fit(vectors[:,1:n_vectors])       \n",
    "        labels = kmeans_model.labels_\n",
    "\n",
    "        # DISPLAY \n",
    "        results = labels.reshape(rows, cols)\n",
    "        result_img = visualize_clustering(pilImg, results, \"Original Image\"\n",
    "                                          , f\"Predicted on {n_vectors} VECTORS with k={k}\"\n",
    "                                          , 'rgb', display=display)\n",
    "        \n",
    "        result_set.append(result_img)\n",
    "        \n",
    "    return result_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buid_cluster_figures_for_k(min_k=2, max_k=10, n_vectors=2, label_each=False, display=False):\n",
    "    if n_vectors > min_k:\n",
    "        raise ValueError(\"# of vectors for training must be <= the minimum k\")\n",
    "        \n",
    "    result_set = []\n",
    "    \n",
    "    for i in range(max_k-1):\n",
    "        k = i + min_k\n",
    "        \n",
    "        if k == 0 or k == 1:\n",
    "            continue\n",
    "\n",
    "        # INSTANTIATE MODEL\n",
    "        kmeans_model = KMeans(n_clusters=k, init='k-means++', n_init=10)          \n",
    "\n",
    "        # FIT\n",
    "        kmeans_model.fit(vectors[:, :n_vectors])       \n",
    "        labels = kmeans_model.labels_\n",
    "\n",
    "        # DISPLAY \n",
    "        results = labels.reshape(rows, cols)\n",
    "        if label_each:\n",
    "            result_img = retrieve_cluster_image(results, f'v={n_vectors}, k={k}')\n",
    "        else:\n",
    "            result_img = retrieve_cluster_image(results)\n",
    "        \n",
    "        result_set.append(result_img)\n",
    "        \n",
    "    return result_set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_clustering_test_for_k(min_k=2, max_k=10, n_vectors=2, display=False):\n",
    "    if n_vectors > min_k:\n",
    "        raise ValueError(\"# of vectors for training must be <= the minimum k\")\n",
    "        \n",
    "    result_set = []\n",
    "    \n",
    "    for i in range(max_k-1):\n",
    "        k = i + min_k\n",
    "        \n",
    "        if k == 0 or k == 1:\n",
    "            continue\n",
    "\n",
    "        # INSTANTIATE MODEL\n",
    "        kmeans_model = KMeans(n_clusters=k, init='k-means++', n_init=10)          \n",
    "\n",
    "        # FIT\n",
    "        kmeans_model.fit(vectors[:,1:n_vectors])       \n",
    "        labels = kmeans_model.labels_\n",
    "\n",
    "        # DISPLAY \n",
    "        results = labels.reshape(rows, cols)\n",
    "        result_img = visualize_clustering(pilImg, results, \"Original Image\"\n",
    "                                          , f\"Predicted on {n_vectors} VECTORS with k={k}\"\n",
    "                                          , 'rgb', display=display)\n",
    "        \n",
    "        result_set.append(result_img)\n",
    "        \n",
    "    return result_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-Existing Library Use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import SpectralClustering\n",
    "\n",
    "def segment_image(image, n_clusters):\n",
    "    red, green, blue = image[:, :, 0], image[:, :, 1], image[:, :, 2]\n",
    "    rows, cols = red.shape\n",
    "\n",
    "    rgb_adj = rgb_distance(red, green, blue)\n",
    "    dist_adj = euclidean_distance(red)\n",
    "    complete_adj = (rgb_adj + dist_adj) / 2\n",
    "\n",
    "    clustering = SpectralClustering(n_clusters=n_clusters, affinity='precomputed')\n",
    "    labels_flat = clustering.fit_predict(complete_adj)\n",
    "    labels = labels_flat.reshape(rows, cols)\n",
    "    \n",
    "    segmented = np.zeros_like(image)\n",
    "    for i in range(n_clusters):\n",
    "        segmented[labels == i] = np.median(image[labels == i], axis=0)\n",
    "        \n",
    "    # Plot the original image and the segmented image side by side\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
    "    ax[0].imshow(image)\n",
    "    ax[0].set_title('Original Image')\n",
    "    ax[1].imshow(segmented)\n",
    "    ax[1].set_title('Segmented Image')\n",
    "    plt.show()\n",
    "\n",
    "    return segmented, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_repeating_values(label_set):\n",
    "#     rows, cols = label_set.shape\n",
    "    all_cluster_counts = np.zeros_like(label_set, dtype=object)\n",
    "    for i, ktest in enumerate(label_set): \n",
    "        for j, single in enumerate(ktest):\n",
    "            # Convert the ndarray to a list and use Counter to count occurrences\n",
    "            value_counts = Counter(single.flatten().tolist())\n",
    "            counts = tuple(value_counts.values())\n",
    "            all_cluster_counts[i,j] = counts\n",
    "    return all_cluster_counts\n",
    "\n",
    "import statistics    \n",
    "def calculate_variances(pixel_counts, fileName=\"\", save=False):\n",
    "    rows, cols = pixel_counts.shape\n",
    "    cluster_variances = np.zeros_like(pixel_counts, dtype=object)\n",
    "    for i in range(rows): \n",
    "        for j in range(cols):\n",
    "            counts = pixel_counts[i,j]\n",
    "            variance = statistics.variance(counts) #for count in counts\n",
    "            cluster_variances[i,j] = variance      \n",
    "    if save:\n",
    "        save_data_csv(cluster_variances, f'Measurements/{fileName}_variance')\n",
    "#     print(cluster_variance)\n",
    "    return cluster_variances \n",
    "\n",
    "def calculate_denominators(pixel_counts):\n",
    "    rows, cols = pixel_counts.shape\n",
    "    denominators = np.empty(rows)\n",
    "    for i in range(rows):\n",
    "        denominators[i] = sum(pixel_counts[i,0])\n",
    "    return denominators\n",
    "\n",
    "\n",
    "def calculate_proportions(pixel_counts, denominators):\n",
    "    rows, cols = pixel_counts.shape\n",
    "    cluster_proportions = np.zeros_like(pixel_counts, dtype=object)\n",
    "    for i in range(rows): \n",
    "        for j in range(cols):\n",
    "            counts = pixel_counts[i,j]\n",
    "            proportion = tuple(count / denominators[i] for count in counts)\n",
    "            cluster_proportions[i,j] = proportion\n",
    "    return cluster_proportions \n",
    "\n",
    "def calculate_balance_measures(proportions, min_k, max_k, fileName=\"\", save=False):\n",
    "    rows, cols = proportions.shape\n",
    "    cluster_counts = list(range(min_k, max_k+1))  \n",
    "    balance_values = np.zeros_like(proportions, dtype=object)\n",
    "\n",
    "    nonnorm_balance_values = np.zeros_like(proportions, dtype=object) \n",
    "    \n",
    "    for i in range(rows): \n",
    "        for j in range(cols):\n",
    "            for k, proportion in enumerate(proportions[i,j]):\n",
    "                if k == 0:\n",
    "                    unnormalized_balance = proportion\n",
    "                else:   \n",
    "                    unnormalized_balance *= proportion\n",
    "            # norm_bal = unnorm_bal / (1/k)^k\n",
    "            normalized_balance = unnormalized_balance / ((1/cluster_counts[i])**cluster_counts[i])\n",
    "            balance_values[i,j] = (normalized_balance)\n",
    "            nonnorm_balance_values[i,j] = (unnormalized_balance)\n",
    "    if save:\n",
    "        save_data_csv(balance_values, f\"Measurements/{fileName}_balance\")\n",
    "    return balance_values, nonnorm_balance_values\n",
    "\n",
    "def summarize_balance_measures(balance_values, measure='', fileName='', save=False):\n",
    "    rows, cols = balance_values.shape\n",
    "    avg_on_cols = []\n",
    "    avg_lowertriangular = []\n",
    "    k_sums = 0\n",
    "    \n",
    "    for j in range(cols):\n",
    "        total_avg = sum(balance_values[:,j]) / rows\n",
    "        half_avg = sum(balance_values[j:,j]) / (rows-j)\n",
    "#         print(total_avg)\n",
    "        avg_on_cols.append(total_avg)\n",
    "        avg_lowertriangular.append(half_avg)\n",
    "        \n",
    "        k_sums += balance_values[j,j]\n",
    "    k_avg = k_sums / rows\n",
    "    avg_on_cols.append(k_avg)\n",
    "    avg_lowertriangular.append(k_avg)\n",
    "    \n",
    "    if save:\n",
    "        save_data_csv(avg_on_cols, f\"Measurements/{fileName}_{measure}_avg\")\n",
    "        save_data_csv(avg_lowertriangular, f\"Measurements/{fileName}_{measure}_avg_lower\")\n",
    "        \n",
    "    return avg_on_cols, avg_lowertriangular\n",
    "\n",
    "def display_balance_results(balance, summary, non_norm_bal=None, proportions=None, specific_index=None):\n",
    "    if specific_index is not None:\n",
    "        if proportions is not None:\n",
    "            print(f\"\\nclustering proportions for K = {specific_index+2}\\n\", proportions[specific_index])\n",
    "        if non_norm_bal is not None:\n",
    "            print(f\"non-normalized clustering balance for K = {specific_index+2}\\n\", non_norm_bal[specific_index])\n",
    "        print(f\"clustering balance for K = {specific_index+2}\\n\", balance[specific_index])\n",
    "    \n",
    "    print(\"\\n-----------------Resulting Balances For 2nd Eigenvectors & Kth Eigenvectors-----------------\")  \n",
    "    rows, cols = balance.shape\n",
    "    for i in range(rows):\n",
    "        if balance[i,0] > balance[i,i]:\n",
    "            measure_status = \"2nd Eigenvector performed BETTER than k-th eigenvector.\"\n",
    "        elif balance[i,0] < balance[i,i]:\n",
    "            measure_status = \"2nd Eigenvector performed WORSE than k-th eigenvector.\"\n",
    "        else:\n",
    "            measure_status = \"2nd Eigenvector performed EQUIVALENTLY to the k-th eigenvector.\"\n",
    "\n",
    "        print(f\"FOR K = {i+2} | V=2: {balance[i,0]:<20.15f} V=k: {balance[i,i]:<20.15f}{measure_status}\")\n",
    "        \n",
    "    print(\"\\n-----------------Averages Across All K For Each Eigenvector Column-----------------\") \n",
    "    print(summary)\n",
    "    print(\"\\tNote 1: last column corresponds to the diagonal k.\\n\",\n",
    "          \"\\tNote 2: columns between the 2nd eigenvector and k appear to have smaller values than k\\n\",\n",
    "          \"\\t        this is because they are inclusive of v>k results (unklike the v=k summary).\")   \n",
    "\n",
    "def calculate_clustering_performance(labels, min_k, max_k, fileName=\"\", lower_triangular=True, save=False):\n",
    "    pixel_counts = count_repeating_values(test_set_labels)\n",
    "    \n",
    "    variances = calculate_variances(pixel_counts, fileName=fileName, save=save)\n",
    "    summary_of_var, summary_lower_var = summarize_balance_measures(variances, measure='variance', fileName=fileName, save=save)\n",
    "#     display_balance_results(balance, summary_of_results, non_norm_bal, proportions)#, specific_index=0)\n",
    "    \n",
    "    denominators = calculate_denominators(pixel_counts)\n",
    "    proportions = calculate_proportions(pixel_counts, denominators)\n",
    "    balance, non_norm_bal = calculate_balance_measures(proportions, min_k=min_k, max_k=max_k, fileName=fileName, save=save)\n",
    "    summary_of_results, summary_lower_triangular = summarize_balance_measures(balance, measure='balance', fileName=fileName, save=save)\n",
    "    display_balance_results(balance, summary_of_results, non_norm_bal, proportions)#, specific_index=0)\n",
    "    \n",
    "    if lower_triangular:\n",
    "        return balance, summary_lower_triangular\n",
    "    else:\n",
    "        return balance, summary_of_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "def calculate_hopkins_statistic(data):\n",
    "    n = data.shape[0]  # Number of data points\n",
    "\n",
    "    # Step 1: Randomly select points from the dataset\n",
    "    random_points = np.random.uniform(low=np.min(data, axis=0), high=np.max(data, axis=0), size=(n, data.shape[1]))\n",
    "\n",
    "    # Step 2: Calculate nearest neighbor distances for random points\n",
    "    nn_random = NearestNeighbors(n_neighbors=1).fit(random_points)\n",
    "    random_distances, _ = nn_random.kneighbors(random_points)\n",
    "\n",
    "    # Step 3: Calculate nearest neighbor distances for the original dataset\n",
    "    nn_data = NearestNeighbors(n_neighbors=2).fit(data)\n",
    "    data_distances, _ = nn_data.kneighbors(data)\n",
    "\n",
    "    # Step 4: Compute the Hopkins statistic\n",
    "    numerator = np.sum(random_distances)\n",
    "    denominator = numerator + np.sum(data_distances[:, 1])  # Exclude self-distances\n",
    "    hopkins_statistic = numerator / denominator\n",
    "\n",
    "    return hopkins_statistic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TEST ENVIRONMENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "def perform_eigenvector_cluster_tests(vectors, shape, min_k=2, max_k=2, min_v=2, max_v=2):\n",
    "    if min_k <= 1:\n",
    "            raise ValueError(\"Clustering cannot be performed for less than 2 classes. Please choose a higher minimum cluster value.\")\n",
    "    if min_v <= 1:\n",
    "            raise ValueError(\"Clustering should not be performed using less than 2 vectors. Please choose a higher minimum vector value.\")\n",
    "    \n",
    "    all_test_labels = np.empty((max_k-min_k+1, max_v-min_v+1), dtype=object)\n",
    "    # TEST EACH CLUSTER COUNT\n",
    "    current_k = min_k\n",
    "    while current_k <= max_k:\n",
    "        # TEST EACH EIGENVECTOR-MATRIX SIZE\n",
    "        current_v = min_v\n",
    "        while current_v <= max_v:\n",
    "            # if current_v > current_k:\n",
    "                # raise ValueError(\"# of vectors for training is ideally <= k\")\n",
    "            # INSTANTIATE MODEL\n",
    "            kmeans_model = KMeans(n_clusters=current_k, init='k-means++', n_init=10)\n",
    "            # FIT\n",
    "            kmeans_model.fit(vectors[:, :current_v])       \n",
    "            labels = kmeans_model.labels_\n",
    "            results = labels.reshape(shape[0], shape[1])\n",
    "            # ADD TO RESULTS\n",
    "            all_test_labels[current_k-min_k, current_v-min_v] = results\n",
    "            current_v += 1\n",
    "        current_k += 1\n",
    "            \n",
    "    return all_test_labels\n",
    "\n",
    "def retrieve_all_cluster_plots(all_labels, auto_label=False):\n",
    "    all_plots = []\n",
    "    rows, cols = all_labels.shape\n",
    "    for i in range(rows):\n",
    "        for j in range(cols):\n",
    "            if auto_label:\n",
    "                single_plot = retrieve_cluster_image(all_labels[i,j], f'k={i}, v={j}')\n",
    "            else:\n",
    "                single_plot = retrieve_cluster_image(all_labels[i,j])\n",
    "            all_plots.append(single_plot)\n",
    "        \n",
    "    return all_plots\n",
    "\n",
    "def retrieve_cluster_image(shaped_labels, title=None):\n",
    "    plt.imshow(shaped_labels)\n",
    "    if title is not None:\n",
    "        plt.title(title, fontsize=12)\n",
    "    plt.grid(False)\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout(pad=0)\n",
    "    cluster_img = transform_plot_to_image(plt)\n",
    "    plt.close()       \n",
    "        \n",
    "    return cluster_img\n",
    "\n",
    "# SUPRESS UNRELATED DEPRECIATION WARNING\n",
    "import warnings\n",
    "def display_clustering_tests(all_labels, all_plots, title, save_individual=False, save_set=False):\n",
    "    rows, cols = all_labels.shape\n",
    "    with warnings.catch_warnings():\n",
    "        # warnings.simplefilter(\"ignore\", category=FutureWarning)\n",
    "        # warnings.simplefilter(\"ignore\", category=np.VisibleDeprecationWarning)\n",
    "        # Convert each PngImageFile to a NumPy array\n",
    "        # all_plots_np = np.array([np.array(plot) for plot in all_plots])\n",
    "        # all_plots_np = all_plots_np.reshape(rows, cols)\n",
    "        # all_plots_np = np.array(all_plots).reshape(rows,cols)\n",
    "        \n",
    "        all_plots_np = [np.array(plot) for plot in all_plots]\n",
    "        assert len(all_plots_np) == 25\n",
    "        # Now pass this list of images to your plotting function\n",
    "        # (Adjust plot_rowsxcols_style2 to handle a list of image arrays)\n",
    "        plot_rowsxcols_style2(all_plots_np, rows, cols, title, save=save_set)\n",
    "\n",
    "    if save_individual:\n",
    "        mini_titles=[]\n",
    "        result_titles=[]\n",
    "        for i in range(rows):\n",
    "            for j in range(cols):\n",
    "                mini_titles.append(f\"{title}_results{i}{j}\")\n",
    "            save_images(np.array(all_plots_np[i]), mini_titles)\n",
    "            mini_titles=[]\n",
    "\n",
    "    plot_rowsxcols_style2(all_plots, rows, cols, title, save=save_set)\n",
    "\n",
    "def display_result_set(result_set, title, save_individual=False, save_set=False):\n",
    "    rows = len(result_set)\n",
    "    cols = len(result_set[0])\n",
    "    result_titles=[]\n",
    "    mini_titles=[]\n",
    "    all_images=[]\n",
    "    for i, result in enumerate(result_set):\n",
    "        for j, img in enumerate(result_set[i]):\n",
    "            all_images.append(img)\n",
    "            mini_titles.append(f\"{title}_results{i}{j}\")\n",
    "        result_titles.append(mini_titles)\n",
    "        mini_titles=[]\n",
    "    \n",
    "    if save_individual:\n",
    "        for i, result in enumerate(result_set):\n",
    "            output_message = save_images(result_set[i], result_titles[i])\n",
    "    plot_rowsxcols_style2(all_images, rows, cols, title, save=save_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
